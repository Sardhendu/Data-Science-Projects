{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "# Created by: Sardhendu Mishra\n",
    "# With Regards to: Course CS 584\n",
    "# CWID: A20388502\n",
    "######################################\n",
    "\n",
    "\n",
    "# import done here\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict, defaultdict\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loading the Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1993, 104)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>communityname</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>numbUrban</th>\n",
       "      <th>pctUrban</th>\n",
       "      <th>medIncome</th>\n",
       "      <th>pctWWage</th>\n",
       "      <th>pctWFarmSelf</th>\n",
       "      <th>pctWInvInc</th>\n",
       "      <th>pctWSocSec</th>\n",
       "      <th>pctWPubAsst</th>\n",
       "      <th>pctWRetire</th>\n",
       "      <th>medFamInc</th>\n",
       "      <th>perCapInc</th>\n",
       "      <th>whitePerCap</th>\n",
       "      <th>blackPerCap</th>\n",
       "      <th>indianPerCap</th>\n",
       "      <th>AsianPerCap</th>\n",
       "      <th>OtherPerCap</th>\n",
       "      <th>HispPerCap</th>\n",
       "      <th>NumUnderPov</th>\n",
       "      <th>PctPopUnderPov</th>\n",
       "      <th>PctLess9thGrade</th>\n",
       "      <th>PctNotHSGrad</th>\n",
       "      <th>PctBSorMore</th>\n",
       "      <th>PctUnemployed</th>\n",
       "      <th>PctEmploy</th>\n",
       "      <th>PctEmplManu</th>\n",
       "      <th>PctEmplProfServ</th>\n",
       "      <th>PctOccupManu</th>\n",
       "      <th>PctOccupMgmtProf</th>\n",
       "      <th>MalePctDivorce</th>\n",
       "      <th>MalePctNevMarr</th>\n",
       "      <th>FemalePctDiv</th>\n",
       "      <th>TotalPctDiv</th>\n",
       "      <th>PersPerFam</th>\n",
       "      <th>PctFam2Par</th>\n",
       "      <th>PctKids2Par</th>\n",
       "      <th>PctYoungKids2Par</th>\n",
       "      <th>PctTeen2Par</th>\n",
       "      <th>PctWorkMomYoungKids</th>\n",
       "      <th>PctWorkMom</th>\n",
       "      <th>NumIlleg</th>\n",
       "      <th>PctIlleg</th>\n",
       "      <th>NumImmig</th>\n",
       "      <th>PctImmigRecent</th>\n",
       "      <th>PctImmigRec5</th>\n",
       "      <th>PctImmigRec8</th>\n",
       "      <th>PctImmigRec10</th>\n",
       "      <th>PctRecentImmig</th>\n",
       "      <th>PctRecImmig5</th>\n",
       "      <th>PctRecImmig8</th>\n",
       "      <th>PctRecImmig10</th>\n",
       "      <th>PctSpeakEnglOnly</th>\n",
       "      <th>PctNotSpeakEnglWell</th>\n",
       "      <th>PctLargHouseFam</th>\n",
       "      <th>PctLargHouseOccup</th>\n",
       "      <th>PersPerOccupHous</th>\n",
       "      <th>PersPerOwnOccHous</th>\n",
       "      <th>PersPerRentOccHous</th>\n",
       "      <th>PctPersOwnOccup</th>\n",
       "      <th>PctPersDenseHous</th>\n",
       "      <th>PctHousLess3BR</th>\n",
       "      <th>MedNumBR</th>\n",
       "      <th>HousVacant</th>\n",
       "      <th>PctHousOccup</th>\n",
       "      <th>PctHousOwnOcc</th>\n",
       "      <th>PctVacantBoarded</th>\n",
       "      <th>PctVacMore6Mos</th>\n",
       "      <th>MedYrHousBuilt</th>\n",
       "      <th>PctHousNoPhone</th>\n",
       "      <th>PctWOFullPlumb</th>\n",
       "      <th>OwnOccLowQuart</th>\n",
       "      <th>OwnOccMedVal</th>\n",
       "      <th>OwnOccHiQuart</th>\n",
       "      <th>RentLowQ</th>\n",
       "      <th>RentMedian</th>\n",
       "      <th>RentHighQ</th>\n",
       "      <th>MedRent</th>\n",
       "      <th>MedRentPctHousInc</th>\n",
       "      <th>MedOwnCostPctInc</th>\n",
       "      <th>MedOwnCostPctIncNoMtg</th>\n",
       "      <th>NumInShelters</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alabastercity</td>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AlexanderCitycity</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Annistoncity</td>\n",
       "      <td>3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Athenscity</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Auburncity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state      communityname  fold  population  householdsize  racepctblack  \\\n",
       "0      1      Alabastercity     7        0.01           0.61          0.21   \n",
       "1      1  AlexanderCitycity    10        0.01           0.41          0.55   \n",
       "2      1       Annistoncity     3        0.03           0.34          0.86   \n",
       "3      1         Athenscity     8        0.01           0.38          0.35   \n",
       "4      1         Auburncity     1        0.04           0.37          0.32   \n",
       "\n",
       "   racePctWhite  racePctAsian  racePctHisp  agePct12t21  agePct12t29  \\\n",
       "0          0.83          0.02         0.01         0.41         0.49   \n",
       "1          0.57          0.01         0.00         0.47         0.45   \n",
       "2          0.30          0.04         0.01         0.41         0.42   \n",
       "3          0.71          0.04         0.01         0.39         0.46   \n",
       "4          0.70          0.21         0.02         1.00         1.00   \n",
       "\n",
       "   agePct16t24  agePct65up  numbUrban  pctUrban  medIncome  pctWWage  \\\n",
       "0         0.26        0.21       0.02       1.0       0.46      0.77   \n",
       "1         0.31        0.57       0.00       0.0       0.15      0.33   \n",
       "2         0.27        0.59       0.04       1.0       0.12      0.32   \n",
       "3         0.31        0.49       0.00       0.0       0.23      0.43   \n",
       "4         1.00        0.14       0.05       1.0       0.02      0.77   \n",
       "\n",
       "   pctWFarmSelf  pctWInvInc  pctWSocSec  pctWPubAsst  pctWRetire  medFamInc  \\\n",
       "0          0.23        0.38        0.22         0.16        0.22       0.42   \n",
       "1          0.13        0.27        0.65         0.41        0.45       0.21   \n",
       "2          0.19        0.28        0.67         0.52        0.57       0.18   \n",
       "3          0.48        0.36        0.53         0.41        0.44       0.29   \n",
       "4          0.57        0.47        0.13         0.11        0.16       0.32   \n",
       "\n",
       "   perCapInc  whitePerCap  blackPerCap  indianPerCap  AsianPerCap  \\\n",
       "0       0.29         0.29         0.27          0.16         0.24   \n",
       "1       0.22         0.29         0.15          0.00         0.29   \n",
       "2       0.21         0.35         0.15          0.26         0.18   \n",
       "3       0.27         0.30         0.18          0.19         0.20   \n",
       "4       0.17         0.19         0.16          0.07         0.21   \n",
       "\n",
       "   OtherPerCap  HispPerCap  NumUnderPov  PctPopUnderPov  PctLess9thGrade  \\\n",
       "0         0.38        0.26         0.01            0.14             0.27   \n",
       "1         0.00        0.14         0.02            0.45             0.57   \n",
       "2         0.84        0.33         0.06            0.65             0.48   \n",
       "3         0.00        0.80         0.02            0.38             0.51   \n",
       "4         0.14        0.22         0.11            1.00             0.18   \n",
       "\n",
       "   PctNotHSGrad  PctBSorMore  PctUnemployed  PctEmploy  PctEmplManu  \\\n",
       "0          0.37         0.39           0.12       0.69         0.27   \n",
       "1          0.70         0.21           0.27       0.43         1.00   \n",
       "2          0.58         0.28           0.79       0.22         0.44   \n",
       "3          0.59         0.32           0.37       0.43         0.64   \n",
       "4          0.18         0.82           0.42       0.23         0.19   \n",
       "\n",
       "   PctEmplProfServ  PctOccupManu  PctOccupMgmtProf  MalePctDivorce  \\\n",
       "0             0.37          0.32              0.48            0.31   \n",
       "1             0.17          0.93              0.24            0.42   \n",
       "2             0.43          0.54              0.41            0.69   \n",
       "3             0.30          0.52              0.46            0.47   \n",
       "4             1.00          0.25              0.67            0.09   \n",
       "\n",
       "   MalePctNevMarr  FemalePctDiv  TotalPctDiv  PersPerFam  PctFam2Par  \\\n",
       "0            0.20          0.35         0.34        0.56        0.81   \n",
       "1            0.32          0.54         0.52        0.46        0.48   \n",
       "2            0.36          0.67         0.71        0.42        0.28   \n",
       "3            0.31          0.42         0.46        0.43        0.63   \n",
       "4            1.00          0.16         0.13        0.38        0.55   \n",
       "\n",
       "   PctKids2Par  PctYoungKids2Par  PctTeen2Par  PctWorkMomYoungKids  \\\n",
       "0         0.79              0.97         0.82                 0.60   \n",
       "1         0.43              0.48         0.59                 0.81   \n",
       "2         0.24              0.38         0.27                 0.49   \n",
       "3         0.62              0.66         0.53                 0.51   \n",
       "4         0.53              0.59         0.54                 0.68   \n",
       "\n",
       "   PctWorkMom  NumIlleg  PctIlleg  NumImmig  PctImmigRecent  PctImmigRec5  \\\n",
       "0        0.51      0.00      0.09      0.00            0.50          0.43   \n",
       "1        0.82      0.02      0.42      0.00            0.00          0.78   \n",
       "2        0.49      0.04      0.55      0.00            0.22          0.28   \n",
       "3        0.47      0.01      0.22      0.00            0.41          0.30   \n",
       "4        0.69      0.03      0.69      0.01            1.00          0.91   \n",
       "\n",
       "   PctImmigRec8  PctImmigRec10  PctRecentImmig  PctRecImmig5  PctRecImmig8  \\\n",
       "0          0.46           0.43            0.04          0.03          0.03   \n",
       "1          0.64           0.54            0.00          0.02          0.01   \n",
       "2          0.45           0.40            0.02          0.02          0.03   \n",
       "3          0.29           0.65            0.04          0.02          0.02   \n",
       "4          0.86           0.80            0.29          0.23          0.20   \n",
       "\n",
       "   PctRecImmig10  PctSpeakEnglOnly  PctNotSpeakEnglWell  PctLargHouseFam  \\\n",
       "0           0.02              0.97                 0.01             0.17   \n",
       "1           0.01              0.98                 0.02             0.19   \n",
       "2           0.03              0.95                 0.02             0.25   \n",
       "3           0.04              0.96                 0.02             0.19   \n",
       "4           0.17              0.90                 0.05             0.14   \n",
       "\n",
       "   PctLargHouseOccup  PersPerOccupHous  PersPerOwnOccHous  PersPerRentOccHous  \\\n",
       "0               0.21              0.65               0.64                0.56   \n",
       "1               0.18              0.43               0.43                0.42   \n",
       "2               0.22              0.36               0.34                0.41   \n",
       "3               0.18              0.38               0.43                0.32   \n",
       "4               0.07              0.25               0.41                0.22   \n",
       "\n",
       "   PctPersOwnOccup  PctPersDenseHous  PctHousLess3BR  MedNumBR  HousVacant  \\\n",
       "0             0.82              0.10            0.22       0.5        0.01   \n",
       "1             0.58              0.17            0.46       0.5        0.02   \n",
       "2             0.50              0.13            0.51       0.5        0.07   \n",
       "3             0.58              0.12            0.45       0.5        0.03   \n",
       "4             0.24              0.14            0.71       0.0        0.06   \n",
       "\n",
       "   PctHousOccup  PctHousOwnOcc  PctVacantBoarded  PctVacMore6Mos  \\\n",
       "0          0.85           0.82              0.00            0.26   \n",
       "1          0.73           0.58              0.18            0.40   \n",
       "2          0.56           0.52              0.31            0.60   \n",
       "3          0.66           0.55              0.18            0.26   \n",
       "4          0.66           0.21              0.07            0.24   \n",
       "\n",
       "   MedYrHousBuilt  PctHousNoPhone  PctWOFullPlumb  OwnOccLowQuart  \\\n",
       "0            0.83            0.13            0.66            0.16   \n",
       "1            0.56            0.55            0.48            0.06   \n",
       "2            0.40            0.55            0.33            0.05   \n",
       "3            0.58            0.42            0.41            0.10   \n",
       "4            0.77            0.27            0.10            0.16   \n",
       "\n",
       "   OwnOccMedVal  OwnOccHiQuart  RentLowQ  RentMedian  RentHighQ  MedRent  \\\n",
       "0          0.15           0.13      0.13        0.23       0.25     0.28   \n",
       "1          0.06           0.08      0.02        0.07       0.08     0.09   \n",
       "2          0.07           0.09      0.02        0.09       0.13     0.13   \n",
       "3          0.10           0.12      0.08        0.14       0.15     0.15   \n",
       "4          0.16           0.18      0.18        0.21       0.26     0.21   \n",
       "\n",
       "   MedRentPctHousInc  MedOwnCostPctInc  MedOwnCostPctIncNoMtg  NumInShelters  \\\n",
       "0               0.19              0.18                   0.25           0.00   \n",
       "1               0.20              0.16                   0.36           0.00   \n",
       "2               0.41              0.38                   0.47           0.01   \n",
       "3               0.24              0.17                   0.33           0.00   \n",
       "4               1.00              0.16                   0.24           0.00   \n",
       "\n",
       "   NumStreet  PctForeignBorn  PctBornSameState  PctSameHouse85  PctSameCity85  \\\n",
       "0       0.00            0.03              0.70            0.40           0.34   \n",
       "1       0.00            0.00              0.93            0.66           0.82   \n",
       "2       0.02            0.04              0.77            0.59           0.70   \n",
       "3       0.00            0.03              0.78            0.56           0.67   \n",
       "4       0.00            0.12              0.49            0.12           0.00   \n",
       "\n",
       "   PctSameState85  LandArea  PopDens  PctUsePubTrans  LemasPctOfficDrugUn  \\\n",
       "0            0.57      0.05     0.06            0.01                  0.0   \n",
       "1            0.84      0.11     0.03            0.01                  0.0   \n",
       "2            0.64      0.06     0.11            0.04                  0.0   \n",
       "3            0.71      0.09     0.05            0.00                  0.0   \n",
       "4            0.15      0.09     0.09            0.01                  0.0   \n",
       "\n",
       "   ViolentCrimesPerPop  \n",
       "0                 0.06  \n",
       "1                 0.14  \n",
       "2                 1.00  \n",
       "3                 0.23  \n",
       "4                 0.15  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LOAD THE DATASET INTO PANDAS DATAFRAME:\n",
    "datadir = '/Users/sam/All-Program/App-DataSet/Data-Science-Projects/Crime-Prediction/communities-crime-clean.csv'\n",
    "\n",
    "crimeDF = pd.read_csv(datadir, sep=',', header='infer')\n",
    "\n",
    "# Displaying first five elements for all the columns\n",
    "print (crimeDF.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(crimeDF.head())\n",
    "    \n",
    "# Important feature variables\n",
    "nonPredictiveFeatures = ['state','communityname','fold']\n",
    "regTargetVar = ['ViolentCrimesPerPop']\n",
    "classTargetVar = ['highCrime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The cross validation Random state to be used is for all the model is;\n",
    "cv = model_selection.ShuffleSplit(n_splits=10,random_state=675) \n",
    "\n",
    "modelScores = defaultdict(list)\n",
    "modelTopFeatures = defaultdict(list)\n",
    "\n",
    "class ModelScoring():\n",
    "    \n",
    "    def __init__(self,modelName, modelObj):\n",
    "        modelScores[modelName] = []\n",
    "        modelTopFeatures[modelName] = []\n",
    "        self.modelName = modelName\n",
    "        self.model = modelObj\n",
    "        self.cv = model_selection.ShuffleSplit(n_splits=10,\n",
    "                                               random_state=675) \n",
    "        \n",
    "    def setData(self, dataIN, targetIN):\n",
    "        self.dataIN = dataIN\n",
    "        self.targetIN = targetIN\n",
    "        \n",
    "    def cvEvaluate(self, scoringMetric, cv=None):\n",
    "#         modelPerformaceMetric = OrderedDict()\n",
    "        \n",
    "        if cv:\n",
    "            self.cv = cv\n",
    "            \n",
    "        for metric in scoringMetric:\n",
    "            nFoldScore = model_selection.cross_val_score(self.model, \n",
    "                                                         self.dataIN, self.targetIN,\n",
    "                                                         cv=self.cv, \n",
    "                                                         scoring=metric)\n",
    "\n",
    "            modelScores[self.modelName].append({metric:np.mean(nFoldScore)})\n",
    "            \n",
    "    def evaluate(self, yTrue, yPred):\n",
    "        metric = metrics.precision_recall_fscore_support(yTrue, yPred)\n",
    "        modelScores[self.modelName].append({'precision':list(metric[0])})\n",
    "        modelScores[self.modelName].append({'recall':list(metric[1])})\n",
    "        modelScores[self.modelName].append({'fscore':list(metric[2])})\n",
    "    \n",
    "    def setTopFeatures(self, featureList, predictivePower):\n",
    "        for feature, weight in zip(featureList,predictivePower):\n",
    "            modelTopFeatures[self.modelName].append({feature:weight})\n",
    "    \n",
    "    \n",
    "    def getTopFeatures(self, num=5, featureWeights=None):\n",
    "        if not featureWeights:\n",
    "            featureWeights = self.model.coef_\n",
    "            \n",
    "        feauturePredictivePower = pd.DataFrame(columns=['highCrimePredictive_features',\n",
    "                                                      'high_featureWeight', 'lowCrimePredictive_features',\n",
    "                                                      'low_featureWeight'])\n",
    "\n",
    "        posTopWeight_index = featureWeights.flatten().argsort()[-num:][::-1]   # Find the indices of top most feature weights\n",
    "        negTopWeight_index = featureWeights.flatten().argsort()[:num]\n",
    "\n",
    "        posTopWeights = featureWeights.flatten()[posTopWeight_index]\n",
    "        negTopWeights = featureWeights.flatten()[negTopWeight_index]\n",
    "\n",
    "        high_CrimeFeatures = self.dataIN.columns[posTopWeight_index]\n",
    "        low_CrimeFeatures = self.dataIN.columns[negTopWeight_index]\n",
    "\n",
    "        feauturePredictivePower['highCrimePredictive_features'] = high_CrimeFeatures\n",
    "        feauturePredictivePower['high_featureWeight'] = posTopWeights\n",
    "        feauturePredictivePower['lowCrimePredictive_features'] = low_CrimeFeatures\n",
    "        feauturePredictivePower['low_featureWeight'] = negTopWeights\n",
    "#         print (high_CrimeFeatures+low_CrimeFeatures)\n",
    "#         print (posTopWeights+negTopWeights)\n",
    "        \n",
    "        self.setTopFeatures(featureList = [item for item in itertools.chain(high_CrimeFeatures, low_CrimeFeatures)], \n",
    "                            predictivePower = [item for item in itertools.chain(posTopWeights, negTopWeights)])\n",
    "        \n",
    "        return feauturePredictivePower\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1. Decision Trees:\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part (a):  Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Creating a new field “highCrime” which is true if the crime rate per capita (ViolentCrimesPerPop) is greater than 0.1, and false otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% positive:  62.7195183141\n",
      "% Negative:  37.2804816859\n"
     ]
    }
   ],
   "source": [
    "crimeDF['highCrime'] = crimeDF['ViolentCrimesPerPop'] > 0.1\n",
    "# print ('The shape after adding the classification column is; ', crimeDF.shape)\n",
    "percntgPositive = (sum(crimeDF['highCrime'] == True)/ (sum(crimeDF['highCrime'] == True) + sum(crimeDF['highCrime'] == False))) * 100\n",
    "percntgNegative = 100-percntgPositive\n",
    "print ('% positive: ',percntgPositive)\n",
    "print ('% Negative: ',percntgNegative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part (b):  Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Data Preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of dataForDT after preprocessing is:  (1993, 100)\n",
      "The shape of targetForDT after preprocessing is:  (1993,)\n",
      "[0 1 1 ..., 1 1 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>...</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "0        0.01           0.61          0.21          0.83          0.02   \n",
       "1        0.01           0.41          0.55          0.57          0.01   \n",
       "2        0.03           0.34          0.86          0.30          0.04   \n",
       "3        0.01           0.38          0.35          0.71          0.04   \n",
       "4        0.04           0.37          0.32          0.70          0.21   \n",
       "\n",
       "   racePctHisp  agePct12t21  agePct12t29  agePct16t24  agePct65up  \\\n",
       "0         0.01         0.41         0.49         0.26        0.21   \n",
       "1         0.00         0.47         0.45         0.31        0.57   \n",
       "2         0.01         0.41         0.42         0.27        0.59   \n",
       "3         0.01         0.39         0.46         0.31        0.49   \n",
       "4         0.02         1.00         1.00         1.00        0.14   \n",
       "\n",
       "          ...           NumStreet  PctForeignBorn  PctBornSameState  \\\n",
       "0         ...                0.00            0.03              0.70   \n",
       "1         ...                0.00            0.00              0.93   \n",
       "2         ...                0.02            0.04              0.77   \n",
       "3         ...                0.00            0.03              0.78   \n",
       "4         ...                0.00            0.12              0.49   \n",
       "\n",
       "   PctSameHouse85  PctSameCity85  PctSameState85  LandArea  PopDens  \\\n",
       "0            0.40           0.34            0.57      0.05     0.06   \n",
       "1            0.66           0.82            0.84      0.11     0.03   \n",
       "2            0.59           0.70            0.64      0.06     0.11   \n",
       "3            0.56           0.67            0.71      0.09     0.05   \n",
       "4            0.12           0.00            0.15      0.09     0.09   \n",
       "\n",
       "   PctUsePubTrans  LemasPctOfficDrugUn  \n",
       "0            0.01                  0.0  \n",
       "1            0.01                  0.0  \n",
       "2            0.04                  0.0  \n",
       "3            0.00                  0.0  \n",
       "4            0.01                  0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the label into proper binary labels\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "# Remove the non-predictive and the target column form the data\n",
    "dataContinuous = crimeDF.drop(nonPredictiveFeatures+regTargetVar+classTargetVar, 1)  \n",
    "# Convert the target column into binomial label vector\n",
    "targetBinomial = lb.fit_transform(crimeDF['highCrime']).flatten()      \n",
    "\n",
    "print ('The shape of dataForDT after preprocessing is: ', dataContinuous.shape)\n",
    "print ('The shape of targetForDT after preprocessing is: ', targetBinomial.shape)\n",
    "# print (dataForDT)\n",
    "print (targetBinomial)\n",
    "dataContinuous.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### i).  Training accuracy, precision, and recall for the decision tree? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'precision': [1.0, 1.0]}, {'recall': [1.0, 1.0]}, {'fscore': [1.0, 1.0]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Decision tree classifier:\n",
    "classifierDT = tree.DecisionTreeClassifier()\n",
    "classifierDT = classifierDT.fit(dataContinuous, targetBinomial)\n",
    "\n",
    "# Predict on the training Data\n",
    "predForDT = classifierDT.predict(dataContinuous)\n",
    "\n",
    "# ModelScoring\n",
    "modelName = 'Decision Tree Classifier'\n",
    "scoreObj = ModelScoring(modelName = modelName, modelObj=classifierDT)\n",
    "scoreObj.evaluate(targetBinomial,predForDT)\n",
    "modelScores[modelName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the decision tree classifier is:  1.0\n",
      "The precision of the decision tree classifier is:  1.0\n",
      "The recall of the decision tree classifier is:  1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>743</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0     1\n",
       "row_0           \n",
       "0      743     0\n",
       "1        0  1250"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Precision and Recall\n",
    "cnfMatrix = pd.crosstab(targetBinomial, predForDT)\n",
    "cnfMatrix\n",
    "tpDT =  cnfMatrix.iloc[1][1]\n",
    "tnDT =  cnfMatrix.iloc[0][0]\n",
    "fpDT =  cnfMatrix.iloc[0][1]\n",
    "fnDT =  cnfMatrix.iloc[1][0]\n",
    "print ('The accuracy of the decision tree classifier is: ', (tpDT+tnDT)/(tpDT+tnDT+fpDT+fnDT))\n",
    "print ('The precision of the decision tree classifier is: ', tpDT/(tpDT+fpDT))\n",
    "print ('The recall of the decision tree classifier is: ', tpDT/(tpDT+fnDT))\n",
    "# cnfMatrix.iloc[0][0] + cnfMatrix.iloc[1][1]/(cnfMatrix.iloc[0][0] + cnfMatrix.iloc[1][1] + cnfMatrix.iloc[0][0] + cnfMatrix.iloc[1][1])\n",
    "cnfMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### ii). Get main features  used for classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Top 10 features selected by decision tree are: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>infoGain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>PctKids2Par</td>\n",
       "      <td>0.361692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>racePctWhite</td>\n",
       "      <td>0.086461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>racePctHisp</td>\n",
       "      <td>0.045120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PctLess9thGrade</td>\n",
       "      <td>0.026243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PctEmplManu</td>\n",
       "      <td>0.021631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>PctEmploy</td>\n",
       "      <td>0.017151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>PctWOFullPlumb</td>\n",
       "      <td>0.015007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>PctHousOwnOcc</td>\n",
       "      <td>0.014166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>PctLargHouseFam</td>\n",
       "      <td>0.013989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>MedRent</td>\n",
       "      <td>0.012787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature_name  infoGain\n",
       "44      PctKids2Par  0.361692\n",
       "3      racePctWhite  0.086461\n",
       "5       racePctHisp  0.045120\n",
       "29  PctLess9thGrade  0.026243\n",
       "34      PctEmplManu  0.021631\n",
       "33        PctEmploy  0.017151\n",
       "78   PctWOFullPlumb  0.015007\n",
       "73    PctHousOwnOcc  0.014166\n",
       "62  PctLargHouseFam  0.013989\n",
       "85          MedRent  0.012787"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best Fetures: Information gain with GINI\n",
    "ImpfeatureDF = pd.DataFrame(columns=['feature_name', 'infoGain'])\n",
    "featureVec = np.array(dataContinuous.columns)\n",
    "ImpfeatureDF['feature_name'] = np.array(dataContinuous.columns)\n",
    "# print (featureVec)\n",
    "ImpfeatureDF['infoGain'] = classifierDT.feature_importances_\n",
    "\n",
    "print ('The Top 10 features selected by decision tree are: ')\n",
    "inpFeatue = ImpfeatureDF.sort_values('infoGain', ascending=False).head(10)\n",
    "\n",
    "scoreObj.setTopFeatures(inpFeatue['feature_name'], inpFeatue['infoGain'])\n",
    "inpFeatue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part (c): Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### i). 10-fold cross-validation accuracy, precision, and recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 10-Fold: Performance Metric: \n",
      " [{'accuracy': 0.77800000000000002}, {'precision': 0.80267091740113905}, {'recall': 0.84398158874977747}]\n"
     ]
    }
   ],
   "source": [
    "# import random\n",
    "# random.seed(3213)\n",
    "classifierDT = tree.DecisionTreeClassifier()\n",
    "\n",
    "modelName = 'Decision Tree cv Classifier'\n",
    "scoreOBJ = ModelScoring(modelName = modelName, modelObj = classifierDT)\n",
    "scoreOBJ.setData(dataIN=dataContinuous, targetIN=targetBinomial)\n",
    "scoreOBJ.cvEvaluate(scoringMetric=['accuracy', 'precision', 'recall'])\n",
    "\n",
    "print ('Mean 10-Fold: Performance Metric: \\n', modelScores[modelName])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2. Linear Classification:\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part (a) :-  GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### i). 10-fold cross-validation accuracy, precision, and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 10-Fold: Performance Metric: \n",
      " [{'accuracy': 0.78350000000000009}, {'precision': 0.93122871464730816}, {'recall': 0.69799123705957622}]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifierGNB = GaussianNB()\n",
    "# classifierGNB.fit()\n",
    "\n",
    "modelName = 'Gaussian Naive Bayes Classifier'\n",
    "scoreGNB = ModelScoring(modelName = modelName, modelObj = classifierGNB)\n",
    "scoreGNB.setData(dataIN=dataContinuous, targetIN=targetBinomial)\n",
    "scoreGNB.cvEvaluate(scoringMetric=['accuracy', 'precision', 'recall'])\n",
    "\n",
    "print ('Mean 10-Fold: Performance Metric: \\n', modelScores[modelName])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### ii). 10 most predictive features? This can be measured by the normalized absolute difference of means for the feature between the two classes. The larger this different, the more predictive the feature. \n",
    "\n",
    "---> The larger this difference, the more predictive the feature. Why do these make sense?\n",
    "This makes sense because each feature would have a mean value for corresponding to each class. If the difference between the mean is big, this indicates that the feature provides a very good seperation between the different class. The denominator indicates a lower standard deviation is proportional to higher predictive power. This makes sense because if the standard deviation of the two distribution (no and yes) is small then it states that datapoints are very closer to the mean. This further indicates good separation between the cluster of datapoints belonging to different class. Finally, the better/more the separation the better the feature is to classify Yes and No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>PredictivePower</th>\n",
       "      <th>NegPos-Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>PctKids2Par</td>\n",
       "      <td>0.809748</td>\n",
       "      <td>-0.809748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>PctFam2Par</td>\n",
       "      <td>0.745545</td>\n",
       "      <td>-0.745545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>racePctWhite</td>\n",
       "      <td>0.73523</td>\n",
       "      <td>-0.73523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>PctIlleg</td>\n",
       "      <td>0.709261</td>\n",
       "      <td>0.709261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>FemalePctDiv</td>\n",
       "      <td>0.693978</td>\n",
       "      <td>0.693978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TotalPctDiv</td>\n",
       "      <td>0.674645</td>\n",
       "      <td>0.674645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>PctYoungKids2Par</td>\n",
       "      <td>0.665009</td>\n",
       "      <td>-0.665009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pctWInvInc</td>\n",
       "      <td>0.661076</td>\n",
       "      <td>-0.661076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>PctTeen2Par</td>\n",
       "      <td>0.642949</td>\n",
       "      <td>-0.642949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>MalePctDivorce</td>\n",
       "      <td>0.616864</td>\n",
       "      <td>0.616864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_name PredictivePower NegPos-Coefficient\n",
       "44       PctKids2Par        0.809748          -0.809748\n",
       "43        PctFam2Par        0.745545          -0.745545\n",
       "3       racePctWhite         0.73523           -0.73523\n",
       "50          PctIlleg        0.709261           0.709261\n",
       "40      FemalePctDiv        0.693978           0.693978\n",
       "41       TotalPctDiv        0.674645           0.674645\n",
       "45  PctYoungKids2Par        0.665009          -0.665009\n",
       "15        pctWInvInc        0.661076          -0.661076\n",
       "46       PctTeen2Par        0.642949          -0.642949\n",
       "38    MalePctDivorce        0.616864           0.616864"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexClassNo = np.where(targetBinomial==0)[0]\n",
    "indexClassYes = np.where(targetBinomial==1)[0]\n",
    "# print (indexClassYes)\n",
    "\n",
    "NBfeauturePredictivePower = pd.DataFrame(columns=['feature_name','PredictivePower','NegPos-Coefficient'])\n",
    "NBfeauturePredictivePower['feature_name'] = np.array(dataContinuous.columns)\n",
    "\n",
    "for num, features in enumerate(dataContinuous.columns):\n",
    "#     print (features)\n",
    "    meanNo = np.mean(dataContinuous[features][indexClassNo])\n",
    "    meanYes = np.mean(dataContinuous[features][indexClassYes])\n",
    "    stdNo = np.std(dataContinuous[features][indexClassNo])\n",
    "    stdYes = np.std(dataContinuous[features][indexClassYes])\n",
    "    \n",
    "    predictivePower = np.abs(meanYes - meanNo)/(stdYes + stdNo)\n",
    "    negPosCoefficient = (meanYes - meanNo)/(stdYes + stdNo)\n",
    "    NBfeauturePredictivePower.ix[num, 'PredictivePower'] = predictivePower\n",
    "    NBfeauturePredictivePower.ix[num, 'NegPos-Coefficient'] = negPosCoefficient\n",
    "\n",
    "\n",
    "topFeature = NBfeauturePredictivePower.sort_values('PredictivePower', ascending=False).head(10)\n",
    "scoreGNB.setTopFeatures(topFeature['feature_name'], topFeature['NegPos-Coefficient'])\n",
    "\n",
    "topFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part (b) :-  LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### i). 10-fold cross-validation accuracy, precision, and recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 10-Fold: Performance Metric: \n",
      " [{'accuracy': 0.83900000000000008}, {'precision': 0.86434809731621909}, {'recall': 0.8739570632604845}]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "classifierSVC = LinearSVC()\n",
    "# classifierGNB.fit()\n",
    "\n",
    "modelName = 'Linear SVC Classifier'\n",
    "scoreLSVC = ModelScoring(modelName = modelName, modelObj = classifierSVC)\n",
    "scoreLSVC.setData(dataIN=dataContinuous, targetIN=targetBinomial)\n",
    "scoreLSVC.cvEvaluate(scoringMetric=['accuracy', 'precision', 'recall'])\n",
    "\n",
    "print ('Mean 10-Fold: Performance Metric: \\n', modelScores[modelName])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### ii). 10 most predictive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>absFeatureWeights</th>\n",
       "      <th>featureWeights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pctWInvInc</td>\n",
       "      <td>1.888496</td>\n",
       "      <td>-1.888496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>PersPerOccupHous</td>\n",
       "      <td>1.755124</td>\n",
       "      <td>1.755124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>racePctWhite</td>\n",
       "      <td>1.500217</td>\n",
       "      <td>-1.500217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>PctKids2Par</td>\n",
       "      <td>1.190337</td>\n",
       "      <td>-1.190337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>RentHighQ</td>\n",
       "      <td>1.066904</td>\n",
       "      <td>1.066904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>MalePctDivorce</td>\n",
       "      <td>1.065695</td>\n",
       "      <td>1.065695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NumUnderPov</td>\n",
       "      <td>1.051554</td>\n",
       "      <td>1.051554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>NumStreet</td>\n",
       "      <td>1.019158</td>\n",
       "      <td>1.019158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>PctOccupMgmtProf</td>\n",
       "      <td>1.014675</td>\n",
       "      <td>1.014675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>population</td>\n",
       "      <td>1.002296</td>\n",
       "      <td>1.002296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_name  absFeatureWeights  featureWeights\n",
       "15        pctWInvInc           1.888496       -1.888496\n",
       "64  PersPerOccupHous           1.755124        1.755124\n",
       "3       racePctWhite           1.500217       -1.500217\n",
       "44       PctKids2Par           1.190337       -1.190337\n",
       "84         RentHighQ           1.066904        1.066904\n",
       "38    MalePctDivorce           1.065695        1.065695\n",
       "27       NumUnderPov           1.051554        1.051554\n",
       "90         NumStreet           1.019158        1.019158\n",
       "37  PctOccupMgmtProf           1.014675        1.014675\n",
       "0         population           1.002296        1.002296"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierSVC.fit(dataContinuous, targetBinomial)\n",
    "\n",
    "SVCfeauturePredictivePower = pd.DataFrame(columns=['feature_name','absFeatureWeights', 'featureWeights'])\n",
    "SVCfeauturePredictivePower['feature_name'] = np.array(dataContinuous.columns)\n",
    "SVCfeauturePredictivePower['absFeatureWeights'] = np.abs(classifierSVC.coef_).flatten()\n",
    "SVCfeauturePredictivePower['featureWeights'] = classifierSVC.coef_.flatten()\n",
    "topFeatures = SVCfeauturePredictivePower.sort_values('absFeatureWeights', ascending=False).head(10)\n",
    "\n",
    "scoreLSVC.setTopFeatures(topFeatures['feature_name'], topFeatures['featureWeights'])\n",
    "\n",
    "topFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3. Regression:\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part (a) : Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### i). 10-fold cross-validation, mean-squared-error (MSE) of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 10-fold CV negative MSE: \n",
      " [{'neg_mean_squared_error': -0.018922277595922486}]\n"
     ]
    }
   ],
   "source": [
    "# Load the data to fit linear model, To fit the linear model the data would be the same, however the target would change to continuous Variable\n",
    "# Remove the non-predictive and the target column form the data\n",
    "targetContinuous = crimeDF[regTargetVar]\n",
    "\n",
    "# Fit a linear model for cross vlidation:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "classifierLR = LinearRegression()\n",
    "\n",
    "modelName='Linear Regression Classifier'\n",
    "scoreLR = ModelScoring(modelName = modelName, modelObj = classifierLR)\n",
    "scoreLR.setData(dataIN=dataContinuous, targetIN=targetContinuous)\n",
    "scoreLR.cvEvaluate(scoringMetric=['neg_mean_squared_error'])\n",
    "\n",
    "print ('Mean 10-fold CV negative MSE: \\n', modelScores[modelName])\n",
    "\n",
    "# The mean squared error is ~ 0.019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### ii). MSE on the training set (train on all the data then test on it all)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE- train/test on same data: \n",
      " 0.0165167748803\n"
     ]
    }
   ],
   "source": [
    "classifierLR.fit(dataContinuous, targetContinuous)\n",
    "predictContinuousLR = classifierLR.predict(dataContinuous).flatten()\n",
    "mseLR = metrics.mean_squared_error(targetContinuous, predictContinuousLR)\n",
    "\n",
    "print ('MSE- train/test on same data: \\n', mseLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### iii). Features that are most predictive of a high crime rate? A low crime rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 feature predictive of high crime and low crime are: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>highCrimePredictive_features</th>\n",
       "      <th>high_featureWeight</th>\n",
       "      <th>lowCrimePredictive_features</th>\n",
       "      <th>low_featureWeight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PersPerOccupHous</td>\n",
       "      <td>0.635088</td>\n",
       "      <td>PctPersOwnOccup</td>\n",
       "      <td>-0.675694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PctHousOwnOcc</td>\n",
       "      <td>0.568133</td>\n",
       "      <td>TotalPctDiv</td>\n",
       "      <td>-0.561924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MalePctDivorce</td>\n",
       "      <td>0.458517</td>\n",
       "      <td>whitePerCap</td>\n",
       "      <td>-0.351016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PctRecImmig8</td>\n",
       "      <td>0.432511</td>\n",
       "      <td>PctKids2Par</td>\n",
       "      <td>-0.322651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MedRent</td>\n",
       "      <td>0.372728</td>\n",
       "      <td>OwnOccLowQuart</td>\n",
       "      <td>-0.308170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>medFamInc</td>\n",
       "      <td>0.287979</td>\n",
       "      <td>numbUrban</td>\n",
       "      <td>-0.296443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PctEmploy</td>\n",
       "      <td>0.248474</td>\n",
       "      <td>PersPerRentOccHous</td>\n",
       "      <td>-0.254572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MalePctNevMarr</td>\n",
       "      <td>0.226728</td>\n",
       "      <td>RentLowQ</td>\n",
       "      <td>-0.234752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PctPersDenseHous</td>\n",
       "      <td>0.214353</td>\n",
       "      <td>agePct12t29</td>\n",
       "      <td>-0.229218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OwnOccMedVal</td>\n",
       "      <td>0.212876</td>\n",
       "      <td>PctRecImmig5</td>\n",
       "      <td>-0.218221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  highCrimePredictive_features  high_featureWeight  \\\n",
       "0             PersPerOccupHous            0.635088   \n",
       "1                PctHousOwnOcc            0.568133   \n",
       "2               MalePctDivorce            0.458517   \n",
       "3                 PctRecImmig8            0.432511   \n",
       "4                      MedRent            0.372728   \n",
       "5                    medFamInc            0.287979   \n",
       "6                    PctEmploy            0.248474   \n",
       "7               MalePctNevMarr            0.226728   \n",
       "8             PctPersDenseHous            0.214353   \n",
       "9                 OwnOccMedVal            0.212876   \n",
       "\n",
       "  lowCrimePredictive_features  low_featureWeight  \n",
       "0             PctPersOwnOccup          -0.675694  \n",
       "1                 TotalPctDiv          -0.561924  \n",
       "2                 whitePerCap          -0.351016  \n",
       "3                 PctKids2Par          -0.322651  \n",
       "4              OwnOccLowQuart          -0.308170  \n",
       "5                   numbUrban          -0.296443  \n",
       "6          PersPerRentOccHous          -0.254572  \n",
       "7                    RentLowQ          -0.234752  \n",
       "8                 agePct12t29          -0.229218  \n",
       "9                PctRecImmig5          -0.218221  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topFeatureDF = scoreLR.getTopFeatures(num=10)\n",
    "print ('Top 10 feature predictive of high crime and low crime are: \\n')\n",
    "topFeatureDF.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part (b) : Ridge Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### i). MSE of the model under 10-fold CV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The negative MSE of of 10-fold crossvalidation is : \n",
      " [{'neg_mean_squared_error': -0.018581731506130121}]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "alpha = np.array([10, 1, 0.1, 0.01, 0.001], dtype='float64')\n",
    "\n",
    "classifierRR = RidgeCV(alpha)\n",
    "\n",
    "modelName='Ridge Regression Classifier'\n",
    "scoreOBJ = ModelScoring(modelName = modelName, modelObj = classifierRR)\n",
    "scoreOBJ.setData(dataIN=dataContinuous, targetIN=targetContinuous)\n",
    "scoreOBJ.cvEvaluate(scoringMetric=['neg_mean_squared_error'])\n",
    "\n",
    "print ('The negative MSE of of 10-fold crossvalidation is : \\n', modelScores[modelName])\n",
    "\n",
    "# The MSE of teh RIDGE model under 10-fold cv is ~ 0.01858"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### ii). MSE on the training set (train on all the data then test on it all)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE for the Ridge Regression model with default parameter setting is : \n",
      " 0.0167635291552\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# classifierRR = Ridge()\n",
    "classifierRR = classifierRR.fit(dataContinuous, targetContinuous)\n",
    "predictionContinuousRR = classifierRR.predict(dataContinuous)\n",
    "\n",
    "mseRR = metrics.mean_squared_error(targetContinuous, predictionContinuousRR)\n",
    "\n",
    "print ('The MSE for the Ridge Regression model with default parameter setting is : \\n', mseRR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Alpha for Ridge Regression is: \n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "classifierRR.fit(dataContinuous, targetContinuous)\n",
    "print ('The best Alpha for Ridge Regression is: \\n', classifierRR.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Part (c) : Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### i). MSE of the model under 10-fold CV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the 2nd order dataset is:  (1993, 5150)\n",
      "\n",
      "MSE - Poly Ridge Regression - 10 Fold cv: \n",
      " [{'neg_mean_squared_error': -0.017610408756280137}]\n",
      "\n",
      "MSE - Poly Linear Regression - 10 Fold cv: \n",
      " [{'neg_mean_squared_error': -0.10072704067305278}]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Get the Polynomial Features Data\n",
    "classifierPR = PolynomialFeatures(degree=2, include_bias=False)\n",
    "dataContinuousPoly = classifierPR.fit_transform(dataContinuous)\n",
    "print ('The shape of the 2nd order dataset is: ', dataContinuousPoly.shape)\n",
    "\n",
    "######## Ridge Regression with Polynomial Features\n",
    "classifierRR_Poly = RidgeCV(alpha)\n",
    "modelName='Poly Ridge Regression Classifier'\n",
    "scorePRR = ModelScoring(modelName = modelName, modelObj = classifierRR_Poly)\n",
    "scorePRR.setData(dataIN=dataContinuousPoly, targetIN=targetContinuous)\n",
    "scorePRR.cvEvaluate(scoringMetric=['neg_mean_squared_error'])\n",
    "\n",
    "print ('\\nMSE - Poly Ridge Regression - 10 Fold cv: \\n', modelScores[modelName])\n",
    "\n",
    "######## Linear Regression with Polynomial Features\n",
    "classifierLR_poly = LinearRegression()\n",
    "modelName='Poly Linear Regression Classifier'\n",
    "scorePLR = ModelScoring(modelName = modelName, modelObj = classifierLR_poly)\n",
    "scorePLR.setData(dataIN=dataContinuousPoly, targetIN=targetContinuous)\n",
    "scorePLR.cvEvaluate(scoringMetric=['neg_mean_squared_error'])\n",
    "\n",
    "print ('\\nMSE - Poly Linear Regression - 10 Fold cv: \\n', modelScores[modelName])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### ii). MSE on the training set (train on all the data then test on it all)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE - POLY- Linear Regression Train/Test on same - 10 Fold cv: \n",
      " 1.09352811987e-28\n",
      "\n",
      "MSE - POLY- RIDGE Regression Train/Test on same - 10 Fold cv: \n",
      " 0.0122517620613\n"
     ]
    }
   ],
   "source": [
    "######## Linear Regression with Polnomical features\n",
    "classifierLR_poly.fit(dataContinuousPoly, targetContinuous)\n",
    "predictContinuousLR_poly = classifierLR_poly.predict(dataContinuousPoly).flatten()\n",
    "\n",
    "mseLR_poly = metrics.mean_squared_error(targetContinuous, predictContinuousLR_poly)\n",
    "\n",
    "print ('MSE - POLY- Linear Regression Train/Test on same - 10 Fold cv: \\n', mseLR_poly)\n",
    "\n",
    "\n",
    "######## Ridge Regression with Polnomical features\n",
    "classifierRR_Poly.fit(dataContinuousPoly, targetContinuous)\n",
    "predictContinuousRR_poly = classifierRR_Poly.predict(dataContinuousPoly).flatten()\n",
    "\n",
    "mseRR_poly = metrics.mean_squared_error(targetContinuous, predictContinuousRR_poly)\n",
    "\n",
    "print ('\\nMSE - POLY- RIDGE Regression Train/Test on same - 10 Fold cv: \\n', mseRR_poly)\n",
    "\n",
    "\n",
    "# MSE - Train/Test on Train Data Poly Linear Regression - 10 Fold cv: \n",
    "#  1.09352811987e-28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Dirty Data\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part (a):  Decision tree learning question for the full (non-clean) data \n",
    "\n",
    "Clean Data: mean 10-fold Accuracy = 0.778, mean 10-fold Precision = 0.8026709175 and mean 10-fold Recall = 0.84398158875\n",
    "\n",
    "Dirty Data: mean 10-fold Accuracy = 0.752, mean 10-fold Precision = 0.8111893246 and mean 10-fold Recall = 0.810008320515.\n",
    "\n",
    "Comparing the performaces of the decision tree modeled on the dirty data, we see that the accuracy and recall decreases by approximately by 2-3% and the precision increases by 1%, all which are not a very big difference. Since we add a lot of features in the dirty data, we increase the dimensionality which affect the model performance (the curse of dimensionality) and hence the model is more prone to overfit. Hence the slight lower performance in the model with the dirty data.\n",
    "\n",
    "Pruning Tree:  The columns with missing values can be thought as not significant because when we fit the dirty data we get a lower accuracy, precision and recall. When we remove these columns (clean data) the performance improves. \n",
    "\n",
    "Missing Values Analysis: Overall, the missing data could be thaught to induce overfitting into the model because the performance of the model depletes. For further analysis, we find the distribution of the violentCrime columns to all the columns that have missing value. The distribution table can be seen below. As we can see that the distribution is exactly the same for all the column with missing value, this cannot be just by chance. Hence we can say that the values are missing not at random.\n",
    "\n",
    "Also, the distribution is (violentCrimes=0.573731, nonViolent=crimes=0.426269)  which is not very far from the actual distibution of the label column which is (violentCrimes=62.72 and nonViolent-crimes=37.28). This is also a reason that we dont see a lot of change in the two decision tree model build with clean data and dirty data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1994, 128)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>community</th>\n",
       "      <th>communityname</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>numbUrban</th>\n",
       "      <th>pctUrban</th>\n",
       "      <th>medIncome</th>\n",
       "      <th>pctWWage</th>\n",
       "      <th>pctWFarmSelf</th>\n",
       "      <th>pctWInvInc</th>\n",
       "      <th>pctWSocSec</th>\n",
       "      <th>pctWPubAsst</th>\n",
       "      <th>pctWRetire</th>\n",
       "      <th>medFamInc</th>\n",
       "      <th>perCapInc</th>\n",
       "      <th>whitePerCap</th>\n",
       "      <th>blackPerCap</th>\n",
       "      <th>indianPerCap</th>\n",
       "      <th>AsianPerCap</th>\n",
       "      <th>OtherPerCap</th>\n",
       "      <th>HispPerCap</th>\n",
       "      <th>NumUnderPov</th>\n",
       "      <th>PctPopUnderPov</th>\n",
       "      <th>PctLess9thGrade</th>\n",
       "      <th>PctNotHSGrad</th>\n",
       "      <th>PctBSorMore</th>\n",
       "      <th>PctUnemployed</th>\n",
       "      <th>PctEmploy</th>\n",
       "      <th>PctEmplManu</th>\n",
       "      <th>PctEmplProfServ</th>\n",
       "      <th>PctOccupManu</th>\n",
       "      <th>PctOccupMgmtProf</th>\n",
       "      <th>MalePctDivorce</th>\n",
       "      <th>MalePctNevMarr</th>\n",
       "      <th>FemalePctDiv</th>\n",
       "      <th>TotalPctDiv</th>\n",
       "      <th>PersPerFam</th>\n",
       "      <th>PctFam2Par</th>\n",
       "      <th>PctKids2Par</th>\n",
       "      <th>PctYoungKids2Par</th>\n",
       "      <th>PctTeen2Par</th>\n",
       "      <th>PctWorkMomYoungKids</th>\n",
       "      <th>PctWorkMom</th>\n",
       "      <th>NumIlleg</th>\n",
       "      <th>PctIlleg</th>\n",
       "      <th>NumImmig</th>\n",
       "      <th>PctImmigRecent</th>\n",
       "      <th>PctImmigRec5</th>\n",
       "      <th>PctImmigRec8</th>\n",
       "      <th>PctImmigRec10</th>\n",
       "      <th>PctRecentImmig</th>\n",
       "      <th>PctRecImmig5</th>\n",
       "      <th>PctRecImmig8</th>\n",
       "      <th>PctRecImmig10</th>\n",
       "      <th>PctSpeakEnglOnly</th>\n",
       "      <th>PctNotSpeakEnglWell</th>\n",
       "      <th>PctLargHouseFam</th>\n",
       "      <th>PctLargHouseOccup</th>\n",
       "      <th>PersPerOccupHous</th>\n",
       "      <th>PersPerOwnOccHous</th>\n",
       "      <th>PersPerRentOccHous</th>\n",
       "      <th>PctPersOwnOccup</th>\n",
       "      <th>PctPersDenseHous</th>\n",
       "      <th>PctHousLess3BR</th>\n",
       "      <th>MedNumBR</th>\n",
       "      <th>HousVacant</th>\n",
       "      <th>PctHousOccup</th>\n",
       "      <th>PctHousOwnOcc</th>\n",
       "      <th>PctVacantBoarded</th>\n",
       "      <th>PctVacMore6Mos</th>\n",
       "      <th>MedYrHousBuilt</th>\n",
       "      <th>PctHousNoPhone</th>\n",
       "      <th>PctWOFullPlumb</th>\n",
       "      <th>OwnOccLowQuart</th>\n",
       "      <th>OwnOccMedVal</th>\n",
       "      <th>OwnOccHiQuart</th>\n",
       "      <th>RentLowQ</th>\n",
       "      <th>RentMedian</th>\n",
       "      <th>RentHighQ</th>\n",
       "      <th>MedRent</th>\n",
       "      <th>MedRentPctHousInc</th>\n",
       "      <th>MedOwnCostPctInc</th>\n",
       "      <th>MedOwnCostPctIncNoMtg</th>\n",
       "      <th>NumInShelters</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LemasSwornFT</th>\n",
       "      <th>LemasSwFTPerPop</th>\n",
       "      <th>LemasSwFTFieldOps</th>\n",
       "      <th>LemasSwFTFieldPerPop</th>\n",
       "      <th>LemasTotalReq</th>\n",
       "      <th>LemasTotReqPerPop</th>\n",
       "      <th>PolicReqPerOffic</th>\n",
       "      <th>PolicPerPop</th>\n",
       "      <th>RacialMatchCommPol</th>\n",
       "      <th>PctPolicWhite</th>\n",
       "      <th>PctPolicBlack</th>\n",
       "      <th>PctPolicHisp</th>\n",
       "      <th>PctPolicAsian</th>\n",
       "      <th>PctPolicMinor</th>\n",
       "      <th>OfficAssgnDrugUnits</th>\n",
       "      <th>NumKindsDrugsSeiz</th>\n",
       "      <th>PolicAveOTWorked</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>PolicCars</th>\n",
       "      <th>PolicOperBudg</th>\n",
       "      <th>LemasPctPolicOnPatr</th>\n",
       "      <th>LemasGangUnitDeploy</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>PolicBudgPerPop</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Lakewoodcity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Tukwilacity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Aberdeentown</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>81440</td>\n",
       "      <td>Willingborotownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>95</td>\n",
       "      <td>6096</td>\n",
       "      <td>Bethlehemtownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state county community        communityname  fold  population  \\\n",
       "0      8      ?         ?         Lakewoodcity     1        0.19   \n",
       "1     53      ?         ?          Tukwilacity     1        0.00   \n",
       "2     24      ?         ?         Aberdeentown     1        0.00   \n",
       "3     34      5     81440  Willingborotownship     1        0.04   \n",
       "4     42     95      6096    Bethlehemtownship     1        0.01   \n",
       "\n",
       "   householdsize  racepctblack  racePctWhite  racePctAsian  racePctHisp  \\\n",
       "0           0.33          0.02          0.90          0.12         0.17   \n",
       "1           0.16          0.12          0.74          0.45         0.07   \n",
       "2           0.42          0.49          0.56          0.17         0.04   \n",
       "3           0.77          1.00          0.08          0.12         0.10   \n",
       "4           0.55          0.02          0.95          0.09         0.05   \n",
       "\n",
       "   agePct12t21  agePct12t29  agePct16t24  agePct65up  numbUrban  pctUrban  \\\n",
       "0         0.34         0.47         0.29        0.32       0.20       1.0   \n",
       "1         0.26         0.59         0.35        0.27       0.02       1.0   \n",
       "2         0.39         0.47         0.28        0.32       0.00       0.0   \n",
       "3         0.51         0.50         0.34        0.21       0.06       1.0   \n",
       "4         0.38         0.38         0.23        0.36       0.02       0.9   \n",
       "\n",
       "   medIncome  pctWWage  pctWFarmSelf  pctWInvInc  pctWSocSec  pctWPubAsst  \\\n",
       "0       0.37      0.72          0.34        0.60        0.29         0.15   \n",
       "1       0.31      0.72          0.11        0.45        0.25         0.29   \n",
       "2       0.30      0.58          0.19        0.39        0.38         0.40   \n",
       "3       0.58      0.89          0.21        0.43        0.36         0.20   \n",
       "4       0.50      0.72          0.16        0.68        0.44         0.11   \n",
       "\n",
       "   pctWRetire  medFamInc  perCapInc  whitePerCap  blackPerCap  indianPerCap  \\\n",
       "0        0.43       0.39       0.40         0.39         0.32          0.27   \n",
       "1        0.39       0.29       0.37         0.38         0.33          0.16   \n",
       "2        0.84       0.28       0.27         0.29         0.27          0.07   \n",
       "3        0.82       0.51       0.36         0.40         0.39          0.16   \n",
       "4        0.71       0.46       0.43         0.41         0.28          0.00   \n",
       "\n",
       "   AsianPerCap OtherPerCap  HispPerCap  NumUnderPov  PctPopUnderPov  \\\n",
       "0         0.27        0.36        0.41         0.08            0.19   \n",
       "1         0.30        0.22        0.35         0.01            0.24   \n",
       "2         0.29        0.28        0.39         0.01            0.27   \n",
       "3         0.25        0.36        0.44         0.01            0.10   \n",
       "4         0.74        0.51        0.48         0.00            0.06   \n",
       "\n",
       "   PctLess9thGrade  PctNotHSGrad  PctBSorMore  PctUnemployed  PctEmploy  \\\n",
       "0             0.10          0.18         0.48           0.27       0.68   \n",
       "1             0.14          0.24         0.30           0.27       0.73   \n",
       "2             0.27          0.43         0.19           0.36       0.58   \n",
       "3             0.09          0.25         0.31           0.33       0.71   \n",
       "4             0.25          0.30         0.33           0.12       0.65   \n",
       "\n",
       "   PctEmplManu  PctEmplProfServ  PctOccupManu  PctOccupMgmtProf  \\\n",
       "0         0.23             0.41          0.25              0.52   \n",
       "1         0.57             0.15          0.42              0.36   \n",
       "2         0.32             0.29          0.49              0.32   \n",
       "3         0.36             0.45          0.37              0.39   \n",
       "4         0.67             0.38          0.42              0.46   \n",
       "\n",
       "   MalePctDivorce  MalePctNevMarr  FemalePctDiv  TotalPctDiv  PersPerFam  \\\n",
       "0            0.68            0.40          0.75         0.75        0.35   \n",
       "1            1.00            0.63          0.91         1.00        0.29   \n",
       "2            0.63            0.41          0.71         0.70        0.45   \n",
       "3            0.34            0.45          0.49         0.44        0.75   \n",
       "4            0.22            0.27          0.20         0.21        0.51   \n",
       "\n",
       "   PctFam2Par  PctKids2Par  PctYoungKids2Par  PctTeen2Par  \\\n",
       "0        0.55         0.59              0.61         0.56   \n",
       "1        0.43         0.47              0.60         0.39   \n",
       "2        0.42         0.44              0.43         0.43   \n",
       "3        0.65         0.54              0.83         0.65   \n",
       "4        0.91         0.91              0.89         0.85   \n",
       "\n",
       "   PctWorkMomYoungKids  PctWorkMom  NumIlleg  PctIlleg  NumImmig  \\\n",
       "0                 0.74        0.76      0.04      0.14      0.03   \n",
       "1                 0.46        0.53      0.00      0.24      0.01   \n",
       "2                 0.71        0.67      0.01      0.46      0.00   \n",
       "3                 0.85        0.86      0.03      0.33      0.02   \n",
       "4                 0.40        0.60      0.00      0.06      0.00   \n",
       "\n",
       "   PctImmigRecent  PctImmigRec5  PctImmigRec8  PctImmigRec10  PctRecentImmig  \\\n",
       "0            0.24          0.27          0.37           0.39            0.07   \n",
       "1            0.52          0.62          0.64           0.63            0.25   \n",
       "2            0.07          0.06          0.15           0.19            0.02   \n",
       "3            0.11          0.20          0.30           0.31            0.05   \n",
       "4            0.03          0.07          0.20           0.27            0.01   \n",
       "\n",
       "   PctRecImmig5  PctRecImmig8  PctRecImmig10  PctSpeakEnglOnly  \\\n",
       "0          0.07          0.08           0.08              0.89   \n",
       "1          0.27          0.25           0.23              0.84   \n",
       "2          0.02          0.04           0.05              0.88   \n",
       "3          0.08          0.11           0.11              0.81   \n",
       "4          0.02          0.04           0.05              0.88   \n",
       "\n",
       "   PctNotSpeakEnglWell  PctLargHouseFam  PctLargHouseOccup  PersPerOccupHous  \\\n",
       "0                 0.06             0.14               0.13              0.33   \n",
       "1                 0.10             0.16               0.10              0.17   \n",
       "2                 0.04             0.20               0.20              0.46   \n",
       "3                 0.08             0.56               0.62              0.85   \n",
       "4                 0.05             0.16               0.19              0.59   \n",
       "\n",
       "   PersPerOwnOccHous  PersPerRentOccHous  PctPersOwnOccup  PctPersDenseHous  \\\n",
       "0               0.39                0.28             0.55              0.09   \n",
       "1               0.29                0.17             0.26              0.20   \n",
       "2               0.52                0.43             0.42              0.15   \n",
       "3               0.77                1.00             0.94              0.12   \n",
       "4               0.60                0.37             0.89              0.02   \n",
       "\n",
       "   PctHousLess3BR  MedNumBR  HousVacant  PctHousOccup  PctHousOwnOcc  \\\n",
       "0            0.51       0.5        0.21          0.71           0.52   \n",
       "1            0.82       0.0        0.02          0.79           0.24   \n",
       "2            0.51       0.5        0.01          0.86           0.41   \n",
       "3            0.01       0.5        0.01          0.97           0.96   \n",
       "4            0.19       0.5        0.01          0.89           0.87   \n",
       "\n",
       "   PctVacantBoarded  PctVacMore6Mos  MedYrHousBuilt  PctHousNoPhone  \\\n",
       "0              0.05            0.26            0.65            0.14   \n",
       "1              0.02            0.25            0.65            0.16   \n",
       "2              0.29            0.30            0.52            0.47   \n",
       "3              0.60            0.47            0.52            0.11   \n",
       "4              0.04            0.55            0.73            0.05   \n",
       "\n",
       "   PctWOFullPlumb  OwnOccLowQuart  OwnOccMedVal  OwnOccHiQuart  RentLowQ  \\\n",
       "0            0.06            0.22          0.19           0.18      0.36   \n",
       "1            0.00            0.21          0.20           0.21      0.42   \n",
       "2            0.45            0.18          0.17           0.16      0.27   \n",
       "3            0.11            0.24          0.21           0.19      0.75   \n",
       "4            0.14            0.31          0.31           0.30      0.40   \n",
       "\n",
       "   RentMedian  RentHighQ  MedRent  MedRentPctHousInc  MedOwnCostPctInc  \\\n",
       "0        0.35       0.38     0.34               0.38              0.46   \n",
       "1        0.38       0.40     0.37               0.29              0.32   \n",
       "2        0.29       0.27     0.31               0.48              0.39   \n",
       "3        0.70       0.77     0.89               0.63              0.51   \n",
       "4        0.36       0.38     0.38               0.22              0.51   \n",
       "\n",
       "   MedOwnCostPctIncNoMtg  NumInShelters  NumStreet  PctForeignBorn  \\\n",
       "0                   0.25           0.04        0.0            0.12   \n",
       "1                   0.18           0.00        0.0            0.21   \n",
       "2                   0.28           0.00        0.0            0.14   \n",
       "3                   0.47           0.00        0.0            0.19   \n",
       "4                   0.21           0.00        0.0            0.11   \n",
       "\n",
       "   PctBornSameState  PctSameHouse85  PctSameCity85  PctSameState85  \\\n",
       "0              0.42            0.50           0.51            0.64   \n",
       "1              0.50            0.34           0.60            0.52   \n",
       "2              0.49            0.54           0.67            0.56   \n",
       "3              0.30            0.73           0.64            0.65   \n",
       "4              0.72            0.64           0.61            0.53   \n",
       "\n",
       "  LemasSwornFT LemasSwFTPerPop LemasSwFTFieldOps LemasSwFTFieldPerPop  \\\n",
       "0         0.03            0.13              0.96                 0.17   \n",
       "1            ?               ?                 ?                    ?   \n",
       "2            ?               ?                 ?                    ?   \n",
       "3            ?               ?                 ?                    ?   \n",
       "4            ?               ?                 ?                    ?   \n",
       "\n",
       "  LemasTotalReq LemasTotReqPerPop PolicReqPerOffic PolicPerPop  \\\n",
       "0          0.06              0.18             0.44        0.13   \n",
       "1             ?                 ?                ?           ?   \n",
       "2             ?                 ?                ?           ?   \n",
       "3             ?                 ?                ?           ?   \n",
       "4             ?                 ?                ?           ?   \n",
       "\n",
       "  RacialMatchCommPol PctPolicWhite PctPolicBlack PctPolicHisp PctPolicAsian  \\\n",
       "0               0.94          0.93          0.03         0.07           0.1   \n",
       "1                  ?             ?             ?            ?             ?   \n",
       "2                  ?             ?             ?            ?             ?   \n",
       "3                  ?             ?             ?            ?             ?   \n",
       "4                  ?             ?             ?            ?             ?   \n",
       "\n",
       "  PctPolicMinor OfficAssgnDrugUnits NumKindsDrugsSeiz PolicAveOTWorked  \\\n",
       "0          0.07                0.02              0.57             0.29   \n",
       "1             ?                   ?                 ?                ?   \n",
       "2             ?                   ?                 ?                ?   \n",
       "3             ?                   ?                 ?                ?   \n",
       "4             ?                   ?                 ?                ?   \n",
       "\n",
       "   LandArea  PopDens  PctUsePubTrans PolicCars PolicOperBudg  \\\n",
       "0      0.12     0.26            0.20      0.06          0.04   \n",
       "1      0.02     0.12            0.45         ?             ?   \n",
       "2      0.01     0.21            0.02         ?             ?   \n",
       "3      0.02     0.39            0.28         ?             ?   \n",
       "4      0.04     0.09            0.02         ?             ?   \n",
       "\n",
       "  LemasPctPolicOnPatr LemasGangUnitDeploy  LemasPctOfficDrugUn  \\\n",
       "0                 0.9                 0.5                 0.32   \n",
       "1                   ?                   ?                 0.00   \n",
       "2                   ?                   ?                 0.00   \n",
       "3                   ?                   ?                 0.00   \n",
       "4                   ?                   ?                 0.00   \n",
       "\n",
       "  PolicBudgPerPop  ViolentCrimesPerPop  \n",
       "0            0.14                 0.20  \n",
       "1               ?                 0.67  \n",
       "2               ?                 0.43  \n",
       "3               ?                 0.12  \n",
       "4               ?                 0.03  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datadir = '/Users/sam/All-Program/App-DataSet/Data-Science-Projects/Crime-Prediction/communities-crime-full.csv'\n",
    "\n",
    "crimeDF_dirty = pd.read_csv(datadir, header='infer', sep=',')\n",
    "\n",
    "print (crimeDF_dirty.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(crimeDF_dirty.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of dataForDT after preprocessing is:  (1994, 122)\n",
      "The shape of targetForDT after preprocessing is:  (1994,)\n",
      "[1 1 1 ..., 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>...</th>\n",
       "      <th>PolicAveOTWorked</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>PolicCars</th>\n",
       "      <th>PolicOperBudg</th>\n",
       "      <th>LemasPctPolicOnPatr</th>\n",
       "      <th>LemasGangUnitDeploy</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>PolicBudgPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.21</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "0        0.19           0.33          0.02          0.90          0.12   \n",
       "1        0.00           0.16          0.12          0.74          0.45   \n",
       "2        0.00           0.42          0.49          0.56          0.17   \n",
       "3        0.04           0.77          1.00          0.08          0.12   \n",
       "4        0.01           0.55          0.02          0.95          0.09   \n",
       "\n",
       "   racePctHisp  agePct12t21  agePct12t29  agePct16t24  agePct65up  \\\n",
       "0         0.17         0.34         0.47         0.29        0.32   \n",
       "1         0.07         0.26         0.59         0.35        0.27   \n",
       "2         0.04         0.39         0.47         0.28        0.32   \n",
       "3         0.10         0.51         0.50         0.34        0.21   \n",
       "4         0.05         0.38         0.38         0.23        0.36   \n",
       "\n",
       "        ...         PolicAveOTWorked  LandArea  PopDens  PctUsePubTrans  \\\n",
       "0       ...                     0.29      0.12     0.26            0.20   \n",
       "1       ...                        ?      0.02     0.12            0.45   \n",
       "2       ...                        ?      0.01     0.21            0.02   \n",
       "3       ...                        ?      0.02     0.39            0.28   \n",
       "4       ...                        ?      0.04     0.09            0.02   \n",
       "\n",
       "   PolicCars  PolicOperBudg  LemasPctPolicOnPatr  LemasGangUnitDeploy  \\\n",
       "0       0.06           0.04                  0.9                  0.5   \n",
       "1          ?              ?                    ?                    ?   \n",
       "2          ?              ?                    ?                    ?   \n",
       "3          ?              ?                    ?                    ?   \n",
       "4          ?              ?                    ?                    ?   \n",
       "\n",
       "   LemasPctOfficDrugUn  PolicBudgPerPop  \n",
       "0                 0.32             0.14  \n",
       "1                 0.00                ?  \n",
       "2                 0.00                ?  \n",
       "3                 0.00                ?  \n",
       "4                 0.00                ?  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonPredictiveFeatures = ['state','county','community', 'communityname','fold']\n",
    "regTargetVar = ['ViolentCrimesPerPop']\n",
    "classTargetVar = ['highCrime']\n",
    "\n",
    "# Convert the lebel form continuous to discrete\n",
    "crimeDF_dirty['highCrime'] = crimeDF_dirty['ViolentCrimesPerPop'] > 0.1\n",
    "\n",
    "crimeDF_dirty.head()\n",
    "\n",
    "# converting the label into proper binary labels\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "# # Remove the non-predictive and the target column form the data\n",
    "dataContinuous_dirty = crimeDF_dirty.drop(nonPredictiveFeatures+regTargetVar+classTargetVar, 1)  \n",
    "# # Convert the target column into binomial label vector\n",
    "targetBinomial_dirty = lb.fit_transform(crimeDF_dirty['highCrime']).flatten()      \n",
    "\n",
    "print ('The shape of dataForDT after preprocessing is: ', dataContinuous_dirty.shape)\n",
    "print ('The shape of targetForDT after preprocessing is: ', targetBinomial_dirty.shape)\n",
    "# print (dataForDT)\n",
    "print (targetBinomial_dirty)\n",
    "dataContinuous_dirty.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Imputing missing values with the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>...</th>\n",
       "      <th>PolicAveOTWorked</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>PolicCars</th>\n",
       "      <th>PolicOperBudg</th>\n",
       "      <th>LemasPctPolicOnPatr</th>\n",
       "      <th>LemasGangUnitDeploy</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>PolicBudgPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305987</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.163103</td>\n",
       "      <td>0.076708</td>\n",
       "      <td>0.698589</td>\n",
       "      <td>0.440439</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.195078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305987</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.163103</td>\n",
       "      <td>0.076708</td>\n",
       "      <td>0.698589</td>\n",
       "      <td>0.440439</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.195078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305987</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.163103</td>\n",
       "      <td>0.076708</td>\n",
       "      <td>0.698589</td>\n",
       "      <td>0.440439</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.195078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305987</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.163103</td>\n",
       "      <td>0.076708</td>\n",
       "      <td>0.698589</td>\n",
       "      <td>0.440439</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.195078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "0        0.19           0.33          0.02          0.90          0.12   \n",
       "1        0.00           0.16          0.12          0.74          0.45   \n",
       "2        0.00           0.42          0.49          0.56          0.17   \n",
       "3        0.04           0.77          1.00          0.08          0.12   \n",
       "4        0.01           0.55          0.02          0.95          0.09   \n",
       "\n",
       "   racePctHisp  agePct12t21  agePct12t29  agePct16t24  agePct65up  \\\n",
       "0         0.17         0.34         0.47         0.29        0.32   \n",
       "1         0.07         0.26         0.59         0.35        0.27   \n",
       "2         0.04         0.39         0.47         0.28        0.32   \n",
       "3         0.10         0.51         0.50         0.34        0.21   \n",
       "4         0.05         0.38         0.38         0.23        0.36   \n",
       "\n",
       "        ...         PolicAveOTWorked  LandArea  PopDens  PctUsePubTrans  \\\n",
       "0       ...                 0.290000      0.12     0.26            0.20   \n",
       "1       ...                 0.305987      0.02     0.12            0.45   \n",
       "2       ...                 0.305987      0.01     0.21            0.02   \n",
       "3       ...                 0.305987      0.02     0.39            0.28   \n",
       "4       ...                 0.305987      0.04     0.09            0.02   \n",
       "\n",
       "   PolicCars  PolicOperBudg  LemasPctPolicOnPatr  LemasGangUnitDeploy  \\\n",
       "0   0.060000       0.040000             0.900000             0.500000   \n",
       "1   0.163103       0.076708             0.698589             0.440439   \n",
       "2   0.163103       0.076708             0.698589             0.440439   \n",
       "3   0.163103       0.076708             0.698589             0.440439   \n",
       "4   0.163103       0.076708             0.698589             0.440439   \n",
       "\n",
       "   LemasPctOfficDrugUn  PolicBudgPerPop  \n",
       "0                 0.32         0.140000  \n",
       "1                 0.00         0.195078  \n",
       "2                 0.00         0.195078  \n",
       "3                 0.00         0.195078  \n",
       "4                 0.00         0.195078  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We inpute missing value with the mean because there is a \n",
    "# high probability of data having a value of 0 \n",
    "# so imputing with zero would bais the decision tree model\n",
    "# Also, there is very less probability for the data\n",
    "# to have the value of exact mean at float64.\n",
    "# Also, For decision tree classification, since we are splitting,\n",
    "# imputing any value should not make a lot of difference\n",
    "\n",
    "dataContinuous_dirtyMean = dataContinuous_dirty\n",
    "\n",
    "# First We replace all the ? with np.NaN\n",
    "dataContinuous_dirtyMean = dataContinuous_dirtyMean.replace(to_replace='?', value=np.NaN)\n",
    "dataContinuous_dirtyMean = dataContinuous_dirtyMean.astype('float64')\n",
    "\n",
    "meanDF = dataContinuous_dirtyMean.mean(axis=0, skipna=True)\n",
    "\n",
    "def inputeMean(dataFrameIN):\n",
    "    for columns in dataFrameIN.columns:\n",
    "        dataFrameIN[columns] = dataFrameIN[columns].replace(to_replace=np.NaN, value=meanDF[columns])\n",
    "    return (dataFrameIN)\n",
    "    \n",
    "dataContinuous_dirtyMean = inputeMean(dataContinuous_dirtyMean)\n",
    "\n",
    "dataContinuous_dirtyMean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold CV: Performance metric \n",
      " [{'accuracy': 0.75250000000000006}, {'precision': 0.81118932459178839}, {'recall': 0.81000832051507454}]\n"
     ]
    }
   ],
   "source": [
    "# Fit the Decision Tree Model\n",
    "classifierDT_dirty = tree.DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "modelName='DirtyData: Decision Tree Classifier'\n",
    "scoreOBJ = ModelScoring(modelName = modelName, modelObj = classifierDT_dirty)\n",
    "scoreOBJ.setData(dataIN=dataContinuous_dirtyMean, targetIN=targetBinomial_dirty)\n",
    "scoreOBJ.cvEvaluate(scoringMetric=['accuracy','precision','recall'])\n",
    "\n",
    "print ('10-Fold CV: Performance metric \\n',modelScores[modelName])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Distribution of the class variable given few column with missing value (the column data in grouped by on missing value \"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>%non-ViolentCrime</th>\n",
       "      <th>%ViolentCrime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LemasPctPolicOnPatr</th>\n",
       "      <td>0.426269</td>\n",
       "      <td>0.573731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LemasGangUnitDeploy</th>\n",
       "      <td>0.426269</td>\n",
       "      <td>0.573731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolicOperBudg</th>\n",
       "      <td>0.426269</td>\n",
       "      <td>0.573731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolicCars</th>\n",
       "      <td>0.426269</td>\n",
       "      <td>0.573731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolicAveOTWorked</th>\n",
       "      <td>0.426269</td>\n",
       "      <td>0.573731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PolicBudgPerPop</th>\n",
       "      <td>0.426269</td>\n",
       "      <td>0.573731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    %non-ViolentCrime %ViolentCrime\n",
       "LemasPctPolicOnPatr          0.426269      0.573731\n",
       "LemasGangUnitDeploy          0.426269      0.573731\n",
       "PolicOperBudg                0.426269      0.573731\n",
       "PolicCars                    0.426269      0.573731\n",
       "PolicAveOTWorked             0.426269      0.573731\n",
       "PolicBudgPerPop              0.426269      0.573731"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def checkMissingDist(dataFrameIN, columnNameList):\n",
    "    distMissing_DF = pd.DataFrame(columns=['%non-ViolentCrime', '%ViolentCrime'])\n",
    "    for columnName in columnNameList:\n",
    "        dfNew = pd.DataFrame(columns=[columnName, 'target'])\n",
    "        dfNew[columnName] = dataFrameIN[columnName]\n",
    "        dfNew['target'] = targetBinomial_dirty\n",
    "        dfcrosstab = dfNew[(dfNew[columnName] == '?')].groupby('target').size()\n",
    "#         print (dfcrosstab[0]/(dfcrosstab[0]+dfcrosstab[1]))\n",
    "#         print (dfcrosstab[1]/(dfcrosstab[0]+dfcrosstab[1]))\n",
    "        distMissing_DF.ix[columnName,'%non-ViolentCrime'] = dfcrosstab[0]/(dfcrosstab[0]+dfcrosstab[1])\n",
    "        distMissing_DF.ix[columnName,'%ViolentCrime'] = dfcrosstab[1]/(dfcrosstab[0]+dfcrosstab[1])\n",
    "    return distMissing_DF\n",
    "    \n",
    "columnNameList = ['LemasPctPolicOnPatr', 'LemasGangUnitDeploy', 'PolicOperBudg', 'PolicCars', 'PolicAveOTWorked', 'PolicBudgPerPop']\n",
    "distMissing_DF = checkMissingDist(dataContinuous_dirty, columnNameList)\n",
    "                                  \n",
    "distMissing_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# LASSO Feature Selection; Logistic and Poly SVM\n",
    "---------\n",
    "\n",
    "Step 1: We replace all the missing values of the dirty data with the mean. We also experiment with median, but the feature selection technique doesnt choose any of the features with missing data.\n",
    "\n",
    "Step 2: We use Lasso Feature selection technique to find the most predictive features in the dataset (both clean and dirty). Lasso finds 34 most important features out of the 100 features from the clean dataset and 37 features out of 122 features from the Dirty Data.\n",
    "\n",
    "Step 3: To the new data (clean and dirty) consisting only the features selected, we fit a simple Logistic Regression model and compute the precision, recall and accuracy using CrossValidation.\n",
    "\n",
    "Step 4: To the new data (clean and dirty) consisting only the features selected, we fit a SVM model usign a polynomial kernel (3rd order) and compute the precision, recall and accuracy using CrossValidation.\n",
    "\n",
    "Note: Lasso Regression and Logistic Regression with L1 norm produces different outputs and performance mesure. While Evaluating models we see that the features selection with Lasso using Logistic (with L1 norm) was better than simple Logistic with L1 norm. That is the reason we do LASSO feature selection separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Clean Data: Lasso Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of Clean Data is:  (1993, 100)\n",
      "CleanData: Number of Features selected by Lasso is:  34\n",
      "The first degree features most predictive of a high crime rate and low crime rate and their respective weights are: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>highCrimePredictive_features</th>\n",
       "      <th>high_featureWeight</th>\n",
       "      <th>lowCrimePredictive_features</th>\n",
       "      <th>low_featureWeight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TotalPctDiv</td>\n",
       "      <td>0.351936</td>\n",
       "      <td>pctWInvInc</td>\n",
       "      <td>-0.765809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>racePctHisp</td>\n",
       "      <td>0.217541</td>\n",
       "      <td>PctKids2Par</td>\n",
       "      <td>-0.412368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OwnOccHiQuart</td>\n",
       "      <td>0.114368</td>\n",
       "      <td>PersPerOwnOccHous</td>\n",
       "      <td>-0.242417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OtherPerCap</td>\n",
       "      <td>0.099266</td>\n",
       "      <td>racePctWhite</td>\n",
       "      <td>-0.227684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>population</td>\n",
       "      <td>0.084624</td>\n",
       "      <td>NumIlleg</td>\n",
       "      <td>-0.152096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RentHighQ</td>\n",
       "      <td>0.079851</td>\n",
       "      <td>PctWOFullPlumb</td>\n",
       "      <td>-0.111452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>agePct65up</td>\n",
       "      <td>0.077351</td>\n",
       "      <td>PctHousOccup</td>\n",
       "      <td>-0.092672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pctUrban</td>\n",
       "      <td>0.074902</td>\n",
       "      <td>PctEmplManu</td>\n",
       "      <td>-0.071834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FemalePctDiv</td>\n",
       "      <td>0.065055</td>\n",
       "      <td>HispPerCap</td>\n",
       "      <td>-0.071482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>racePctAsian</td>\n",
       "      <td>0.056690</td>\n",
       "      <td>householdsize</td>\n",
       "      <td>-0.058220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  highCrimePredictive_features  high_featureWeight  \\\n",
       "0                  TotalPctDiv            0.351936   \n",
       "1                  racePctHisp            0.217541   \n",
       "2                OwnOccHiQuart            0.114368   \n",
       "3                  OtherPerCap            0.099266   \n",
       "4                   population            0.084624   \n",
       "5                    RentHighQ            0.079851   \n",
       "6                   agePct65up            0.077351   \n",
       "7                     pctUrban            0.074902   \n",
       "8                 FemalePctDiv            0.065055   \n",
       "9                 racePctAsian            0.056690   \n",
       "\n",
       "  lowCrimePredictive_features  low_featureWeight  \n",
       "0                  pctWInvInc          -0.765809  \n",
       "1                 PctKids2Par          -0.412368  \n",
       "2           PersPerOwnOccHous          -0.242417  \n",
       "3                racePctWhite          -0.227684  \n",
       "4                    NumIlleg          -0.152096  \n",
       "5              PctWOFullPlumb          -0.111452  \n",
       "6                PctHousOccup          -0.092672  \n",
       "7                 PctEmplManu          -0.071834  \n",
       "8                  HispPerCap          -0.071482  \n",
       "9               householdsize          -0.058220  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "\n",
    "print ('The shape of Clean Data is: ', dataContinuous.shape)\n",
    "\n",
    "# Fit LASSO (Linear regression with L1 Norm)\n",
    "classifierLS_clean = linear_model.Lasso(alpha=0.001, \n",
    "                                  fit_intercept=True, \n",
    "                                  max_iter=1000)\n",
    "\n",
    "classifierLS_clean.fit(dataContinuous, targetBinomial)\n",
    "\n",
    "print ('CleanData: Number of Features selected by Lasso is: ', len(np.where(classifierLS_clean.coef_ != 0)[0]))\n",
    "\n",
    "\n",
    "\n",
    "modelName='Clean Data: Lasso Features'\n",
    "clnLasso_scoreOBJ = ModelScoring(modelName = modelName, modelObj = classifierLS_clean)\n",
    "clnLasso_scoreOBJ.setData(dataIN=dataContinuous, targetIN=targetBinomial)\n",
    "topFeatureDF = clnLasso_scoreOBJ.getTopFeatures(num=10)\n",
    "print ('The first degree features most predictive of a high crime rate and low crime rate and their respective weights are: ')\n",
    "topFeatureDF.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Dirty Data: Lasso Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of Clean Data is:  (1994, 122)\n",
      "CleanData: Number of Features selected by Lasso is:  37\n",
      "The first degree features most predictive of a high crime rate and low crime rate and their respective weights are: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>highCrimePredictive_features</th>\n",
       "      <th>high_featureWeight</th>\n",
       "      <th>lowCrimePredictive_features</th>\n",
       "      <th>low_featureWeight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TotalPctDiv</td>\n",
       "      <td>0.374450</td>\n",
       "      <td>pctWInvInc</td>\n",
       "      <td>-0.758303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RacialMatchCommPol</td>\n",
       "      <td>0.288589</td>\n",
       "      <td>PctKids2Par</td>\n",
       "      <td>-0.405172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>racePctHisp</td>\n",
       "      <td>0.201255</td>\n",
       "      <td>racePctWhite</td>\n",
       "      <td>-0.287850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OwnOccHiQuart</td>\n",
       "      <td>0.118270</td>\n",
       "      <td>PersPerOwnOccHous</td>\n",
       "      <td>-0.217569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OtherPerCap</td>\n",
       "      <td>0.101677</td>\n",
       "      <td>PctPolicMinor</td>\n",
       "      <td>-0.183767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RentHighQ</td>\n",
       "      <td>0.076659</td>\n",
       "      <td>PctWOFullPlumb</td>\n",
       "      <td>-0.102562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pctUrban</td>\n",
       "      <td>0.072331</td>\n",
       "      <td>PctHousOccup</td>\n",
       "      <td>-0.087678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>agePct65up</td>\n",
       "      <td>0.069682</td>\n",
       "      <td>PctEmplManu</td>\n",
       "      <td>-0.076873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pctWRetire</td>\n",
       "      <td>0.052898</td>\n",
       "      <td>PctPolicBlack</td>\n",
       "      <td>-0.068177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FemalePctDiv</td>\n",
       "      <td>0.047071</td>\n",
       "      <td>HispPerCap</td>\n",
       "      <td>-0.066024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  highCrimePredictive_features  high_featureWeight  \\\n",
       "0                  TotalPctDiv            0.374450   \n",
       "1           RacialMatchCommPol            0.288589   \n",
       "2                  racePctHisp            0.201255   \n",
       "3                OwnOccHiQuart            0.118270   \n",
       "4                  OtherPerCap            0.101677   \n",
       "5                    RentHighQ            0.076659   \n",
       "6                     pctUrban            0.072331   \n",
       "7                   agePct65up            0.069682   \n",
       "8                   pctWRetire            0.052898   \n",
       "9                 FemalePctDiv            0.047071   \n",
       "\n",
       "  lowCrimePredictive_features  low_featureWeight  \n",
       "0                  pctWInvInc          -0.758303  \n",
       "1                 PctKids2Par          -0.405172  \n",
       "2                racePctWhite          -0.287850  \n",
       "3           PersPerOwnOccHous          -0.217569  \n",
       "4               PctPolicMinor          -0.183767  \n",
       "5              PctWOFullPlumb          -0.102562  \n",
       "6                PctHousOccup          -0.087678  \n",
       "7                 PctEmplManu          -0.076873  \n",
       "8               PctPolicBlack          -0.068177  \n",
       "9                  HispPerCap          -0.066024  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('The shape of Clean Data is: ', dataContinuous_dirtyMean.shape)\n",
    "\n",
    "classifierLS_dirty = linear_model.Lasso(alpha=0.001, \n",
    "                                  fit_intercept=True, \n",
    "                                  max_iter=1000)\n",
    "\n",
    "classifierLS_dirty.fit(dataContinuous_dirtyMean, targetBinomial_dirty)\n",
    "\n",
    "print ('CleanData: Number of Features selected by Lasso is: ', len(np.where(classifierLS_dirty.coef_ != 0)[0]))\n",
    "\n",
    "\n",
    "\n",
    "modelName='Dirty Data: Lasso Features'\n",
    "drtyLasso_scoreOBJ = ModelScoring(modelName = modelName, modelObj = classifierLS_dirty)\n",
    "drtyLasso_scoreOBJ.setData(dataIN=dataContinuous_dirtyMean, targetIN=targetBinomial_dirty)\n",
    "topFeatureDF = drtyLasso_scoreOBJ.getTopFeatures(num=10)\n",
    "print ('The first degree features most predictive of a high crime rate and low crime rate and their respective weights are: ')\n",
    "topFeatureDF.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Logistic Regresion with L1 norm: Clean Data and Dirty Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Data: The Shape of New data is:  (1993, 34)\n",
      "Model (Clean Data; Lasso Feature selection; Logistic with L1 Norm) : Performance Metric: \n",
      " [{'accuracy': 0.85149999999999992}, {'precision': 0.8709122026050311}, {'recall': 0.88880138359548133}]\n",
      "\n",
      "Dirty Data: The Shape of New data is:  (1994, 37)\n",
      "Model (Dirty Data; Lasso Feature selection; Logistic with L1 Norm) : Performance Metric: \n",
      " [{'accuracy': 0.84999999999999998}, {'precision': 0.88315316441279157}, {'recall': 0.88196204423858404}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Logistic model with L1 norm:\n",
    "C = 1\n",
    "classifierLR_L1_poly = linear_model.LogisticRegression(penalty='l1', \n",
    "                                                       C=C, fit_intercept=True, \n",
    "                                                       max_iter=1000)\n",
    "\n",
    "####### For Clean Data\n",
    "newCoeff = classifierLS_clean.coef_.flatten()\n",
    "newCleanData = dataContinuous[dataContinuous.columns[np.where(newCoeff!=0)[0]]]\n",
    "print ('Clean Data: The Shape of New data is: ', newCleanData.shape)\n",
    "\n",
    "modelName='Clean Data; Lasso Feature selection; Logistic with L1 Norm'\n",
    "cleanLasso_scoreOBJ = ModelScoring(modelName = modelName, modelObj = classifierLR_L1_poly)\n",
    "cleanLasso_scoreOBJ.setData(dataIN=newCleanData, targetIN=targetBinomial)\n",
    "cleanLasso_scoreOBJ.cvEvaluate(scoringMetric=['accuracy','precision','recall'])\n",
    "\n",
    "print ('Model (%s) : Performance Metric: \\n'%modelName, modelScores[modelName])\n",
    "print ('')\n",
    "\n",
    "\n",
    "\n",
    "#######  For Dirty Data\n",
    "newCoeff = classifierLS_dirty.coef_.flatten()\n",
    "newDirtyData = dataContinuous_dirtyMean[dataContinuous_dirtyMean.columns[np.where(newCoeff!=0)[0]]]\n",
    "print ('Dirty Data: The Shape of New data is: ', newDirtyData.shape)\n",
    "\n",
    "modelName='Dirty Data; Lasso Feature selection; Logistic with L1 Norm'\n",
    "dirtyLasso_scoreOBJ = ModelScoring(modelName = modelName, modelObj = classifierLR_L1_poly)\n",
    "dirtyLasso_scoreOBJ.setData(dataIN=newDirtyData, targetIN=targetBinomial_dirty)\n",
    "dirtyLasso_scoreOBJ.cvEvaluate(scoringMetric=['accuracy','precision','recall'])\n",
    "\n",
    "print ('Model (%s) : Performance Metric: \\n'%modelName, modelScores[modelName])\n",
    "print ('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Poly Kernel SVM: Clean Data and Dirty Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Data: The Shape of New data is:  (1993, 34)\n",
      "Model (Clean Data; Lasso Feature selection; Poly SVM) : Performance Metric: \n",
      " [{'accuracy': 0.83050000000000002}, {'precision': 0.84073677346707765}, {'recall': 0.89131720925893521}]\n",
      "\n",
      "Dirty Data: The Shape of New data is:  (1994, 37)\n",
      "Model (Dirty Data; Lasso Feature selection; Poly SVM) : Performance Metric: \n",
      " [{'accuracy': 0.83699999999999997}, {'precision': 0.86248894734647141}, {'recall': 0.88574373106459969}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "classifierSVM_poly = svm.SVC(kernel='poly', gamma=0.1, C=0.5, degree=3)\n",
    "\n",
    "\n",
    "####### For Clean Data\n",
    "newCoeff = classifierLS_clean.coef_.flatten()\n",
    "newCleanData = dataContinuous[dataContinuous.columns[np.where(newCoeff!=0)[0]]]\n",
    "print ('Clean Data: The Shape of New data is: ', newCleanData.shape)\n",
    "\n",
    "modelName='Clean Data; Lasso Feature selection; Poly SVM'\n",
    "cleanLasso_scoreOBJ = ModelScoring(modelName = modelName, modelObj = classifierSVM_poly)\n",
    "cleanLasso_scoreOBJ.setData(dataIN=newCleanData, targetIN=targetBinomial)\n",
    "cleanLasso_scoreOBJ.cvEvaluate(scoringMetric=['accuracy','precision','recall'])\n",
    "\n",
    "print ('Model (%s) : Performance Metric: \\n'%modelName, modelScores[modelName])\n",
    "print ('')\n",
    "\n",
    "\n",
    "\n",
    "#######  For Dirty Data\n",
    "newCoeff = classifierLS_dirty.coef_.flatten()\n",
    "newDirtyData = dataContinuous_dirtyMean[dataContinuous_dirtyMean.columns[np.where(newCoeff!=0)[0]]]\n",
    "print ('Dirty Data: The Shape of New data is: ', newDirtyData.shape)\n",
    "\n",
    "modelName='Dirty Data; Lasso Feature selection; Poly SVM'\n",
    "dirtyLasso_scoreOBJ = ModelScoring(modelName = modelName, modelObj = classifierSVM_poly)\n",
    "dirtyLasso_scoreOBJ.setData(dataIN=newDirtyData, targetIN=targetBinomial_dirty)\n",
    "dirtyLasso_scoreOBJ.cvEvaluate(scoringMetric=['accuracy','precision','recall'])\n",
    "\n",
    "print ('Model (%s) : Performance Metric: \\n'%modelName, modelScores[modelName])\n",
    "print ('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# SVM (RBF), Random Forests, AdaBoost\n",
    "---------\n",
    "\n",
    "Here we build and evaluate three different models. 1) SVM with rbf Kernel, 2) Random Forest and 3) Adaboost. \n",
    "\n",
    "Step 1: First we define a range of coefficients for each parameter c and gamma for the rbf kernel. We run the SVM model for all different combination of c and gamma and then find the accuracy, precision and recall using a 10 fold cross validation\n",
    "\n",
    "Step 2: Second we fit a random forest model for 500 decision trees for 10 fold cross validation and evaluate the model.\n",
    "\n",
    "Step 3: Third, we fit a adaboost model with for 500 estimators for 10 fold cross validation and eveluate the models\n",
    "\n",
    "\n",
    "##### SVM - RBF kernel: \n",
    "The solution is reliable in a sense that the dynamics of SVM is robust to overfitting. For classifying a new data point, despite the infinite dimensionality of the rbf kernel, we only have to go through support vectors, which are very less in number. The same has been processed through the crossvalidation. Moreover, The precision and recall scores are very high meaning that the algorithm is doing very good at identifying vilont crimes. Additionally, cmpared to some of the above approaches the accuracy is also good enough.\n",
    "\n",
    "From the result we see that the best result is at [c= 1.0 and gamma = 0.01]\t[acc=0.818322, precision=0.900897, recall=0.8624]. This indicates a small value of \"gamma\" which can be understood that the dataset doesn't have a very high degree non-linear split. The smaller \"gamma\" also indicates that the model is unable to find the complex structure in the data (even though it does, the model doesn't generalize well for the validation dataset), hence we can think of the model as close to a linear fit. Thats the rason that the evaluation metric of the \"rbf\" kernel is very close to \"linear SVC\".\n",
    "\n",
    "##### Random Forest and Adaboost: \n",
    "Random Forest and Ada boost belongs to the family of ensambles and boosting algorithms that are very robust to overfitting as they fit many different models and average their prediction. For a Random Forest model, it fits many decision tree for randomly sampled data and average the knowledge of all the trees. Random forest were seen to be second best model just after logistic regression with Lasso feature selection. The performance of the random forest model is also consistent making is reliable for the dataset. For Adaboost the performace metric are lesser when compared to random forest but not very less. Hence these output of these models can be thaught as reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### SVM with RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "class SVM_model():\n",
    "\n",
    "    def __init__(self, kernel='rbf'):\n",
    "#         self.c_range = [0.01, 0.1, 1.0, 10.0, 100.0]#, 1000.0]            \n",
    "#         self.gamma_range = [0.001, 0.01, 0.1, 1, 10.0, 100]  \n",
    "        self.c_range = [0.01, 0.05, 0.1, 0.5, 1] #, 1000.0]            \n",
    "        self.gamma_range = [0.01, 0.05, 0.1, 0.5, 1] \n",
    "        \n",
    "        self.kernel=kernel\n",
    "\n",
    "    def classify(self, trainData, trainLabels, validData):\n",
    "        c_range = self.c_range\n",
    "        gamma_range = self.gamma_range\n",
    "        \n",
    "        pred_dict = {}\n",
    "        for (c,gamma) in itertools.product(c_range, gamma_range):\n",
    "            string = \"c\" + str(c) + \"_\" + \"gamma\" + str(gamma)  \n",
    "            clf = svm.SVC(kernel=self.kernel, C=c, gamma=gamma)\n",
    "            classifier = clf.fit(trainData,trainLabels)\n",
    "            pred_dict[string] = clf.predict(validData)\n",
    "        return pred_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Since the classes \"HighCrime\", \"LowCrime\" are unbalanced, We do stratifies Sampling and fetch 10-fold cross validation dataset.\n",
    "import itertools\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def buildModel(data, target):\n",
    "    dataContinuous_NDarr = np.array(data, dtype='float64')\n",
    "    targetBinomial_NDarr = np.array(target, dtype='float64')\n",
    "\n",
    "    stN_Fold = StratifiedKFold(n_splits=10, random_state=675)  # We use the same seed, to get a rought comparison of the model with all other models.\n",
    "    stN_Fold.get_n_splits(dataContinuous_NDarr, targetBinomial_NDarr)\n",
    "#     print (stN_Fold)\n",
    "\n",
    "\n",
    "    objSVM = SVM_model(kernel='rbf')\n",
    "    outputEvaluationDict = {}\n",
    "    validLabelDict = {}\n",
    "    for foldNUM, (trainIndex, validIndex) in enumerate(stN_Fold.split(dataContinuous_NDarr, targetBinomial_NDarr)):\n",
    "#         print(\"Train:\", len(trainIndex), \"CrossValid:\", len(validIndex))\n",
    "        if len(trainIndex)+len(validIndex) != len(dataContinuous):\n",
    "            raise ValueError('The length of the samples doesnt match')\n",
    "\n",
    "\n",
    "        outputEvaluationDict[foldNUM] = objSVM.classify(trainData=dataContinuous_NDarr[trainIndex], \n",
    "                                                        trainLabels=targetBinomial_NDarr[trainIndex], \n",
    "                                                        validData=dataContinuous_NDarr[validIndex])\n",
    "        validLabelDict[foldNUM] = targetBinomial_NDarr[validIndex]\n",
    "    return outputEvaluationDict, validLabelDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg-accuracy</th>\n",
       "      <th>avg-precision</th>\n",
       "      <th>avg-recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma0.01</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma0.05</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma0.1</th>\n",
       "      <td>0.654769</td>\n",
       "      <td>0.718544</td>\n",
       "      <td>0.9960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma0.5</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma1</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.05_gamma0.01</th>\n",
       "      <td>0.648756</td>\n",
       "      <td>0.712208</td>\n",
       "      <td>0.9976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.05_gamma0.05</th>\n",
       "      <td>0.789216</td>\n",
       "      <td>0.865033</td>\n",
       "      <td>0.8760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.05_gamma0.1</th>\n",
       "      <td>0.788206</td>\n",
       "      <td>0.864716</td>\n",
       "      <td>0.8680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.05_gamma0.5</th>\n",
       "      <td>0.749573</td>\n",
       "      <td>0.821524</td>\n",
       "      <td>0.9104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.05_gamma1</th>\n",
       "      <td>0.656796</td>\n",
       "      <td>0.722586</td>\n",
       "      <td>0.9776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma0.01</th>\n",
       "      <td>0.766136</td>\n",
       "      <td>0.836136</td>\n",
       "      <td>0.9112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma0.05</th>\n",
       "      <td>0.802256</td>\n",
       "      <td>0.880729</td>\n",
       "      <td>0.8688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma0.1</th>\n",
       "      <td>0.806776</td>\n",
       "      <td>0.885797</td>\n",
       "      <td>0.8696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma0.5</th>\n",
       "      <td>0.776168</td>\n",
       "      <td>0.851007</td>\n",
       "      <td>0.8936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma1</th>\n",
       "      <td>0.702407</td>\n",
       "      <td>0.770363</td>\n",
       "      <td>0.9416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.5_gamma0.01</th>\n",
       "      <td>0.807279</td>\n",
       "      <td>0.886712</td>\n",
       "      <td>0.8648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.5_gamma0.05</th>\n",
       "      <td>0.819334</td>\n",
       "      <td>0.905624</td>\n",
       "      <td>0.8512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.5_gamma0.1</th>\n",
       "      <td>0.811796</td>\n",
       "      <td>0.897975</td>\n",
       "      <td>0.8432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.5_gamma0.5</th>\n",
       "      <td>0.790716</td>\n",
       "      <td>0.873793</td>\n",
       "      <td>0.8496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.5_gamma1</th>\n",
       "      <td>0.761116</td>\n",
       "      <td>0.838893</td>\n",
       "      <td>0.8704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1_gamma0.01</th>\n",
       "      <td>0.818322</td>\n",
       "      <td>0.900897</td>\n",
       "      <td>0.8624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1_gamma0.05</th>\n",
       "      <td>0.810789</td>\n",
       "      <td>0.896968</td>\n",
       "      <td>0.8416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1_gamma0.1</th>\n",
       "      <td>0.805766</td>\n",
       "      <td>0.891250</td>\n",
       "      <td>0.8368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1_gamma0.5</th>\n",
       "      <td>0.782704</td>\n",
       "      <td>0.867504</td>\n",
       "      <td>0.8344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1_gamma1</th>\n",
       "      <td>0.753085</td>\n",
       "      <td>0.833826</td>\n",
       "      <td>0.8432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 avg-accuracy  avg-precision  avg-recall\n",
       "c0.01_gamma0.01      0.627198       0.690013      1.0000\n",
       "c0.01_gamma0.05      0.627198       0.690013      1.0000\n",
       "c0.01_gamma0.1       0.654769       0.718544      0.9960\n",
       "c0.01_gamma0.5       0.627198       0.690013      1.0000\n",
       "c0.01_gamma1         0.627198       0.690013      1.0000\n",
       "c0.05_gamma0.01      0.648756       0.712208      0.9976\n",
       "c0.05_gamma0.05      0.789216       0.865033      0.8760\n",
       "c0.05_gamma0.1       0.788206       0.864716      0.8680\n",
       "c0.05_gamma0.5       0.749573       0.821524      0.9104\n",
       "c0.05_gamma1         0.656796       0.722586      0.9776\n",
       "c0.1_gamma0.01       0.766136       0.836136      0.9112\n",
       "c0.1_gamma0.05       0.802256       0.880729      0.8688\n",
       "c0.1_gamma0.1        0.806776       0.885797      0.8696\n",
       "c0.1_gamma0.5        0.776168       0.851007      0.8936\n",
       "c0.1_gamma1          0.702407       0.770363      0.9416\n",
       "c0.5_gamma0.01       0.807279       0.886712      0.8648\n",
       "c0.5_gamma0.05       0.819334       0.905624      0.8512\n",
       "c0.5_gamma0.1        0.811796       0.897975      0.8432\n",
       "c0.5_gamma0.5        0.790716       0.873793      0.8496\n",
       "c0.5_gamma1          0.761116       0.838893      0.8704\n",
       "c1_gamma0.01         0.818322       0.900897      0.8624\n",
       "c1_gamma0.05         0.810789       0.896968      0.8416\n",
       "c1_gamma0.1          0.805766       0.891250      0.8368\n",
       "c1_gamma0.5          0.782704       0.867504      0.8344\n",
       "c1_gamma1            0.753085       0.833826      0.8432"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c_range = [0.01, 0.1, 1.0, 10.0, 100.0]#, 1000.0]            \n",
    "# gamma_range = [0.001, 0.01, 0.1, 1, 10.0, 100] \n",
    "\n",
    "c_range = [0.01, 0.05, 0.1, 0.5, 1] #, 1000.0]            \n",
    "gamma_range = [0.01, 0.05, 0.1, 0.5, 1] \n",
    "\n",
    "DF_PrecisionRecallFscore = pd.DataFrame(np.NaN, index=[\"c\" + str(c) + \"_\" + \"gamma\" + str(gamma) for c, gamma in itertools.product(c_range, gamma_range)],\n",
    "                                        columns=['avg-accuracy', 'avg-precision', 'avg-recall'])\n",
    "\n",
    "outputEvaluationDict, validLabelDict = buildModel(dataContinuous, targetBinomial)\n",
    "\n",
    "for foldNUM, c_gamma_prediction in  outputEvaluationDict.items():\n",
    "#     print ('Running for cross validation fold : ', numFold)\n",
    "    for c_gamma, prediction in c_gamma_prediction.items():\n",
    "        if pd.isnull(DF_PrecisionRecallFscore.ix[c_gamma, 'avg-accuracy']):\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-accuracy'] = metrics.accuracy_score(validLabelDict[foldNUM], prediction)\n",
    "        else:\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-accuracy'] = DF_PrecisionRecallFscore.ix[c_gamma, 'avg-accuracy'] + metrics.accuracy_score(validLabelDict[foldNUM], prediction)\n",
    "            \n",
    "        if pd.isnull(DF_PrecisionRecallFscore.ix[c_gamma, 'avg-precision']):\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-precision'] = metrics.precision_score(validLabelDict[foldNUM], prediction)\n",
    "        else:\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-precision'] = DF_PrecisionRecallFscore.ix[c_gamma, 'avg-accuracy'] + metrics.precision_score(validLabelDict[foldNUM], prediction)\n",
    "            \n",
    "        if pd.isnull(DF_PrecisionRecallFscore.ix[c_gamma, 'avg-recall']):\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-recall'] = metrics.recall_score(validLabelDict[foldNUM], prediction)\n",
    "        else:\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-recall'] = DF_PrecisionRecallFscore.ix[c_gamma, 'avg-recall'] + metrics.recall_score(validLabelDict[foldNUM], prediction)\n",
    "\n",
    "DF_PrecisionRecallFscore/(foldNUM+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Random Forests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'accuracy': 0.84199999999999997}, {'precision': 0.86346677944514327}, {'recall': 0.88492710688727683}]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifierRF = RandomForestClassifier(n_estimators=500, criterion='gini')  # Entropy and Gini provides very similar evaluation results\n",
    "classifierRF.fit(dataContinuous, targetBinomial)\n",
    "\n",
    "modelName='Random Forest'\n",
    "scoreOBJ = ModelScoring(modelName = modelName, modelObj = classifierRF)\n",
    "scoreOBJ.setData(dataIN=dataContinuous, targetIN=targetBinomial)\n",
    "scoreOBJ.cvEvaluate(scoringMetric=['accuracy','precision','recall'])\n",
    "\n",
    "print (modelScores[modelName])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>absFeatureGain</th>\n",
       "      <th>featureGain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>PctKids2Par</td>\n",
       "      <td>0.063366</td>\n",
       "      <td>0.063366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>racePctWhite</td>\n",
       "      <td>0.061412</td>\n",
       "      <td>0.061412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>PctIlleg</td>\n",
       "      <td>0.042549</td>\n",
       "      <td>0.042549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>PctPersDenseHous</td>\n",
       "      <td>0.041143</td>\n",
       "      <td>0.041143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>PctFam2Par</td>\n",
       "      <td>0.038669</td>\n",
       "      <td>0.038669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>FemalePctDiv</td>\n",
       "      <td>0.034174</td>\n",
       "      <td>0.034174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TotalPctDiv</td>\n",
       "      <td>0.031145</td>\n",
       "      <td>0.031145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NumIlleg</td>\n",
       "      <td>0.028525</td>\n",
       "      <td>0.028525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>racepctblack</td>\n",
       "      <td>0.024374</td>\n",
       "      <td>0.024374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>PctYoungKids2Par</td>\n",
       "      <td>0.023780</td>\n",
       "      <td>0.023780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_name  absFeatureGain  featureGain\n",
       "44       PctKids2Par        0.063366     0.063366\n",
       "3       racePctWhite        0.061412     0.061412\n",
       "50          PctIlleg        0.042549     0.042549\n",
       "68  PctPersDenseHous        0.041143     0.041143\n",
       "43        PctFam2Par        0.038669     0.038669\n",
       "40      FemalePctDiv        0.034174     0.034174\n",
       "41       TotalPctDiv        0.031145     0.031145\n",
       "49          NumIlleg        0.028525     0.028525\n",
       "2       racepctblack        0.024374     0.024374\n",
       "45  PctYoungKids2Par        0.023780     0.023780"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFfeauturePredictivePower = pd.DataFrame(columns=['feature_name','absFeatureGain', 'featureGain'])\n",
    "\n",
    "RFfeauturePredictivePower['feature_name'] = np.array(dataContinuous.columns)\n",
    "RFfeauturePredictivePower['absFeatureGain'] = np.abs(classifierRF.feature_importances_)\n",
    "RFfeauturePredictivePower['featureGain'] = classifierRF.feature_importances_\n",
    "RFfeauturePredictivePower.sort_values('absFeatureGain', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'accuracy': 0.80999999999999994}, {'precision': 0.8353443501939537}, {'recall': 0.85848163563420066}]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "classifierAB = AdaBoostClassifier(n_estimators=500, learning_rate=1)  # Entropy and Gini provides very similar evaluation results\n",
    "classifierAB.fit(dataContinuous, targetBinomial)\n",
    "\n",
    "modelName='Ada Boost Classifier'\n",
    "scoreOBJ = ModelScoring(modelName = modelName, modelObj = classifierAB)\n",
    "scoreOBJ.setData(dataIN=dataContinuous, targetIN=targetBinomial)\n",
    "scoreOBJ.cvEvaluate(scoringMetric=['accuracy','precision','recall'])\n",
    "\n",
    "print (modelScores[modelName])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>absFeatureGain</th>\n",
       "      <th>featureGain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>MedOwnCostPctIncNoMtg</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>PctKids2Par</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>PctVacMore6Mos</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>indianPerCap</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>PctTeen2Par</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pctWInvInc</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TotalPctDiv</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>racePctWhite</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>PersPerOccupHous</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>blackPerCap</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature_name  absFeatureGain  featureGain\n",
       "88  MedOwnCostPctIncNoMtg           0.034        0.034\n",
       "44            PctKids2Par           0.024        0.024\n",
       "75         PctVacMore6Mos           0.024        0.024\n",
       "23           indianPerCap           0.024        0.024\n",
       "46            PctTeen2Par           0.022        0.022\n",
       "15             pctWInvInc           0.020        0.020\n",
       "41            TotalPctDiv           0.020        0.020\n",
       "3            racePctWhite           0.020        0.020\n",
       "64       PersPerOccupHous           0.020        0.020\n",
       "22            blackPerCap           0.020        0.020"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ABfeauturePredictivePower = pd.DataFrame(columns=['feature_name','absFeatureGain', 'featureGain'])\n",
    "\n",
    "ABfeauturePredictivePower['feature_name'] = np.array(dataContinuous.columns)\n",
    "ABfeauturePredictivePower['absFeatureGain'] = np.abs(classifierAB.feature_importances_)\n",
    "ABfeauturePredictivePower['featureGain'] = classifierAB.feature_importances_\n",
    "ABfeauturePredictivePower.sort_values('absFeatureGain', ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
