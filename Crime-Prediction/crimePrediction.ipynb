{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import done here\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loading the Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1993, 104)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>communityname</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>numbUrban</th>\n",
       "      <th>pctUrban</th>\n",
       "      <th>medIncome</th>\n",
       "      <th>pctWWage</th>\n",
       "      <th>pctWFarmSelf</th>\n",
       "      <th>pctWInvInc</th>\n",
       "      <th>pctWSocSec</th>\n",
       "      <th>pctWPubAsst</th>\n",
       "      <th>pctWRetire</th>\n",
       "      <th>medFamInc</th>\n",
       "      <th>perCapInc</th>\n",
       "      <th>whitePerCap</th>\n",
       "      <th>blackPerCap</th>\n",
       "      <th>indianPerCap</th>\n",
       "      <th>AsianPerCap</th>\n",
       "      <th>OtherPerCap</th>\n",
       "      <th>HispPerCap</th>\n",
       "      <th>NumUnderPov</th>\n",
       "      <th>PctPopUnderPov</th>\n",
       "      <th>PctLess9thGrade</th>\n",
       "      <th>PctNotHSGrad</th>\n",
       "      <th>PctBSorMore</th>\n",
       "      <th>PctUnemployed</th>\n",
       "      <th>PctEmploy</th>\n",
       "      <th>PctEmplManu</th>\n",
       "      <th>PctEmplProfServ</th>\n",
       "      <th>PctOccupManu</th>\n",
       "      <th>PctOccupMgmtProf</th>\n",
       "      <th>MalePctDivorce</th>\n",
       "      <th>MalePctNevMarr</th>\n",
       "      <th>FemalePctDiv</th>\n",
       "      <th>TotalPctDiv</th>\n",
       "      <th>PersPerFam</th>\n",
       "      <th>PctFam2Par</th>\n",
       "      <th>PctKids2Par</th>\n",
       "      <th>PctYoungKids2Par</th>\n",
       "      <th>PctTeen2Par</th>\n",
       "      <th>PctWorkMomYoungKids</th>\n",
       "      <th>PctWorkMom</th>\n",
       "      <th>NumIlleg</th>\n",
       "      <th>PctIlleg</th>\n",
       "      <th>NumImmig</th>\n",
       "      <th>PctImmigRecent</th>\n",
       "      <th>PctImmigRec5</th>\n",
       "      <th>PctImmigRec8</th>\n",
       "      <th>PctImmigRec10</th>\n",
       "      <th>PctRecentImmig</th>\n",
       "      <th>PctRecImmig5</th>\n",
       "      <th>PctRecImmig8</th>\n",
       "      <th>PctRecImmig10</th>\n",
       "      <th>PctSpeakEnglOnly</th>\n",
       "      <th>PctNotSpeakEnglWell</th>\n",
       "      <th>PctLargHouseFam</th>\n",
       "      <th>PctLargHouseOccup</th>\n",
       "      <th>PersPerOccupHous</th>\n",
       "      <th>PersPerOwnOccHous</th>\n",
       "      <th>PersPerRentOccHous</th>\n",
       "      <th>PctPersOwnOccup</th>\n",
       "      <th>PctPersDenseHous</th>\n",
       "      <th>PctHousLess3BR</th>\n",
       "      <th>MedNumBR</th>\n",
       "      <th>HousVacant</th>\n",
       "      <th>PctHousOccup</th>\n",
       "      <th>PctHousOwnOcc</th>\n",
       "      <th>PctVacantBoarded</th>\n",
       "      <th>PctVacMore6Mos</th>\n",
       "      <th>MedYrHousBuilt</th>\n",
       "      <th>PctHousNoPhone</th>\n",
       "      <th>PctWOFullPlumb</th>\n",
       "      <th>OwnOccLowQuart</th>\n",
       "      <th>OwnOccMedVal</th>\n",
       "      <th>OwnOccHiQuart</th>\n",
       "      <th>RentLowQ</th>\n",
       "      <th>RentMedian</th>\n",
       "      <th>RentHighQ</th>\n",
       "      <th>MedRent</th>\n",
       "      <th>MedRentPctHousInc</th>\n",
       "      <th>MedOwnCostPctInc</th>\n",
       "      <th>MedOwnCostPctIncNoMtg</th>\n",
       "      <th>NumInShelters</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alabastercity</td>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AlexanderCitycity</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Annistoncity</td>\n",
       "      <td>3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Athenscity</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Auburncity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state      communityname  fold  population  householdsize  racepctblack  \\\n",
       "0      1      Alabastercity     7        0.01           0.61          0.21   \n",
       "1      1  AlexanderCitycity    10        0.01           0.41          0.55   \n",
       "2      1       Annistoncity     3        0.03           0.34          0.86   \n",
       "3      1         Athenscity     8        0.01           0.38          0.35   \n",
       "4      1         Auburncity     1        0.04           0.37          0.32   \n",
       "\n",
       "   racePctWhite  racePctAsian  racePctHisp  agePct12t21  agePct12t29  \\\n",
       "0          0.83          0.02         0.01         0.41         0.49   \n",
       "1          0.57          0.01         0.00         0.47         0.45   \n",
       "2          0.30          0.04         0.01         0.41         0.42   \n",
       "3          0.71          0.04         0.01         0.39         0.46   \n",
       "4          0.70          0.21         0.02         1.00         1.00   \n",
       "\n",
       "   agePct16t24  agePct65up  numbUrban  pctUrban  medIncome  pctWWage  \\\n",
       "0         0.26        0.21       0.02       1.0       0.46      0.77   \n",
       "1         0.31        0.57       0.00       0.0       0.15      0.33   \n",
       "2         0.27        0.59       0.04       1.0       0.12      0.32   \n",
       "3         0.31        0.49       0.00       0.0       0.23      0.43   \n",
       "4         1.00        0.14       0.05       1.0       0.02      0.77   \n",
       "\n",
       "   pctWFarmSelf  pctWInvInc  pctWSocSec  pctWPubAsst  pctWRetire  medFamInc  \\\n",
       "0          0.23        0.38        0.22         0.16        0.22       0.42   \n",
       "1          0.13        0.27        0.65         0.41        0.45       0.21   \n",
       "2          0.19        0.28        0.67         0.52        0.57       0.18   \n",
       "3          0.48        0.36        0.53         0.41        0.44       0.29   \n",
       "4          0.57        0.47        0.13         0.11        0.16       0.32   \n",
       "\n",
       "   perCapInc  whitePerCap  blackPerCap  indianPerCap  AsianPerCap  \\\n",
       "0       0.29         0.29         0.27          0.16         0.24   \n",
       "1       0.22         0.29         0.15          0.00         0.29   \n",
       "2       0.21         0.35         0.15          0.26         0.18   \n",
       "3       0.27         0.30         0.18          0.19         0.20   \n",
       "4       0.17         0.19         0.16          0.07         0.21   \n",
       "\n",
       "   OtherPerCap  HispPerCap  NumUnderPov  PctPopUnderPov  PctLess9thGrade  \\\n",
       "0         0.38        0.26         0.01            0.14             0.27   \n",
       "1         0.00        0.14         0.02            0.45             0.57   \n",
       "2         0.84        0.33         0.06            0.65             0.48   \n",
       "3         0.00        0.80         0.02            0.38             0.51   \n",
       "4         0.14        0.22         0.11            1.00             0.18   \n",
       "\n",
       "   PctNotHSGrad  PctBSorMore  PctUnemployed  PctEmploy  PctEmplManu  \\\n",
       "0          0.37         0.39           0.12       0.69         0.27   \n",
       "1          0.70         0.21           0.27       0.43         1.00   \n",
       "2          0.58         0.28           0.79       0.22         0.44   \n",
       "3          0.59         0.32           0.37       0.43         0.64   \n",
       "4          0.18         0.82           0.42       0.23         0.19   \n",
       "\n",
       "   PctEmplProfServ  PctOccupManu  PctOccupMgmtProf  MalePctDivorce  \\\n",
       "0             0.37          0.32              0.48            0.31   \n",
       "1             0.17          0.93              0.24            0.42   \n",
       "2             0.43          0.54              0.41            0.69   \n",
       "3             0.30          0.52              0.46            0.47   \n",
       "4             1.00          0.25              0.67            0.09   \n",
       "\n",
       "   MalePctNevMarr  FemalePctDiv  TotalPctDiv  PersPerFam  PctFam2Par  \\\n",
       "0            0.20          0.35         0.34        0.56        0.81   \n",
       "1            0.32          0.54         0.52        0.46        0.48   \n",
       "2            0.36          0.67         0.71        0.42        0.28   \n",
       "3            0.31          0.42         0.46        0.43        0.63   \n",
       "4            1.00          0.16         0.13        0.38        0.55   \n",
       "\n",
       "   PctKids2Par  PctYoungKids2Par  PctTeen2Par  PctWorkMomYoungKids  \\\n",
       "0         0.79              0.97         0.82                 0.60   \n",
       "1         0.43              0.48         0.59                 0.81   \n",
       "2         0.24              0.38         0.27                 0.49   \n",
       "3         0.62              0.66         0.53                 0.51   \n",
       "4         0.53              0.59         0.54                 0.68   \n",
       "\n",
       "   PctWorkMom  NumIlleg  PctIlleg  NumImmig  PctImmigRecent  PctImmigRec5  \\\n",
       "0        0.51      0.00      0.09      0.00            0.50          0.43   \n",
       "1        0.82      0.02      0.42      0.00            0.00          0.78   \n",
       "2        0.49      0.04      0.55      0.00            0.22          0.28   \n",
       "3        0.47      0.01      0.22      0.00            0.41          0.30   \n",
       "4        0.69      0.03      0.69      0.01            1.00          0.91   \n",
       "\n",
       "   PctImmigRec8  PctImmigRec10  PctRecentImmig  PctRecImmig5  PctRecImmig8  \\\n",
       "0          0.46           0.43            0.04          0.03          0.03   \n",
       "1          0.64           0.54            0.00          0.02          0.01   \n",
       "2          0.45           0.40            0.02          0.02          0.03   \n",
       "3          0.29           0.65            0.04          0.02          0.02   \n",
       "4          0.86           0.80            0.29          0.23          0.20   \n",
       "\n",
       "   PctRecImmig10  PctSpeakEnglOnly  PctNotSpeakEnglWell  PctLargHouseFam  \\\n",
       "0           0.02              0.97                 0.01             0.17   \n",
       "1           0.01              0.98                 0.02             0.19   \n",
       "2           0.03              0.95                 0.02             0.25   \n",
       "3           0.04              0.96                 0.02             0.19   \n",
       "4           0.17              0.90                 0.05             0.14   \n",
       "\n",
       "   PctLargHouseOccup  PersPerOccupHous  PersPerOwnOccHous  PersPerRentOccHous  \\\n",
       "0               0.21              0.65               0.64                0.56   \n",
       "1               0.18              0.43               0.43                0.42   \n",
       "2               0.22              0.36               0.34                0.41   \n",
       "3               0.18              0.38               0.43                0.32   \n",
       "4               0.07              0.25               0.41                0.22   \n",
       "\n",
       "   PctPersOwnOccup  PctPersDenseHous  PctHousLess3BR  MedNumBR  HousVacant  \\\n",
       "0             0.82              0.10            0.22       0.5        0.01   \n",
       "1             0.58              0.17            0.46       0.5        0.02   \n",
       "2             0.50              0.13            0.51       0.5        0.07   \n",
       "3             0.58              0.12            0.45       0.5        0.03   \n",
       "4             0.24              0.14            0.71       0.0        0.06   \n",
       "\n",
       "   PctHousOccup  PctHousOwnOcc  PctVacantBoarded  PctVacMore6Mos  \\\n",
       "0          0.85           0.82              0.00            0.26   \n",
       "1          0.73           0.58              0.18            0.40   \n",
       "2          0.56           0.52              0.31            0.60   \n",
       "3          0.66           0.55              0.18            0.26   \n",
       "4          0.66           0.21              0.07            0.24   \n",
       "\n",
       "   MedYrHousBuilt  PctHousNoPhone  PctWOFullPlumb  OwnOccLowQuart  \\\n",
       "0            0.83            0.13            0.66            0.16   \n",
       "1            0.56            0.55            0.48            0.06   \n",
       "2            0.40            0.55            0.33            0.05   \n",
       "3            0.58            0.42            0.41            0.10   \n",
       "4            0.77            0.27            0.10            0.16   \n",
       "\n",
       "   OwnOccMedVal  OwnOccHiQuart  RentLowQ  RentMedian  RentHighQ  MedRent  \\\n",
       "0          0.15           0.13      0.13        0.23       0.25     0.28   \n",
       "1          0.06           0.08      0.02        0.07       0.08     0.09   \n",
       "2          0.07           0.09      0.02        0.09       0.13     0.13   \n",
       "3          0.10           0.12      0.08        0.14       0.15     0.15   \n",
       "4          0.16           0.18      0.18        0.21       0.26     0.21   \n",
       "\n",
       "   MedRentPctHousInc  MedOwnCostPctInc  MedOwnCostPctIncNoMtg  NumInShelters  \\\n",
       "0               0.19              0.18                   0.25           0.00   \n",
       "1               0.20              0.16                   0.36           0.00   \n",
       "2               0.41              0.38                   0.47           0.01   \n",
       "3               0.24              0.17                   0.33           0.00   \n",
       "4               1.00              0.16                   0.24           0.00   \n",
       "\n",
       "   NumStreet  PctForeignBorn  PctBornSameState  PctSameHouse85  PctSameCity85  \\\n",
       "0       0.00            0.03              0.70            0.40           0.34   \n",
       "1       0.00            0.00              0.93            0.66           0.82   \n",
       "2       0.02            0.04              0.77            0.59           0.70   \n",
       "3       0.00            0.03              0.78            0.56           0.67   \n",
       "4       0.00            0.12              0.49            0.12           0.00   \n",
       "\n",
       "   PctSameState85  LandArea  PopDens  PctUsePubTrans  LemasPctOfficDrugUn  \\\n",
       "0            0.57      0.05     0.06            0.01                  0.0   \n",
       "1            0.84      0.11     0.03            0.01                  0.0   \n",
       "2            0.64      0.06     0.11            0.04                  0.0   \n",
       "3            0.71      0.09     0.05            0.00                  0.0   \n",
       "4            0.15      0.09     0.09            0.01                  0.0   \n",
       "\n",
       "   ViolentCrimesPerPop  \n",
       "0                 0.06  \n",
       "1                 0.14  \n",
       "2                 1.00  \n",
       "3                 0.23  \n",
       "4                 0.15  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LOAD THE DATASET INTO PANDAS DATAFRAME:\n",
    "datadir = '/Users/sam/All-Program/App-DataSet/Study/Crime-Prediction/communities-crime-clean.csv'\n",
    "\n",
    "crimeDF = pd.read_csv(datadir, sep=',', header='infer')\n",
    "\n",
    "# Displaying first five elements for all the columns\n",
    "print (crimeDF.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(crimeDF.head())\n",
    "    \n",
    "# Important feature variables\n",
    "nonPredictiveFeatures = ['state','communityname','fold']\n",
    "regTargetVar = ['ViolentCrimesPerPop']\n",
    "classTargetVar = ['highCrime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The cross validation Random state to be used is for all the model is;\n",
    "cv = model_selection.ShuffleSplit(n_splits=10,random_state=675) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1. Decision Trees:\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part (a):\n",
    "Create a new field “highCrime” which is true if the crime rate per capita (ViolentCrimesPerPop) is greater than 0.1, and false otherwise. What are the percentage of positive and negative instances in the dataset?\n",
    "\n",
    "Solutions: The percentage of positive instances is 62.72 and the percentage of negative insances is 37.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape after adding the classification column is;  (1993, 105)\n",
      "Percent of positive instancs are 62.719518 and percent of negative instances are 37.280482 \n"
     ]
    }
   ],
   "source": [
    "crimeDF['highCrime'] = crimeDF['ViolentCrimesPerPop'] > 0.1\n",
    "print ('The shape after adding the classification column is; ', crimeDF.shape)\n",
    "percntgPositive = (sum(crimeDF['highCrime'] == True)/ (sum(crimeDF['highCrime'] == True) + sum(crimeDF['highCrime'] == False))) * 100\n",
    "percntgNegative = 100-percntgPositive\n",
    "print ('Percent of positive instancs are %f and percent of negative instances are %f '%(percntgPositive, percntgNegative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1993, 105)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>communityname</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>...</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "      <th>highCrime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alabastercity</td>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AlexanderCitycity</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Annistoncity</td>\n",
       "      <td>3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Athenscity</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Auburncity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   state      communityname  fold  population  householdsize  racepctblack  \\\n",
       "0      1      Alabastercity     7        0.01           0.61          0.21   \n",
       "1      1  AlexanderCitycity    10        0.01           0.41          0.55   \n",
       "2      1       Annistoncity     3        0.03           0.34          0.86   \n",
       "3      1         Athenscity     8        0.01           0.38          0.35   \n",
       "4      1         Auburncity     1        0.04           0.37          0.32   \n",
       "\n",
       "   racePctWhite  racePctAsian  racePctHisp  agePct12t21    ...      \\\n",
       "0          0.83          0.02         0.01         0.41    ...       \n",
       "1          0.57          0.01         0.00         0.47    ...       \n",
       "2          0.30          0.04         0.01         0.41    ...       \n",
       "3          0.71          0.04         0.01         0.39    ...       \n",
       "4          0.70          0.21         0.02         1.00    ...       \n",
       "\n",
       "   PctBornSameState  PctSameHouse85  PctSameCity85  PctSameState85  LandArea  \\\n",
       "0              0.70            0.40           0.34            0.57      0.05   \n",
       "1              0.93            0.66           0.82            0.84      0.11   \n",
       "2              0.77            0.59           0.70            0.64      0.06   \n",
       "3              0.78            0.56           0.67            0.71      0.09   \n",
       "4              0.49            0.12           0.00            0.15      0.09   \n",
       "\n",
       "   PopDens  PctUsePubTrans  LemasPctOfficDrugUn  ViolentCrimesPerPop  \\\n",
       "0     0.06            0.01                  0.0                 0.06   \n",
       "1     0.03            0.01                  0.0                 0.14   \n",
       "2     0.11            0.04                  0.0                 1.00   \n",
       "3     0.05            0.00                  0.0                 0.23   \n",
       "4     0.09            0.01                  0.0                 0.15   \n",
       "\n",
       "   highCrime  \n",
       "0      False  \n",
       "1       True  \n",
       "2       True  \n",
       "3       True  \n",
       "4       True  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (crimeDF.shape)\n",
    "crimeDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part (b):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Data Preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of dataForDT after preprocessing is:  (1993, 100)\n",
      "The shape of targetForDT after preprocessing is:  (1993,)\n",
      "[0 1 1 ..., 1 1 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>...</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "0        0.01           0.61          0.21          0.83          0.02   \n",
       "1        0.01           0.41          0.55          0.57          0.01   \n",
       "2        0.03           0.34          0.86          0.30          0.04   \n",
       "3        0.01           0.38          0.35          0.71          0.04   \n",
       "4        0.04           0.37          0.32          0.70          0.21   \n",
       "\n",
       "   racePctHisp  agePct12t21  agePct12t29  agePct16t24  agePct65up  \\\n",
       "0         0.01         0.41         0.49         0.26        0.21   \n",
       "1         0.00         0.47         0.45         0.31        0.57   \n",
       "2         0.01         0.41         0.42         0.27        0.59   \n",
       "3         0.01         0.39         0.46         0.31        0.49   \n",
       "4         0.02         1.00         1.00         1.00        0.14   \n",
       "\n",
       "          ...           NumStreet  PctForeignBorn  PctBornSameState  \\\n",
       "0         ...                0.00            0.03              0.70   \n",
       "1         ...                0.00            0.00              0.93   \n",
       "2         ...                0.02            0.04              0.77   \n",
       "3         ...                0.00            0.03              0.78   \n",
       "4         ...                0.00            0.12              0.49   \n",
       "\n",
       "   PctSameHouse85  PctSameCity85  PctSameState85  LandArea  PopDens  \\\n",
       "0            0.40           0.34            0.57      0.05     0.06   \n",
       "1            0.66           0.82            0.84      0.11     0.03   \n",
       "2            0.59           0.70            0.64      0.06     0.11   \n",
       "3            0.56           0.67            0.71      0.09     0.05   \n",
       "4            0.12           0.00            0.15      0.09     0.09   \n",
       "\n",
       "   PctUsePubTrans  LemasPctOfficDrugUn  \n",
       "0            0.01                  0.0  \n",
       "1            0.01                  0.0  \n",
       "2            0.04                  0.0  \n",
       "3            0.00                  0.0  \n",
       "4            0.01                  0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the label into proper binary labels\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "# Remove the non-predictive and the target column form the data\n",
    "dataContinuous = crimeDF.drop(nonPredictiveFeatures+regTargetVar+classTargetVar, 1)  \n",
    "# Convert the target column into binomial label vector\n",
    "targetBinomial = lb.fit_transform(crimeDF['highCrime']).flatten()      \n",
    "\n",
    "print ('The shape of dataForDT after preprocessing is: ', dataContinuous.shape)\n",
    "print ('The shape of targetForDT after preprocessing is: ', targetBinomial.shape)\n",
    "# print (dataForDT)\n",
    "print (targetBinomial)\n",
    "dataContinuous.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. What are the training accuracy, precision, and recall for this tree? \n",
    "\n",
    "Solution: \n",
    "\n",
    "Accuracy = 1.0, Precision = 1.0, Recall = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Fitting Decision tree classifier:\n",
    "classifierDT = tree.DecisionTreeClassifier()\n",
    "classifierDT = classifierDT.fit(dataContinuous, targetBinomial)\n",
    "\n",
    "# Predict on the training Data\n",
    "predForDT = classifierDT.predict(dataContinuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the decision tree classifier is:  1.0\n",
      "The precision of the decision tree classifier is:  1.0\n",
      "The recall of the decision tree classifier is:  1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>743</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0     1\n",
       "row_0           \n",
       "0      743     0\n",
       "1        0  1250"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Precision and Recall\n",
    "cnfMatrix = pd.crosstab(targetBinomial, predForDT)\n",
    "cnfMatrix\n",
    "tpDT =  cnfMatrix.iloc[1][1]\n",
    "tnDT =  cnfMatrix.iloc[0][0]\n",
    "fpDT =  cnfMatrix.iloc[0][1]\n",
    "fnDT =  cnfMatrix.iloc[1][0]\n",
    "print ('The accuracy of the decision tree classifier is: ', (tpDT+tnDT)/(tpDT+tnDT+fpDT+fnDT))\n",
    "print ('The precision of the decision tree classifier is: ', tpDT/(tpDT+fpDT))\n",
    "print ('The recall of the decision tree classifier is: ', tpDT/(tpDT+fnDT))\n",
    "# cnfMatrix.iloc[0][0] + cnfMatrix.iloc[1][1]/(cnfMatrix.iloc[0][0] + cnfMatrix.iloc[1][1] + cnfMatrix.iloc[0][0] + cnfMatrix.iloc[1][1])\n",
    "cnfMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "ii. What are the main features used for classification? Can you explain why they make sense (or not)?\n",
    "\n",
    "Solution: \n",
    "\n",
    "PctKids2Par : percentage of kids in family housing with two parents\n",
    "\n",
    "racePctWhite :\n",
    "\n",
    "PctLess9thGrade: percentage of people 25 and over with less than a 9th grade education\n",
    "\n",
    "PctEmplManu : percentage of people 16 and over who are employed in manufacturing\n",
    "\n",
    "blackPerCap : per capita income for african americans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Top 5 features are selected by decision tree is: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>infoGain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>PctKids2Par</td>\n",
       "      <td>0.358652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>racePctWhite</td>\n",
       "      <td>0.088817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>racePctHisp</td>\n",
       "      <td>0.048585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PctLess9thGrade</td>\n",
       "      <td>0.023864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PctEmplManu</td>\n",
       "      <td>0.021210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>blackPerCap</td>\n",
       "      <td>0.015154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>PctLargHouseFam</td>\n",
       "      <td>0.014203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>PctHousOwnOcc</td>\n",
       "      <td>0.013686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>PctWOFullPlumb</td>\n",
       "      <td>0.013076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>PctImmigRec10</td>\n",
       "      <td>0.011994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature_name  infoGain\n",
       "44      PctKids2Par  0.358652\n",
       "3      racePctWhite  0.088817\n",
       "5       racePctHisp  0.048585\n",
       "29  PctLess9thGrade  0.023864\n",
       "34      PctEmplManu  0.021210\n",
       "22      blackPerCap  0.015154\n",
       "62  PctLargHouseFam  0.014203\n",
       "73    PctHousOwnOcc  0.013686\n",
       "78   PctWOFullPlumb  0.013076\n",
       "55    PctImmigRec10  0.011994"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best Fetures: Information gain with GINI\n",
    "ImpfeatureDF = pd.DataFrame(columns=['feature_name', 'infoGain'])\n",
    "featureVec = np.array(dataContinuous.columns)\n",
    "ImpfeatureDF['feature_name'] = np.array(dataContinuous.columns)\n",
    "# print (featureVec)\n",
    "ImpfeatureDF['infoGain'] = classifierDT.feature_importances_\n",
    "\n",
    "print ('The Top 5 features selected by decision tree are: ')\n",
    "ImpfeatureDF.sort_values('infoGain', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part (c):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "i. What are the 10-fold cross-validation accuracy, precision, and recall?\n",
    "\n",
    "Solutions: mean n-fold Accuracy = 0.7735, mean n-fold Precision = 0.802457540816 and mean Recall = 0.827406078072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the decision tree classifier is [ 0.755  0.76   0.79   0.765  0.74   0.765  0.785  0.78   0.795  0.8  ] and their mean is :  0.7735\n",
      "The 10 Fold precision of the decision tree classifier is [ 0.80314961  0.80487805  0.85365854  0.83193277  0.76744186  0.76153846\n",
      "  0.77304965  0.81538462  0.81679389  0.79674797] and their mean is :  0.802457540816\n",
      "The 10 Fold recall of the decision tree classifier is [ 0.8         0.84745763  0.81395349  0.73015873  0.85470085  0.81034483\n",
      "  0.86885246  0.87903226  0.86614173  0.8034188 ] and their mean is :  0.827406078072\n"
     ]
    }
   ],
   "source": [
    "# import random\n",
    "# random.seed(3213)\n",
    "classifierDT = tree.DecisionTreeClassifier()\n",
    "\n",
    "nfoldACC = model_selection.cross_val_score(classifierDT, dataContinuous, targetBinomial, cv=cv, scoring='accuracy')\n",
    "nfoldPrecision = model_selection.cross_val_score(classifierDT, dataContinuous, targetBinomial, cv=cv, scoring='precision')\n",
    "nfoldRecall = model_selection.cross_val_score(classifierDT, dataContinuous, targetBinomial, cv=cv, scoring='recall')\n",
    "\n",
    "print ('The 10 Fold accuracy of the decision tree classifier is %s and their mean is : '%(str(nfoldACC)), np.mean(nfoldACC))\n",
    "print ('The 10 Fold precision of the decision tree classifier is %s and their mean is : '%(str(nfoldPrecision)), np.mean(nfoldPrecision))\n",
    "print ('The 10 Fold recall of the decision tree classifier is %s and their mean is : '%(str(nfoldRecall)), np.mean(nfoldRecall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "ii. Why are they different from the results in the previous test?\n",
    "\n",
    "Solution:\n",
    "In the first Decision Tree fit, since we fit on the whole dataset, the tree learned the entire data and made very good classification with 100% accuracy, precision and recall. This states that the previous method is prone to overfitting and may not generalize well for a new data. As data are always noisy. In the current model since we do crossvalidation we train on separate data and test on separate data. Thw model doesnt perform very well on the rest data and hence the accuracy. precision and recall of the model decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2. Linear Classification:\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part (a) :-  GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "i. What is the 10-fold cross-validation accuracy, precision, and recall for this method?\n",
    "\n",
    "Solutions: mean n-fold Accuracy = 0.7865, mean n-fold Precision = 0.930803183479 and mean Recall = 0.703736494399"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the gaussian naive bayes classifier is [ 0.785  0.795  0.745  0.77   0.795  0.785  0.825  0.805  0.78   0.78 ] and their mean is :  0.7865\n",
      "The 10 Fold precision of the gaussian naive bayes classifier is [ 0.96590909  0.93258427  0.90625     0.95454545  0.90425532  0.96202532\n",
      "  0.93939394  0.91262136  0.94623656  0.88421053] and their mean is :  0.930803183479\n",
      "The 10 Fold recall of the gaussian naive bayes classifier is [ 0.68        0.70338983  0.6744186   0.66666667  0.72649573  0.65517241\n",
      "  0.76229508  0.75806452  0.69291339  0.71794872] and their mean is :  0.703736494399\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifierGNB = GaussianNB()\n",
    "# classifierGNB.fit()\n",
    "\n",
    "nfoldACC = model_selection.cross_val_score(classifierGNB, dataContinuous, targetBinomial, cv=cv, scoring='accuracy')\n",
    "nfoldPrecision = model_selection.cross_val_score(classifierGNB, dataContinuous, targetBinomial, cv=cv, scoring='precision')\n",
    "nfoldRecall = model_selection.cross_val_score(classifierGNB, dataContinuous, targetBinomial, cv=cv, scoring='recall')\n",
    "\n",
    "print ('The 10 Fold accuracy of the gaussian naive bayes classifier is %s and their mean is : '%(str(nfoldACC)), np.mean(nfoldACC))\n",
    "print ('The 10 Fold precision of the gaussian naive bayes classifier is %s and their mean is : '%(str(nfoldPrecision)), np.mean(nfoldPrecision))\n",
    "print ('The 10 Fold recall of the gaussian naive bayes classifier is %s and their mean is : '%(str(nfoldRecall)), np.mean(nfoldRecall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "ii. What are the 10 most predictive features? This can be measured by the normalized absolute difference of means for the feature between the two classes:\n",
    "\n",
    "Solution: The 10 most predictive features are given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>PredictivePower</th>\n",
       "      <th>NegPos-Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>PctKids2Par</td>\n",
       "      <td>0.809748</td>\n",
       "      <td>-0.809748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>PctFam2Par</td>\n",
       "      <td>0.745545</td>\n",
       "      <td>-0.745545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>racePctWhite</td>\n",
       "      <td>0.73523</td>\n",
       "      <td>-0.73523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>PctIlleg</td>\n",
       "      <td>0.709261</td>\n",
       "      <td>0.709261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>FemalePctDiv</td>\n",
       "      <td>0.693978</td>\n",
       "      <td>0.693978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TotalPctDiv</td>\n",
       "      <td>0.674645</td>\n",
       "      <td>0.674645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>PctYoungKids2Par</td>\n",
       "      <td>0.665009</td>\n",
       "      <td>-0.665009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pctWInvInc</td>\n",
       "      <td>0.661076</td>\n",
       "      <td>-0.661076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>PctTeen2Par</td>\n",
       "      <td>0.642949</td>\n",
       "      <td>-0.642949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>MalePctDivorce</td>\n",
       "      <td>0.616864</td>\n",
       "      <td>0.616864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>racepctblack</td>\n",
       "      <td>0.578923</td>\n",
       "      <td>0.578923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pctWPubAsst</td>\n",
       "      <td>0.577968</td>\n",
       "      <td>0.577968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>PctPersOwnOccup</td>\n",
       "      <td>0.560887</td>\n",
       "      <td>-0.560887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>PctPersDenseHous</td>\n",
       "      <td>0.539324</td>\n",
       "      <td>0.539324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>PctHousLess3BR</td>\n",
       "      <td>0.515117</td>\n",
       "      <td>0.515117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>PctHousNoPhone</td>\n",
       "      <td>0.514508</td>\n",
       "      <td>0.514508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PctPopUnderPov</td>\n",
       "      <td>0.499676</td>\n",
       "      <td>0.499676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>PctUnemployed</td>\n",
       "      <td>0.49086</td>\n",
       "      <td>0.49086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>PctHousOwnOcc</td>\n",
       "      <td>0.47944</td>\n",
       "      <td>-0.47944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>PctNotHSGrad</td>\n",
       "      <td>0.469018</td>\n",
       "      <td>0.469018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_name PredictivePower NegPos-Coefficient\n",
       "44       PctKids2Par        0.809748          -0.809748\n",
       "43        PctFam2Par        0.745545          -0.745545\n",
       "3       racePctWhite         0.73523           -0.73523\n",
       "50          PctIlleg        0.709261           0.709261\n",
       "40      FemalePctDiv        0.693978           0.693978\n",
       "41       TotalPctDiv        0.674645           0.674645\n",
       "45  PctYoungKids2Par        0.665009          -0.665009\n",
       "15        pctWInvInc        0.661076          -0.661076\n",
       "46       PctTeen2Par        0.642949          -0.642949\n",
       "38    MalePctDivorce        0.616864           0.616864\n",
       "2       racepctblack        0.578923           0.578923\n",
       "17       pctWPubAsst        0.577968           0.577968\n",
       "67   PctPersOwnOccup        0.560887          -0.560887\n",
       "68  PctPersDenseHous        0.539324           0.539324\n",
       "69    PctHousLess3BR        0.515117           0.515117\n",
       "77    PctHousNoPhone        0.514508           0.514508\n",
       "28    PctPopUnderPov        0.499676           0.499676\n",
       "32     PctUnemployed         0.49086            0.49086\n",
       "73     PctHousOwnOcc         0.47944           -0.47944\n",
       "30      PctNotHSGrad        0.469018           0.469018"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexClassNo = np.where(targetBinomial==0)[0]\n",
    "indexClassYes = np.where(targetBinomial==1)[0]\n",
    "# print (indexClassYes)\n",
    "\n",
    "NBfeauturePredictivePower = pd.DataFrame(columns=['feature_name','PredictivePower','NegPos-Coefficient'])\n",
    "NBfeauturePredictivePower['feature_name'] = np.array(dataContinuous.columns)\n",
    "\n",
    "for num, features in enumerate(dataContinuous.columns):\n",
    "    meanNo = np.mean(dataContinuous[features][indexClassNo])\n",
    "    meanYes = np.mean(dataContinuous[features][indexClassYes])\n",
    "    stdNo = np.std(dataContinuous[features][indexClassNo])\n",
    "    stdYes = np.std(dataContinuous[features][indexClassYes])\n",
    "    \n",
    "    predictivePower = np.abs(meanYes - meanNo)/(stdYes + stdNo)\n",
    "    negPosCoefficient = (meanYes - meanNo)/(stdYes + stdNo)\n",
    "    NBfeauturePredictivePower.ix[num, 'PredictivePower'] = predictivePower\n",
    "    NBfeauturePredictivePower.ix[num, 'NegPos-Coefficient'] = negPosCoefficient\n",
    "\n",
    "\n",
    "NBfeauturePredictivePower.sort_values('PredictivePower', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "iii. How do these results compare with your results from decision trees, above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part (b) :-  LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "i. What is the 10-fold cross-validation accuracy, precision, and recall for this method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the gaussian naive bayes classifier is [ 0.84   0.835  0.845  0.86   0.815  0.805  0.865  0.845  0.835  0.845] and their mean is :  0.839\n",
      "The 10 Fold precision of the gaussian naive bayes classifier is [ 0.88429752  0.85123967  0.8828125   0.90163934  0.81746032  0.83478261\n",
      "  0.89256198  0.84444444  0.89830508  0.8359375 ] and their mean is :  0.864348097316\n",
      "The 10 Fold recall of the gaussian naive bayes classifier is [ 0.856       0.87288136  0.87596899  0.87301587  0.88034188  0.82758621\n",
      "  0.8852459   0.91935484  0.83464567  0.91452991] and their mean is :  0.87395706326\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "classifierSVC = LinearSVC()\n",
    "# classifierGNB.fit()\n",
    "\n",
    "nfoldACC = model_selection.cross_val_score(classifierSVC, dataContinuous, targetBinomial, cv=cv, scoring='accuracy')\n",
    "nfoldPrecision = model_selection.cross_val_score(classifierSVC, dataContinuous, targetBinomial, cv=cv, scoring='precision')\n",
    "nfoldRecall = model_selection.cross_val_score(classifierSVC, dataContinuous, targetBinomial, cv=cv, scoring='recall')\n",
    "\n",
    "print ('The 10 Fold accuracy of the gaussian naive bayes classifier is %s and their mean is : '%(str(nfoldACC)), np.mean(nfoldACC))\n",
    "print ('The 10 Fold precision of the gaussian naive bayes classifier is %s and their mean is : '%(str(nfoldPrecision)), np.mean(nfoldPrecision))\n",
    "print ('The 10 Fold recall of the gaussian naive bayes classifier is %s and their mean is : '%(str(nfoldRecall)), np.mean(nfoldRecall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "ii. What are the 10 most predictive features? This can be measured by the absolute feature weights in the model. Why do these make sense (or not)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>featureWeights</th>\n",
       "      <th>negPosWeights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pctWInvInc</td>\n",
       "      <td>1.891001</td>\n",
       "      <td>-1.891001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>PersPerOccupHous</td>\n",
       "      <td>1.753985</td>\n",
       "      <td>1.753985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>racePctWhite</td>\n",
       "      <td>1.500055</td>\n",
       "      <td>-1.500055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>PctKids2Par</td>\n",
       "      <td>1.191181</td>\n",
       "      <td>-1.191181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>RentHighQ</td>\n",
       "      <td>1.066864</td>\n",
       "      <td>1.066864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>MalePctDivorce</td>\n",
       "      <td>1.065301</td>\n",
       "      <td>1.065301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NumUnderPov</td>\n",
       "      <td>1.050941</td>\n",
       "      <td>1.050941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>NumStreet</td>\n",
       "      <td>1.019857</td>\n",
       "      <td>1.019857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>PctOccupMgmtProf</td>\n",
       "      <td>1.016436</td>\n",
       "      <td>1.016436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>population</td>\n",
       "      <td>1.002225</td>\n",
       "      <td>1.002225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_name  featureWeights  negPosWeights\n",
       "15        pctWInvInc        1.891001      -1.891001\n",
       "64  PersPerOccupHous        1.753985       1.753985\n",
       "3       racePctWhite        1.500055      -1.500055\n",
       "44       PctKids2Par        1.191181      -1.191181\n",
       "84         RentHighQ        1.066864       1.066864\n",
       "38    MalePctDivorce        1.065301       1.065301\n",
       "27       NumUnderPov        1.050941       1.050941\n",
       "90         NumStreet        1.019857       1.019857\n",
       "37  PctOccupMgmtProf        1.016436       1.016436\n",
       "0         population        1.002225       1.002225"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierSVC = classifierSVC.fit(dataContinuous, targetBinomial)\n",
    "\n",
    "SVCfeauturePredictivePower = pd.DataFrame(columns=['feature_name','featureWeights', 'negPosWeights'])\n",
    "SVCfeauturePredictivePower['feature_name'] = np.array(dataContinuous.columns)\n",
    "SVCfeauturePredictivePower['featureWeights'] = np.abs(classifierSVC.coef_).flatten()\n",
    "SVCfeauturePredictivePower['negPosWeights'] = classifierSVC.coef_.flatten()\n",
    "SVCfeauturePredictivePower.sort_values('featureWeights', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3. Regression:\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part (a) : Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "i. Using 10-fold cross-validation, what is the estimated mean-squared-error (MSE) of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold mean squared error of the linear regression model is [0.018571812010381092, 0.019937673075568253, 0.021118718947362895, 0.015449687510177067, 0.016512056355443512, 0.014169593859648, 0.01684571351236135, 0.019708872904223955, 0.024066076630366071, 0.022842571153692627] and their mean is :  0.0189222775959\n"
     ]
    }
   ],
   "source": [
    "# Load the data to fit linear model, To fit the linear model the data would be the same, however the target would change to continuous Variable\n",
    "# Remove the non-predictive and the target column form the data\n",
    "targetContinuous = crimeDF[regTargetVar]\n",
    "\n",
    "# Fit a linear model for cross vlidation:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "classifierLR = LinearRegression()\n",
    "\n",
    "nfoldMSE = model_selection.cross_val_score(classifierLR, dataContinuous, targetContinuous, cv=cv, scoring='neg_mean_squared_error')\n",
    "\n",
    "# The sign of the mean squared error in scipy api is flipped, the values are the same, when using negative the larger is the better\n",
    "posMSEarr = [np.abs(mseval) for mseval in nfoldMSE]\n",
    "print ('The 10 Fold mean squared error of the linear regression model is %s and their mean is : '%(str(posMSEarr)), np.mean(posMSEarr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "ii. What is the MSE on the training set (train on all the data then test on it all)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE on the training set for the Linear model is : 0.0165167748803\n"
     ]
    }
   ],
   "source": [
    "classifierLR = classifierLR.fit(dataContinuous, targetContinuous)\n",
    "predictContinuousLR = classifierLR.predict(dataContinuous).flatten()\n",
    "mseLR = metrics.mean_squared_error(targetContinuous, predictContinuousLR)\n",
    "\n",
    "print ('The MSE on the training set for the Linear model is :', mseLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "iii. What features are most predictive of a high crime rate? A low crime rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features most predictive of a high crime rate and low crime rate and their respective weights are: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>highCrimePredictive_features</th>\n",
       "      <th>high_featureWeight</th>\n",
       "      <th>lowCrimePredictive_features</th>\n",
       "      <th>low_featureWeight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PersPerOccupHous</td>\n",
       "      <td>0.635088</td>\n",
       "      <td>PctPersOwnOccup</td>\n",
       "      <td>-0.675694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PctHousOwnOcc</td>\n",
       "      <td>0.568133</td>\n",
       "      <td>TotalPctDiv</td>\n",
       "      <td>-0.561924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MalePctDivorce</td>\n",
       "      <td>0.458517</td>\n",
       "      <td>whitePerCap</td>\n",
       "      <td>-0.351016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PctRecImmig8</td>\n",
       "      <td>0.432511</td>\n",
       "      <td>PctKids2Par</td>\n",
       "      <td>-0.322651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MedRent</td>\n",
       "      <td>0.372728</td>\n",
       "      <td>OwnOccLowQuart</td>\n",
       "      <td>-0.308170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  highCrimePredictive_features  high_featureWeight  \\\n",
       "0             PersPerOccupHous            0.635088   \n",
       "1                PctHousOwnOcc            0.568133   \n",
       "2               MalePctDivorce            0.458517   \n",
       "3                 PctRecImmig8            0.432511   \n",
       "4                      MedRent            0.372728   \n",
       "\n",
       "  lowCrimePredictive_features  low_featureWeight  \n",
       "0             PctPersOwnOccup          -0.675694  \n",
       "1                 TotalPctDiv          -0.561924  \n",
       "2                 whitePerCap          -0.351016  \n",
       "3                 PctKids2Par          -0.322651  \n",
       "4              OwnOccLowQuart          -0.308170  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRfeauturePredictivePower = pd.DataFrame(columns=['highCrimePredictive_features','high_featureWeight', 'lowCrimePredictive_features','low_featureWeight'])\n",
    "\n",
    "top5Weight_index = classifierLR.coef_.flatten().argsort()[-5:][::-1]   # Find the indices of top most feature weights\n",
    "lowest5Weight_index = classifierLR.coef_.flatten().argsort()[:5]\n",
    "\n",
    "top5Weights = classifierLR.coef_.flatten()[top5Weight_index]\n",
    "lowest5Weights = classifierLR.coef_.flatten()[lowest5Weight_index]\n",
    "\n",
    "high_CrimeFeatures = dataContinuous.columns[top5Weight_index]\n",
    "low_CrimeFeatures = dataContinuous.columns[lowest5Weight_index]\n",
    "\n",
    "LRfeauturePredictivePower['highCrimePredictive_features'] = high_CrimeFeatures\n",
    "LRfeauturePredictivePower['high_featureWeight'] = top5Weights\n",
    "LRfeauturePredictivePower['lowCrimePredictive_features'] = low_CrimeFeatures\n",
    "LRfeauturePredictivePower['low_featureWeight'] = lowest5Weights\n",
    "\n",
    "print ('The features most predictive of a high crime rate and low crime rate and their respective weights are: ')\n",
    "LRfeauturePredictivePower.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part (b) : Ridge Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "i. What is the estimated MSE of the model under 10-fold CV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE for the best model based on cross validation is (0.0167635291552) and the corresponding norm co-efficient alpha is:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "alpha = np.array([10, 1, 0.1, 0.01, 0.001], dtype='float64')\n",
    "\n",
    "classifierRR_cv = RidgeCV(alpha, cv=cv)\n",
    "\n",
    "classifierRR_cv = classifierRR_cv.fit(dataContinuous, targetContinuous)\n",
    "predictionContinuousRR_cv = classifierRR_cv.predict(dataContinuous)\n",
    "# print (predictContinuous)\n",
    "\n",
    "mseRR_Best = metrics.mean_squared_error(targetContinuous, predictionContinuousRR_cv)\n",
    "alpha_Best = classifierRR_cv.alpha_\n",
    "print ('The MSE for the best model based on cross validation is (%s) and the corresponding norm co-efficient alpha is: '%str(mseRR_Best), alpha_Best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "ii. What is the MSE on the training set (train on all the data then test on it all)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE for the Ridge Regression model with default parameter setting is:  0.0167635291552\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "classifierRR = Ridge()\n",
    "classifierRR = classifierRR.fit(dataContinuous, targetContinuous)\n",
    "predictionContinuousRR = classifierRR.predict(dataContinuous)\n",
    "\n",
    "mseRR = metrics.mean_squared_error(targetContinuous, predictionContinuousRR)\n",
    "print ('The MSE for the Ridge Regression model with default parameter setting is: ', mseRR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "iii. What is the best alpha?\n",
    "\n",
    "Solution: The best alpha value is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "iv. What does this say about the amount of overfitting in linear regression for this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Part (c) : Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "i. What is the estimated MSE of the model under 10-fold CV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the 2nd order dataset is:  (1993, 5151)\n",
      "The 10 Fold mean squared error of the linear regression model is [0.091388554482501355, 0.075553464088000052, 0.094912422334410704, 0.092169643279396099, 0.12734117666192893, 0.10154176579614323, 0.084699443868283222, 0.089201570560247634, 0.14535794713774755, 0.10509797066470958] and their mean is :  0.100726395887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "classifierPR = PolynomialFeatures(degree=2)\n",
    "dataContinuousPoly = classifierPR.fit_transform(dataContinuous)\n",
    "print ('The shape of the 2nd order dataset is: ', dataContinuousPoly.shape)\n",
    "\n",
    "classifierLR_poly = LinearRegression()\n",
    "nFoldMSE_poly = model_selection.cross_val_score(classifierLR_poly, dataContinuousPoly, targetContinuous, cv=cv, scoring='neg_mean_squared_error')\n",
    "\n",
    "posMSEarr_poly = [np.abs(mseval) for mseval in nFoldMSE_poly]\n",
    "print ('The 10 Fold mean squared error of the linear regression model is %s and their mean is : '%(str(posMSEarr_poly)), np.mean(posMSEarr_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE (polynomial features) for the best model based on cross validation is (0.0122517620613) and the corresponding norm co-efficient alpha is:  10.0\n"
     ]
    }
   ],
   "source": [
    "classifierRR_poly = RidgeCV(alpha, cv=cv)\n",
    "\n",
    "classifierRR_poly = classifierRR_poly.fit(dataContinuousPoly, targetContinuous)\n",
    "predictionContinuousRR_poly = classifierRR_poly.predict(dataContinuousPoly)\n",
    "# print (predictContinuous)\n",
    "\n",
    "mseRR_poly_Best = metrics.mean_squared_error(targetContinuous, predictionContinuousRR_poly)\n",
    "alpha_poly_Best = classifierRR_poly.alpha_\n",
    "# print (classifierRR.decision_function)\n",
    "print ('The MSE (polynomial features) for the best model based on cross validation is (%s) and the corresponding norm co-efficient alpha is: '%str(mseRR_poly_Best), alpha_poly_Best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "ii. What is the MSE on the training set (train on all the data then test on it all)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (polynomial features) of the linear regression model is 1.79748563752e-28 : \n"
     ]
    }
   ],
   "source": [
    "classifierLR_poly = LinearRegression()\n",
    "classifierLR_poly = classifierLR_poly.fit(dataContinuousPoly, targetContinuous)\n",
    "predictContinuousLR_poly = classifierLR_poly.predict(dataContinuousPoly).flatten()\n",
    "\n",
    "mseLR_poly = metrics.mean_squared_error(targetContinuous, predictContinuousLR_poly)\n",
    "\n",
    "print ('The mean squared error (polynomial features) of the linear regression model is %s : '%(str(mseLR_poly)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "iii. Does this mean the quadratic model is better than the linear model for this problem?\n",
    "\n",
    "Solution: Despite the MSE of the polynomial feature space (quadratic) much closer to 0, the quadratic model is not a good fit. Because, the model learns the training data very well. This scenario may lead to overfitting as the real world dataset is more noisy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Dirty Data\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### a) Repeat the decision tree learning question for the full (non-clean) data set and present the results. Are the CV results better or worse? What does this say about the effect of missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1994, 128)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>community</th>\n",
       "      <th>communityname</th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>numbUrban</th>\n",
       "      <th>pctUrban</th>\n",
       "      <th>medIncome</th>\n",
       "      <th>pctWWage</th>\n",
       "      <th>pctWFarmSelf</th>\n",
       "      <th>pctWInvInc</th>\n",
       "      <th>pctWSocSec</th>\n",
       "      <th>pctWPubAsst</th>\n",
       "      <th>pctWRetire</th>\n",
       "      <th>medFamInc</th>\n",
       "      <th>perCapInc</th>\n",
       "      <th>whitePerCap</th>\n",
       "      <th>blackPerCap</th>\n",
       "      <th>indianPerCap</th>\n",
       "      <th>AsianPerCap</th>\n",
       "      <th>OtherPerCap</th>\n",
       "      <th>HispPerCap</th>\n",
       "      <th>NumUnderPov</th>\n",
       "      <th>PctPopUnderPov</th>\n",
       "      <th>PctLess9thGrade</th>\n",
       "      <th>PctNotHSGrad</th>\n",
       "      <th>PctBSorMore</th>\n",
       "      <th>PctUnemployed</th>\n",
       "      <th>PctEmploy</th>\n",
       "      <th>PctEmplManu</th>\n",
       "      <th>PctEmplProfServ</th>\n",
       "      <th>PctOccupManu</th>\n",
       "      <th>PctOccupMgmtProf</th>\n",
       "      <th>MalePctDivorce</th>\n",
       "      <th>MalePctNevMarr</th>\n",
       "      <th>FemalePctDiv</th>\n",
       "      <th>TotalPctDiv</th>\n",
       "      <th>PersPerFam</th>\n",
       "      <th>PctFam2Par</th>\n",
       "      <th>PctKids2Par</th>\n",
       "      <th>PctYoungKids2Par</th>\n",
       "      <th>PctTeen2Par</th>\n",
       "      <th>PctWorkMomYoungKids</th>\n",
       "      <th>PctWorkMom</th>\n",
       "      <th>NumIlleg</th>\n",
       "      <th>PctIlleg</th>\n",
       "      <th>NumImmig</th>\n",
       "      <th>PctImmigRecent</th>\n",
       "      <th>PctImmigRec5</th>\n",
       "      <th>PctImmigRec8</th>\n",
       "      <th>PctImmigRec10</th>\n",
       "      <th>PctRecentImmig</th>\n",
       "      <th>PctRecImmig5</th>\n",
       "      <th>PctRecImmig8</th>\n",
       "      <th>PctRecImmig10</th>\n",
       "      <th>PctSpeakEnglOnly</th>\n",
       "      <th>PctNotSpeakEnglWell</th>\n",
       "      <th>PctLargHouseFam</th>\n",
       "      <th>PctLargHouseOccup</th>\n",
       "      <th>PersPerOccupHous</th>\n",
       "      <th>PersPerOwnOccHous</th>\n",
       "      <th>PersPerRentOccHous</th>\n",
       "      <th>PctPersOwnOccup</th>\n",
       "      <th>PctPersDenseHous</th>\n",
       "      <th>PctHousLess3BR</th>\n",
       "      <th>MedNumBR</th>\n",
       "      <th>HousVacant</th>\n",
       "      <th>PctHousOccup</th>\n",
       "      <th>PctHousOwnOcc</th>\n",
       "      <th>PctVacantBoarded</th>\n",
       "      <th>PctVacMore6Mos</th>\n",
       "      <th>MedYrHousBuilt</th>\n",
       "      <th>PctHousNoPhone</th>\n",
       "      <th>PctWOFullPlumb</th>\n",
       "      <th>OwnOccLowQuart</th>\n",
       "      <th>OwnOccMedVal</th>\n",
       "      <th>OwnOccHiQuart</th>\n",
       "      <th>RentLowQ</th>\n",
       "      <th>RentMedian</th>\n",
       "      <th>RentHighQ</th>\n",
       "      <th>MedRent</th>\n",
       "      <th>MedRentPctHousInc</th>\n",
       "      <th>MedOwnCostPctInc</th>\n",
       "      <th>MedOwnCostPctIncNoMtg</th>\n",
       "      <th>NumInShelters</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LemasSwornFT</th>\n",
       "      <th>LemasSwFTPerPop</th>\n",
       "      <th>LemasSwFTFieldOps</th>\n",
       "      <th>LemasSwFTFieldPerPop</th>\n",
       "      <th>LemasTotalReq</th>\n",
       "      <th>LemasTotReqPerPop</th>\n",
       "      <th>PolicReqPerOffic</th>\n",
       "      <th>PolicPerPop</th>\n",
       "      <th>RacialMatchCommPol</th>\n",
       "      <th>PctPolicWhite</th>\n",
       "      <th>PctPolicBlack</th>\n",
       "      <th>PctPolicHisp</th>\n",
       "      <th>PctPolicAsian</th>\n",
       "      <th>PctPolicMinor</th>\n",
       "      <th>OfficAssgnDrugUnits</th>\n",
       "      <th>NumKindsDrugsSeiz</th>\n",
       "      <th>PolicAveOTWorked</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>PolicCars</th>\n",
       "      <th>PolicOperBudg</th>\n",
       "      <th>LemasPctPolicOnPatr</th>\n",
       "      <th>LemasGangUnitDeploy</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>PolicBudgPerPop</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Lakewoodcity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Tukwilacity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Aberdeentown</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>81440</td>\n",
       "      <td>Willingborotownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>95</td>\n",
       "      <td>6096</td>\n",
       "      <td>Bethlehemtownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state county community        communityname  fold  population  \\\n",
       "0      8      ?         ?         Lakewoodcity     1        0.19   \n",
       "1     53      ?         ?          Tukwilacity     1        0.00   \n",
       "2     24      ?         ?         Aberdeentown     1        0.00   \n",
       "3     34      5     81440  Willingborotownship     1        0.04   \n",
       "4     42     95      6096    Bethlehemtownship     1        0.01   \n",
       "\n",
       "   householdsize  racepctblack  racePctWhite  racePctAsian  racePctHisp  \\\n",
       "0           0.33          0.02          0.90          0.12         0.17   \n",
       "1           0.16          0.12          0.74          0.45         0.07   \n",
       "2           0.42          0.49          0.56          0.17         0.04   \n",
       "3           0.77          1.00          0.08          0.12         0.10   \n",
       "4           0.55          0.02          0.95          0.09         0.05   \n",
       "\n",
       "   agePct12t21  agePct12t29  agePct16t24  agePct65up  numbUrban  pctUrban  \\\n",
       "0         0.34         0.47         0.29        0.32       0.20       1.0   \n",
       "1         0.26         0.59         0.35        0.27       0.02       1.0   \n",
       "2         0.39         0.47         0.28        0.32       0.00       0.0   \n",
       "3         0.51         0.50         0.34        0.21       0.06       1.0   \n",
       "4         0.38         0.38         0.23        0.36       0.02       0.9   \n",
       "\n",
       "   medIncome  pctWWage  pctWFarmSelf  pctWInvInc  pctWSocSec  pctWPubAsst  \\\n",
       "0       0.37      0.72          0.34        0.60        0.29         0.15   \n",
       "1       0.31      0.72          0.11        0.45        0.25         0.29   \n",
       "2       0.30      0.58          0.19        0.39        0.38         0.40   \n",
       "3       0.58      0.89          0.21        0.43        0.36         0.20   \n",
       "4       0.50      0.72          0.16        0.68        0.44         0.11   \n",
       "\n",
       "   pctWRetire  medFamInc  perCapInc  whitePerCap  blackPerCap  indianPerCap  \\\n",
       "0        0.43       0.39       0.40         0.39         0.32          0.27   \n",
       "1        0.39       0.29       0.37         0.38         0.33          0.16   \n",
       "2        0.84       0.28       0.27         0.29         0.27          0.07   \n",
       "3        0.82       0.51       0.36         0.40         0.39          0.16   \n",
       "4        0.71       0.46       0.43         0.41         0.28          0.00   \n",
       "\n",
       "   AsianPerCap OtherPerCap  HispPerCap  NumUnderPov  PctPopUnderPov  \\\n",
       "0         0.27        0.36        0.41         0.08            0.19   \n",
       "1         0.30        0.22        0.35         0.01            0.24   \n",
       "2         0.29        0.28        0.39         0.01            0.27   \n",
       "3         0.25        0.36        0.44         0.01            0.10   \n",
       "4         0.74        0.51        0.48         0.00            0.06   \n",
       "\n",
       "   PctLess9thGrade  PctNotHSGrad  PctBSorMore  PctUnemployed  PctEmploy  \\\n",
       "0             0.10          0.18         0.48           0.27       0.68   \n",
       "1             0.14          0.24         0.30           0.27       0.73   \n",
       "2             0.27          0.43         0.19           0.36       0.58   \n",
       "3             0.09          0.25         0.31           0.33       0.71   \n",
       "4             0.25          0.30         0.33           0.12       0.65   \n",
       "\n",
       "   PctEmplManu  PctEmplProfServ  PctOccupManu  PctOccupMgmtProf  \\\n",
       "0         0.23             0.41          0.25              0.52   \n",
       "1         0.57             0.15          0.42              0.36   \n",
       "2         0.32             0.29          0.49              0.32   \n",
       "3         0.36             0.45          0.37              0.39   \n",
       "4         0.67             0.38          0.42              0.46   \n",
       "\n",
       "   MalePctDivorce  MalePctNevMarr  FemalePctDiv  TotalPctDiv  PersPerFam  \\\n",
       "0            0.68            0.40          0.75         0.75        0.35   \n",
       "1            1.00            0.63          0.91         1.00        0.29   \n",
       "2            0.63            0.41          0.71         0.70        0.45   \n",
       "3            0.34            0.45          0.49         0.44        0.75   \n",
       "4            0.22            0.27          0.20         0.21        0.51   \n",
       "\n",
       "   PctFam2Par  PctKids2Par  PctYoungKids2Par  PctTeen2Par  \\\n",
       "0        0.55         0.59              0.61         0.56   \n",
       "1        0.43         0.47              0.60         0.39   \n",
       "2        0.42         0.44              0.43         0.43   \n",
       "3        0.65         0.54              0.83         0.65   \n",
       "4        0.91         0.91              0.89         0.85   \n",
       "\n",
       "   PctWorkMomYoungKids  PctWorkMom  NumIlleg  PctIlleg  NumImmig  \\\n",
       "0                 0.74        0.76      0.04      0.14      0.03   \n",
       "1                 0.46        0.53      0.00      0.24      0.01   \n",
       "2                 0.71        0.67      0.01      0.46      0.00   \n",
       "3                 0.85        0.86      0.03      0.33      0.02   \n",
       "4                 0.40        0.60      0.00      0.06      0.00   \n",
       "\n",
       "   PctImmigRecent  PctImmigRec5  PctImmigRec8  PctImmigRec10  PctRecentImmig  \\\n",
       "0            0.24          0.27          0.37           0.39            0.07   \n",
       "1            0.52          0.62          0.64           0.63            0.25   \n",
       "2            0.07          0.06          0.15           0.19            0.02   \n",
       "3            0.11          0.20          0.30           0.31            0.05   \n",
       "4            0.03          0.07          0.20           0.27            0.01   \n",
       "\n",
       "   PctRecImmig5  PctRecImmig8  PctRecImmig10  PctSpeakEnglOnly  \\\n",
       "0          0.07          0.08           0.08              0.89   \n",
       "1          0.27          0.25           0.23              0.84   \n",
       "2          0.02          0.04           0.05              0.88   \n",
       "3          0.08          0.11           0.11              0.81   \n",
       "4          0.02          0.04           0.05              0.88   \n",
       "\n",
       "   PctNotSpeakEnglWell  PctLargHouseFam  PctLargHouseOccup  PersPerOccupHous  \\\n",
       "0                 0.06             0.14               0.13              0.33   \n",
       "1                 0.10             0.16               0.10              0.17   \n",
       "2                 0.04             0.20               0.20              0.46   \n",
       "3                 0.08             0.56               0.62              0.85   \n",
       "4                 0.05             0.16               0.19              0.59   \n",
       "\n",
       "   PersPerOwnOccHous  PersPerRentOccHous  PctPersOwnOccup  PctPersDenseHous  \\\n",
       "0               0.39                0.28             0.55              0.09   \n",
       "1               0.29                0.17             0.26              0.20   \n",
       "2               0.52                0.43             0.42              0.15   \n",
       "3               0.77                1.00             0.94              0.12   \n",
       "4               0.60                0.37             0.89              0.02   \n",
       "\n",
       "   PctHousLess3BR  MedNumBR  HousVacant  PctHousOccup  PctHousOwnOcc  \\\n",
       "0            0.51       0.5        0.21          0.71           0.52   \n",
       "1            0.82       0.0        0.02          0.79           0.24   \n",
       "2            0.51       0.5        0.01          0.86           0.41   \n",
       "3            0.01       0.5        0.01          0.97           0.96   \n",
       "4            0.19       0.5        0.01          0.89           0.87   \n",
       "\n",
       "   PctVacantBoarded  PctVacMore6Mos  MedYrHousBuilt  PctHousNoPhone  \\\n",
       "0              0.05            0.26            0.65            0.14   \n",
       "1              0.02            0.25            0.65            0.16   \n",
       "2              0.29            0.30            0.52            0.47   \n",
       "3              0.60            0.47            0.52            0.11   \n",
       "4              0.04            0.55            0.73            0.05   \n",
       "\n",
       "   PctWOFullPlumb  OwnOccLowQuart  OwnOccMedVal  OwnOccHiQuart  RentLowQ  \\\n",
       "0            0.06            0.22          0.19           0.18      0.36   \n",
       "1            0.00            0.21          0.20           0.21      0.42   \n",
       "2            0.45            0.18          0.17           0.16      0.27   \n",
       "3            0.11            0.24          0.21           0.19      0.75   \n",
       "4            0.14            0.31          0.31           0.30      0.40   \n",
       "\n",
       "   RentMedian  RentHighQ  MedRent  MedRentPctHousInc  MedOwnCostPctInc  \\\n",
       "0        0.35       0.38     0.34               0.38              0.46   \n",
       "1        0.38       0.40     0.37               0.29              0.32   \n",
       "2        0.29       0.27     0.31               0.48              0.39   \n",
       "3        0.70       0.77     0.89               0.63              0.51   \n",
       "4        0.36       0.38     0.38               0.22              0.51   \n",
       "\n",
       "   MedOwnCostPctIncNoMtg  NumInShelters  NumStreet  PctForeignBorn  \\\n",
       "0                   0.25           0.04        0.0            0.12   \n",
       "1                   0.18           0.00        0.0            0.21   \n",
       "2                   0.28           0.00        0.0            0.14   \n",
       "3                   0.47           0.00        0.0            0.19   \n",
       "4                   0.21           0.00        0.0            0.11   \n",
       "\n",
       "   PctBornSameState  PctSameHouse85  PctSameCity85  PctSameState85  \\\n",
       "0              0.42            0.50           0.51            0.64   \n",
       "1              0.50            0.34           0.60            0.52   \n",
       "2              0.49            0.54           0.67            0.56   \n",
       "3              0.30            0.73           0.64            0.65   \n",
       "4              0.72            0.64           0.61            0.53   \n",
       "\n",
       "  LemasSwornFT LemasSwFTPerPop LemasSwFTFieldOps LemasSwFTFieldPerPop  \\\n",
       "0         0.03            0.13              0.96                 0.17   \n",
       "1            ?               ?                 ?                    ?   \n",
       "2            ?               ?                 ?                    ?   \n",
       "3            ?               ?                 ?                    ?   \n",
       "4            ?               ?                 ?                    ?   \n",
       "\n",
       "  LemasTotalReq LemasTotReqPerPop PolicReqPerOffic PolicPerPop  \\\n",
       "0          0.06              0.18             0.44        0.13   \n",
       "1             ?                 ?                ?           ?   \n",
       "2             ?                 ?                ?           ?   \n",
       "3             ?                 ?                ?           ?   \n",
       "4             ?                 ?                ?           ?   \n",
       "\n",
       "  RacialMatchCommPol PctPolicWhite PctPolicBlack PctPolicHisp PctPolicAsian  \\\n",
       "0               0.94          0.93          0.03         0.07           0.1   \n",
       "1                  ?             ?             ?            ?             ?   \n",
       "2                  ?             ?             ?            ?             ?   \n",
       "3                  ?             ?             ?            ?             ?   \n",
       "4                  ?             ?             ?            ?             ?   \n",
       "\n",
       "  PctPolicMinor OfficAssgnDrugUnits NumKindsDrugsSeiz PolicAveOTWorked  \\\n",
       "0          0.07                0.02              0.57             0.29   \n",
       "1             ?                   ?                 ?                ?   \n",
       "2             ?                   ?                 ?                ?   \n",
       "3             ?                   ?                 ?                ?   \n",
       "4             ?                   ?                 ?                ?   \n",
       "\n",
       "   LandArea  PopDens  PctUsePubTrans PolicCars PolicOperBudg  \\\n",
       "0      0.12     0.26            0.20      0.06          0.04   \n",
       "1      0.02     0.12            0.45         ?             ?   \n",
       "2      0.01     0.21            0.02         ?             ?   \n",
       "3      0.02     0.39            0.28         ?             ?   \n",
       "4      0.04     0.09            0.02         ?             ?   \n",
       "\n",
       "  LemasPctPolicOnPatr LemasGangUnitDeploy  LemasPctOfficDrugUn  \\\n",
       "0                 0.9                 0.5                 0.32   \n",
       "1                   ?                   ?                 0.00   \n",
       "2                   ?                   ?                 0.00   \n",
       "3                   ?                   ?                 0.00   \n",
       "4                   ?                   ?                 0.00   \n",
       "\n",
       "  PolicBudgPerPop  ViolentCrimesPerPop  \n",
       "0            0.14                 0.20  \n",
       "1               ?                 0.67  \n",
       "2               ?                 0.43  \n",
       "3               ?                 0.12  \n",
       "4               ?                 0.03  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datadir = '/Users/sam/All-Program/App-DataSet/Study/Crime-Prediction/communities-crime-full.csv'\n",
    "\n",
    "crimeDF_full = pd.read_csv(datadir, header='infer', sep=',')\n",
    "\n",
    "print (crimeDF_full.shape)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(crimeDF_full.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# impute all missing value (?) with "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Extra Credits\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### SVM with RBF Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "i. Here we build a SVM model-classification for varying range of c and gamma with RBF kernel.\n",
    "\n",
    "Approach: Here we define a range of coefficients for each parameter \"c\" and \"gamma\", Using a grid like structure we fit a \"rbf\" kernel for 10-fold cross validation. \"c\" makes the trade of between the misclassification error and simpler moder. A higher \"c\" would try to learn the training data and find more support vectors to support a very high degree of polynomial curve to fit all training points (non-regularized). \"gamma\" can be thought of as how much inverse of variance are we willing to tradeof for the support vectors. A high value of \"gamma\" would result in the radius of the area of influence of the support vectors only including the support vector.\n",
    "\n",
    "From the result we see that the best result is at [c= 1.0 and gamma = 0.01]\t[acc=0.818322, precision=0.900897, recall=0.8624]. This indicates a small value of \"gamma\" which can be understood that the dataset doesn't have a very good decision split. The smaller \"gamma\" also indicates that the model is unable to find the complex structure in the data, hence the model is close to a linear fit. Thats the rason that the evaluation metric of the \"rbf\" kernel is very simimlar to \"linear SVC\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "class SVM_model():\n",
    "\n",
    "    def __init__(self, kernel='rbf'):\n",
    "        self.c_range = [0.01, 0.1, 1.0, 10.0, 100.0]#, 1000.0]            \n",
    "        self.gamma_range = [0.001, 0.01, 0.1, 1, 10.0, 100]  \n",
    "        self.kernel=kernel\n",
    "\n",
    "    def classify(self, trainData, trainLabels, validData):\n",
    "        c_range = self.c_range\n",
    "        gamma_range = self.gamma_range\n",
    "        \n",
    "        pred_dict = {}\n",
    "        for (c,gamma) in itertools.product(c_range, gamma_range):\n",
    "            string = \"c\" + str(c) + \"_\" + \"gamma\" + str(gamma)  \n",
    "            clf = svm.SVC(kernel=self.kernel, C=c, gamma=gamma)\n",
    "            classifier = clf.fit(trainData,trainLabels)\n",
    "            pred_dict[string] = clf.predict(validData)\n",
    "        return pred_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Since the classes \"HighCrime\", \"LowCrime\" are unbalanced, We do stratifies Sampling and fetch 10-fold cross validation dataset.\n",
    "import itertools\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def buildModel(data, target):\n",
    "    dataContinuous_NDarr = np.array(data, dtype='float64')\n",
    "    targetBinomial_NDarr = np.array(target, dtype='float64')\n",
    "\n",
    "    stN_Fold = StratifiedKFold(n_splits=10, random_state=675)  # We use the same seed, to get a rought comparison of the model with all other models.\n",
    "    stN_Fold.get_n_splits(dataContinuous_NDarr, targetBinomial_NDarr)\n",
    "#     print (stN_Fold)\n",
    "\n",
    "\n",
    "    objSVM = SVM_model(kernel='rbf')\n",
    "    outputEvaluationDict = {}\n",
    "    validLabelDict = {}\n",
    "    for foldNUM, (trainIndex, validIndex) in enumerate(stN_Fold.split(dataContinuous_NDarr, targetBinomial_NDarr)):\n",
    "#         print(\"Train:\", len(trainIndex), \"CrossValid:\", len(validIndex))\n",
    "        if len(trainIndex)+len(validIndex) != len(dataContinuous):\n",
    "            raise ValueError('The length of the samples doesnt match')\n",
    "\n",
    "\n",
    "        outputEvaluationDict[foldNUM] = objSVM.classify(trainData=dataContinuous_NDarr[trainIndex], \n",
    "                                                        trainLabels=targetBinomial_NDarr[trainIndex], \n",
    "                                                        validData=dataContinuous_NDarr[validIndex])\n",
    "        validLabelDict[foldNUM] = targetBinomial_NDarr[validIndex]\n",
    "    return outputEvaluationDict, validLabelDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg-accuracy</th>\n",
       "      <th>avg-precision</th>\n",
       "      <th>avg-recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma0.001</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma0.01</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma0.1</th>\n",
       "      <td>0.654266</td>\n",
       "      <td>0.718042</td>\n",
       "      <td>0.9960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma1</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma10.0</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma100</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma0.001</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma0.01</th>\n",
       "      <td>0.766136</td>\n",
       "      <td>0.836136</td>\n",
       "      <td>0.9112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma0.1</th>\n",
       "      <td>0.806274</td>\n",
       "      <td>0.885295</td>\n",
       "      <td>0.8688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma1</th>\n",
       "      <td>0.701912</td>\n",
       "      <td>0.770044</td>\n",
       "      <td>0.9424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma10.0</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma100</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1.0_gamma0.001</th>\n",
       "      <td>0.768141</td>\n",
       "      <td>0.838141</td>\n",
       "      <td>0.9096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1.0_gamma0.01</th>\n",
       "      <td>0.819327</td>\n",
       "      <td>0.902533</td>\n",
       "      <td>0.8624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1.0_gamma0.1</th>\n",
       "      <td>0.806269</td>\n",
       "      <td>0.893046</td>\n",
       "      <td>0.8352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1.0_gamma1</th>\n",
       "      <td>0.754093</td>\n",
       "      <td>0.835436</td>\n",
       "      <td>0.8464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1.0_gamma10.0</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1.0_gamma100</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c10.0_gamma0.001</th>\n",
       "      <td>0.819327</td>\n",
       "      <td>0.902533</td>\n",
       "      <td>0.8608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c10.0_gamma0.01</th>\n",
       "      <td>0.809774</td>\n",
       "      <td>0.895374</td>\n",
       "      <td>0.8416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c10.0_gamma0.1</th>\n",
       "      <td>0.772168</td>\n",
       "      <td>0.856846</td>\n",
       "      <td>0.8160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c10.0_gamma1</th>\n",
       "      <td>0.740060</td>\n",
       "      <td>0.820801</td>\n",
       "      <td>0.8344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c10.0_gamma10.0</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c10.0_gamma100</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c100.0_gamma0.001</th>\n",
       "      <td>0.811281</td>\n",
       "      <td>0.897108</td>\n",
       "      <td>0.8408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c100.0_gamma0.01</th>\n",
       "      <td>0.780688</td>\n",
       "      <td>0.866522</td>\n",
       "      <td>0.8200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c100.0_gamma0.1</th>\n",
       "      <td>0.720513</td>\n",
       "      <td>0.801964</td>\n",
       "      <td>0.7744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c100.0_gamma1</th>\n",
       "      <td>0.740060</td>\n",
       "      <td>0.820801</td>\n",
       "      <td>0.8344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c100.0_gamma10.0</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c100.0_gamma100</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   avg-accuracy  avg-precision  avg-recall\n",
       "c0.01_gamma0.001       0.627198       0.690013      1.0000\n",
       "c0.01_gamma0.01        0.627198       0.690013      1.0000\n",
       "c0.01_gamma0.1         0.654266       0.718042      0.9960\n",
       "c0.01_gamma1           0.627198       0.690013      1.0000\n",
       "c0.01_gamma10.0        0.627198       0.690013      1.0000\n",
       "c0.01_gamma100         0.627198       0.690013      1.0000\n",
       "c0.1_gamma0.001        0.627198       0.690013      1.0000\n",
       "c0.1_gamma0.01         0.766136       0.836136      0.9112\n",
       "c0.1_gamma0.1          0.806274       0.885295      0.8688\n",
       "c0.1_gamma1            0.701912       0.770044      0.9424\n",
       "c0.1_gamma10.0         0.627198       0.690013      1.0000\n",
       "c0.1_gamma100          0.627198       0.690013      1.0000\n",
       "c1.0_gamma0.001        0.768141       0.838141      0.9096\n",
       "c1.0_gamma0.01         0.819327       0.902533      0.8624\n",
       "c1.0_gamma0.1          0.806269       0.893046      0.8352\n",
       "c1.0_gamma1            0.754093       0.835436      0.8464\n",
       "c1.0_gamma10.0         0.627198       0.690013      1.0000\n",
       "c1.0_gamma100          0.627198       0.690013      1.0000\n",
       "c10.0_gamma0.001       0.819327       0.902533      0.8608\n",
       "c10.0_gamma0.01        0.809774       0.895374      0.8416\n",
       "c10.0_gamma0.1         0.772168       0.856846      0.8160\n",
       "c10.0_gamma1           0.740060       0.820801      0.8344\n",
       "c10.0_gamma10.0        0.627198       0.690013      1.0000\n",
       "c10.0_gamma100         0.627198       0.690013      1.0000\n",
       "c100.0_gamma0.001      0.811281       0.897108      0.8408\n",
       "c100.0_gamma0.01       0.780688       0.866522      0.8200\n",
       "c100.0_gamma0.1        0.720513       0.801964      0.7744\n",
       "c100.0_gamma1          0.740060       0.820801      0.8344\n",
       "c100.0_gamma10.0       0.627198       0.690013      1.0000\n",
       "c100.0_gamma100        0.627198       0.690013      1.0000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_range = [0.01, 0.1, 1.0, 10.0, 100.0]#, 1000.0]            \n",
    "gamma_range = [0.001, 0.01, 0.1, 1, 10.0, 100] \n",
    "\n",
    "DF_PrecisionRecallFscore = pd.DataFrame(np.NaN, index=[\"c\" + str(c) + \"_\" + \"gamma\" + str(gamma) for c, gamma in itertools.product(c_range, gamma_range)],\n",
    "                                        columns=['avg-accuracy', 'avg-precision', 'avg-recall'])\n",
    "\n",
    "outputEvaluationDict, validLabelDict = buildModel(dataContinuous, targetBinomial)\n",
    "\n",
    "for foldNUM, c_gamma_prediction in  outputEvaluationDict.items():\n",
    "#     print ('Running for cross validation fold : ', numFold)\n",
    "    for c_gamma, prediction in c_gamma_prediction.items():\n",
    "        if pd.isnull(DF_PrecisionRecallFscore.ix[c_gamma, 'avg-accuracy']):\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-accuracy'] = metrics.accuracy_score(validLabelDict[foldNUM], prediction)\n",
    "        else:\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-accuracy'] = DF_PrecisionRecallFscore.ix[c_gamma, 'avg-accuracy'] + metrics.accuracy_score(validLabelDict[foldNUM], prediction)\n",
    "            \n",
    "        if pd.isnull(DF_PrecisionRecallFscore.ix[c_gamma, 'avg-precision']):\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-precision'] = metrics.precision_score(validLabelDict[foldNUM], prediction)\n",
    "        else:\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-precision'] = DF_PrecisionRecallFscore.ix[c_gamma, 'avg-accuracy'] + metrics.precision_score(validLabelDict[foldNUM], prediction)\n",
    "            \n",
    "        if pd.isnull(DF_PrecisionRecallFscore.ix[c_gamma, 'avg-recall']):\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-recall'] = metrics.recall_score(validLabelDict[foldNUM], prediction)\n",
    "        else:\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-recall'] = DF_PrecisionRecallFscore.ix[c_gamma, 'avg-recall'] + metrics.recall_score(validLabelDict[foldNUM], prediction)\n",
    "\n",
    "DF_PrecisionRecallFscore/(foldNUM+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### SVM with RBF Kernel on PCA reduced matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.990051120184\n",
      "(1993, 57)\n"
     ]
    }
   ],
   "source": [
    "# Employing PCA:\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=dataContinuous.shape[1])\n",
    "pca = pca.fit(dataContinuous)\n",
    "\n",
    "# We use num of components that explains 99% of the variance in the data\n",
    "sumRatio = 0\n",
    "for num, ratio in enumerate(pca.explained_variance_ratio_[::-1]):\n",
    "    sumRatio = sumRatio + ratio\n",
    "    if 1-sumRatio<=0.99:\n",
    "        break\n",
    "        \n",
    "numComponents = dataContinuous.shape[1]-num\n",
    "# print ('dffdsf')\n",
    "print (sum(decomposerPCA.explained_variance_ratio_[0:numComponents]))\n",
    "\n",
    "decomposedPCA = PCA(n_components=numComponents)\n",
    "dataTransformed = decomposedPCA.fit_transform(dataContinuous)\n",
    "print(dataTransformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=675, shuffle=False)\n",
      "Train: 1793 CrossValid: 200\n",
      "Train: 1793 CrossValid: 200\n",
      "Train: 1793 CrossValid: 200\n",
      "Train: 1794 CrossValid: 199\n",
      "Train: 1794 CrossValid: 199\n",
      "Train: 1794 CrossValid: 199\n",
      "Train: 1794 CrossValid: 199\n",
      "Train: 1794 CrossValid: 199\n",
      "Train: 1794 CrossValid: 199\n",
      "Train: 1794 CrossValid: 199\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg-accuracy</th>\n",
       "      <th>avg-precision</th>\n",
       "      <th>avg-recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma0.001</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma0.01</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma0.1</th>\n",
       "      <td>0.656779</td>\n",
       "      <td>0.720554</td>\n",
       "      <td>0.9960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma1</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma10.0</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma100</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma0.001</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma0.01</th>\n",
       "      <td>0.766136</td>\n",
       "      <td>0.836136</td>\n",
       "      <td>0.9112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma0.1</th>\n",
       "      <td>0.807279</td>\n",
       "      <td>0.886856</td>\n",
       "      <td>0.8696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma1</th>\n",
       "      <td>0.706925</td>\n",
       "      <td>0.775081</td>\n",
       "      <td>0.9408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma10.0</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma100</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1.0_gamma0.001</th>\n",
       "      <td>0.767638</td>\n",
       "      <td>0.837461</td>\n",
       "      <td>0.9088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1.0_gamma0.01</th>\n",
       "      <td>0.818824</td>\n",
       "      <td>0.901400</td>\n",
       "      <td>0.8632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1.0_gamma0.1</th>\n",
       "      <td>0.806774</td>\n",
       "      <td>0.892953</td>\n",
       "      <td>0.8392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1.0_gamma1</th>\n",
       "      <td>0.759116</td>\n",
       "      <td>0.840459</td>\n",
       "      <td>0.8456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1.0_gamma10.0</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1.0_gamma100</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c10.0_gamma0.001</th>\n",
       "      <td>0.819327</td>\n",
       "      <td>0.902533</td>\n",
       "      <td>0.8616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c10.0_gamma0.01</th>\n",
       "      <td>0.807774</td>\n",
       "      <td>0.894282</td>\n",
       "      <td>0.8392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c10.0_gamma0.1</th>\n",
       "      <td>0.772666</td>\n",
       "      <td>0.859443</td>\n",
       "      <td>0.8128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c10.0_gamma1</th>\n",
       "      <td>0.739568</td>\n",
       "      <td>0.820309</td>\n",
       "      <td>0.8312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c10.0_gamma10.0</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c10.0_gamma100</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c100.0_gamma0.001</th>\n",
       "      <td>0.810776</td>\n",
       "      <td>0.896603</td>\n",
       "      <td>0.8408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c100.0_gamma0.01</th>\n",
       "      <td>0.790219</td>\n",
       "      <td>0.876995</td>\n",
       "      <td>0.8240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c100.0_gamma0.1</th>\n",
       "      <td>0.728535</td>\n",
       "      <td>0.810502</td>\n",
       "      <td>0.7792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c100.0_gamma1</th>\n",
       "      <td>0.739568</td>\n",
       "      <td>0.820309</td>\n",
       "      <td>0.8312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c100.0_gamma10.0</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c100.0_gamma100</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   avg-accuracy  avg-precision  avg-recall\n",
       "c0.01_gamma0.001       0.627198       0.690013      1.0000\n",
       "c0.01_gamma0.01        0.627198       0.690013      1.0000\n",
       "c0.01_gamma0.1         0.656779       0.720554      0.9960\n",
       "c0.01_gamma1           0.627198       0.690013      1.0000\n",
       "c0.01_gamma10.0        0.627198       0.690013      1.0000\n",
       "c0.01_gamma100         0.627198       0.690013      1.0000\n",
       "c0.1_gamma0.001        0.627198       0.690013      1.0000\n",
       "c0.1_gamma0.01         0.766136       0.836136      0.9112\n",
       "c0.1_gamma0.1          0.807279       0.886856      0.8696\n",
       "c0.1_gamma1            0.706925       0.775081      0.9408\n",
       "c0.1_gamma10.0         0.627198       0.690013      1.0000\n",
       "c0.1_gamma100          0.627198       0.690013      1.0000\n",
       "c1.0_gamma0.001        0.767638       0.837461      0.9088\n",
       "c1.0_gamma0.01         0.818824       0.901400      0.8632\n",
       "c1.0_gamma0.1          0.806774       0.892953      0.8392\n",
       "c1.0_gamma1            0.759116       0.840459      0.8456\n",
       "c1.0_gamma10.0         0.627198       0.690013      1.0000\n",
       "c1.0_gamma100          0.627198       0.690013      1.0000\n",
       "c10.0_gamma0.001       0.819327       0.902533      0.8616\n",
       "c10.0_gamma0.01        0.807774       0.894282      0.8392\n",
       "c10.0_gamma0.1         0.772666       0.859443      0.8128\n",
       "c10.0_gamma1           0.739568       0.820309      0.8312\n",
       "c10.0_gamma10.0        0.627198       0.690013      1.0000\n",
       "c10.0_gamma100         0.627198       0.690013      1.0000\n",
       "c100.0_gamma0.001      0.810776       0.896603      0.8408\n",
       "c100.0_gamma0.01       0.790219       0.876995      0.8240\n",
       "c100.0_gamma0.1        0.728535       0.810502      0.7792\n",
       "c100.0_gamma1          0.739568       0.820309      0.8312\n",
       "c100.0_gamma10.0       0.627198       0.690013      1.0000\n",
       "c100.0_gamma100        0.627198       0.690013      1.0000"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_range = [0.01, 0.1, 1.0, 10.0, 100.0]#, 1000.0]            \n",
    "gamma_range = [0.001, 0.01, 0.1, 1, 10.0, 100] \n",
    "\n",
    "DF_PrecisionRecallFscore = pd.DataFrame(np.NaN, index=[\"c\" + str(c) + \"_\" + \"gamma\" + str(gamma) for c, gamma in itertools.product(c_range, gamma_range)],\n",
    "                                        columns=['avg-accuracy', 'avg-precision', 'avg-recall'])\n",
    "\n",
    "outputEvaluationDict, validLabelDict = buildModel(dataTransformed, targetBinomial)\n",
    "\n",
    "for foldNUM, c_gamma_prediction in  outputEvaluationDict.items():\n",
    "#     print ('Running for cross validation fold : ', numFold)\n",
    "    for c_gamma, prediction in c_gamma_prediction.items():\n",
    "        if pd.isnull(DF_PrecisionRecallFscore.ix[c_gamma, 'avg-accuracy']):\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-accuracy'] = metrics.accuracy_score(validLabelDict[foldNUM], prediction)\n",
    "        else:\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-accuracy'] = DF_PrecisionRecallFscore.ix[c_gamma, 'avg-accuracy'] + metrics.accuracy_score(validLabelDict[foldNUM], prediction)\n",
    "            \n",
    "        if pd.isnull(DF_PrecisionRecallFscore.ix[c_gamma, 'avg-precision']):\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-precision'] = metrics.precision_score(validLabelDict[foldNUM], prediction)\n",
    "        else:\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-precision'] = DF_PrecisionRecallFscore.ix[c_gamma, 'avg-accuracy'] + metrics.precision_score(validLabelDict[foldNUM], prediction)\n",
    "            \n",
    "        if pd.isnull(DF_PrecisionRecallFscore.ix[c_gamma, 'avg-recall']):\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-recall'] = metrics.recall_score(validLabelDict[foldNUM], prediction)\n",
    "        else:\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-recall'] = DF_PrecisionRecallFscore.ix[c_gamma, 'avg-recall'] + metrics.recall_score(validLabelDict[foldNUM], prediction)\n",
    "\n",
    "DF_PrecisionRecallFscore/(foldNUM+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "ii. Using State as an independent variable: Crime is also proportional to the state, Some states have very high crime rate regrardless of other independent features. Here we use \"State\" as a nominal feature with all other feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>...</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "0        0.01           0.61          0.21          0.83          0.02   \n",
       "1        0.01           0.41          0.55          0.57          0.01   \n",
       "2        0.03           0.34          0.86          0.30          0.04   \n",
       "3        0.01           0.38          0.35          0.71          0.04   \n",
       "4        0.04           0.37          0.32          0.70          0.21   \n",
       "\n",
       "   racePctHisp  agePct12t21  agePct12t29  agePct16t24  agePct65up ...    46  \\\n",
       "0         0.01         0.41         0.49         0.26        0.21 ...   0.0   \n",
       "1         0.00         0.47         0.45         0.31        0.57 ...   0.0   \n",
       "2         0.01         0.41         0.42         0.27        0.59 ...   0.0   \n",
       "3         0.01         0.39         0.46         0.31        0.49 ...   0.0   \n",
       "4         0.02         1.00         1.00         1.00        0.14 ...   0.0   \n",
       "\n",
       "    47   48   49   50   51   53   54   55   56  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding of the factor column state\n",
    "dataMixed = pd.concat([dataContinuous, pd.get_dummies(crimeDF['state'])], axis=1)\n",
    "dataMixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=675, shuffle=False)\n",
      "Train: 1793 CrossValid: 200\n",
      "Train: 1793 CrossValid: 200\n",
      "Train: 1793 CrossValid: 200\n",
      "Train: 1794 CrossValid: 199\n",
      "Train: 1794 CrossValid: 199\n",
      "Train: 1794 CrossValid: 199\n",
      "Train: 1794 CrossValid: 199\n",
      "Train: 1794 CrossValid: 199\n",
      "Train: 1794 CrossValid: 199\n",
      "Train: 1794 CrossValid: 199\n"
     ]
    }
   ],
   "source": [
    "# Call the SVM rbf model with the state column:\n",
    "outputEvaluationDict, validLabelDict = buildModel(dataMixed, targetBinomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg-accuracy</th>\n",
       "      <th>avg-precision</th>\n",
       "      <th>avg-recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma0.001</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma0.01</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma0.1</th>\n",
       "      <td>0.630214</td>\n",
       "      <td>0.693028</td>\n",
       "      <td>0.9984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma1</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma10.0</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.01_gamma100</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma0.001</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma0.01</th>\n",
       "      <td>0.762106</td>\n",
       "      <td>0.831928</td>\n",
       "      <td>0.9104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma0.1</th>\n",
       "      <td>0.789221</td>\n",
       "      <td>0.868242</td>\n",
       "      <td>0.8616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma1</th>\n",
       "      <td>0.624178</td>\n",
       "      <td>0.686992</td>\n",
       "      <td>0.9880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma10.0</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0.1_gamma100</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1.0_gamma0.001</th>\n",
       "      <td>0.765621</td>\n",
       "      <td>0.835859</td>\n",
       "      <td>0.9056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1.0_gamma0.01</th>\n",
       "      <td>0.791226</td>\n",
       "      <td>0.874303</td>\n",
       "      <td>0.8416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1.0_gamma0.1</th>\n",
       "      <td>0.728543</td>\n",
       "      <td>0.816577</td>\n",
       "      <td>0.7856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1.0_gamma1</th>\n",
       "      <td>0.670827</td>\n",
       "      <td>0.737106</td>\n",
       "      <td>0.8376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1.0_gamma10.0</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1.0_gamma100</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c10.0_gamma0.001</th>\n",
       "      <td>0.788719</td>\n",
       "      <td>0.871796</td>\n",
       "      <td>0.8408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c10.0_gamma0.01</th>\n",
       "      <td>0.730025</td>\n",
       "      <td>0.817744</td>\n",
       "      <td>0.7736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c10.0_gamma0.1</th>\n",
       "      <td>0.688864</td>\n",
       "      <td>0.777544</td>\n",
       "      <td>0.7424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c10.0_gamma1</th>\n",
       "      <td>0.665807</td>\n",
       "      <td>0.732670</td>\n",
       "      <td>0.8216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c10.0_gamma10.0</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c10.0_gamma100</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c100.0_gamma0.001</th>\n",
       "      <td>0.732033</td>\n",
       "      <td>0.820528</td>\n",
       "      <td>0.7776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c100.0_gamma0.01</th>\n",
       "      <td>0.689872</td>\n",
       "      <td>0.779061</td>\n",
       "      <td>0.7464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c100.0_gamma0.1</th>\n",
       "      <td>0.670312</td>\n",
       "      <td>0.753497</td>\n",
       "      <td>0.7224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c100.0_gamma1</th>\n",
       "      <td>0.665807</td>\n",
       "      <td>0.732670</td>\n",
       "      <td>0.8216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c100.0_gamma10.0</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c100.0_gamma100</th>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.690013</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   avg-accuracy  avg-precision  avg-recall\n",
       "c0.01_gamma0.001       0.627198       0.690013      1.0000\n",
       "c0.01_gamma0.01        0.627198       0.690013      1.0000\n",
       "c0.01_gamma0.1         0.630214       0.693028      0.9984\n",
       "c0.01_gamma1           0.627198       0.690013      1.0000\n",
       "c0.01_gamma10.0        0.627198       0.690013      1.0000\n",
       "c0.01_gamma100         0.627198       0.690013      1.0000\n",
       "c0.1_gamma0.001        0.627198       0.690013      1.0000\n",
       "c0.1_gamma0.01         0.762106       0.831928      0.9104\n",
       "c0.1_gamma0.1          0.789221       0.868242      0.8616\n",
       "c0.1_gamma1            0.624178       0.686992      0.9880\n",
       "c0.1_gamma10.0         0.627198       0.690013      1.0000\n",
       "c0.1_gamma100          0.627198       0.690013      1.0000\n",
       "c1.0_gamma0.001        0.765621       0.835859      0.9056\n",
       "c1.0_gamma0.01         0.791226       0.874303      0.8416\n",
       "c1.0_gamma0.1          0.728543       0.816577      0.7856\n",
       "c1.0_gamma1            0.670827       0.737106      0.8376\n",
       "c1.0_gamma10.0         0.627198       0.690013      1.0000\n",
       "c1.0_gamma100          0.627198       0.690013      1.0000\n",
       "c10.0_gamma0.001       0.788719       0.871796      0.8408\n",
       "c10.0_gamma0.01        0.730025       0.817744      0.7736\n",
       "c10.0_gamma0.1         0.688864       0.777544      0.7424\n",
       "c10.0_gamma1           0.665807       0.732670      0.8216\n",
       "c10.0_gamma10.0        0.627198       0.690013      1.0000\n",
       "c10.0_gamma100         0.627198       0.690013      1.0000\n",
       "c100.0_gamma0.001      0.732033       0.820528      0.7776\n",
       "c100.0_gamma0.01       0.689872       0.779061      0.7464\n",
       "c100.0_gamma0.1        0.670312       0.753497      0.7224\n",
       "c100.0_gamma1          0.665807       0.732670      0.8216\n",
       "c100.0_gamma10.0       0.627198       0.690013      1.0000\n",
       "c100.0_gamma100        0.627198       0.690013      1.0000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_range = [0.01, 0.1, 1.0, 10.0, 100.0]#, 1000.0]            \n",
    "gamma_range = [0.001, 0.01, 0.1, 1, 10.0, 100] \n",
    "\n",
    "DF_PrecisionRecallFscore = pd.DataFrame(np.NaN, index=[\"c\" + str(c) + \"_\" + \"gamma\" + str(gamma) for c, gamma in itertools.product(c_range, gamma_range)],\n",
    "                                        columns=['avg-accuracy', 'avg-precision', 'avg-recall'])\n",
    "\n",
    "for foldNUM, c_gamma_prediction in  outputEvaluationDict.items():\n",
    "#     print ('Running for cross validation fold : ', numFold)\n",
    "    for c_gamma, prediction in c_gamma_prediction.items():\n",
    "        if pd.isnull(DF_PrecisionRecallFscore.ix[c_gamma, 'avg-accuracy']):\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-accuracy'] = metrics.accuracy_score(validLabelDict[foldNUM], prediction)\n",
    "        else:\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-accuracy'] = DF_PrecisionRecallFscore.ix[c_gamma, 'avg-accuracy'] + metrics.accuracy_score(validLabelDict[foldNUM], prediction)\n",
    "            \n",
    "        if pd.isnull(DF_PrecisionRecallFscore.ix[c_gamma, 'avg-precision']):\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-precision'] = metrics.precision_score(validLabelDict[foldNUM], prediction)\n",
    "        else:\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-precision'] = DF_PrecisionRecallFscore.ix[c_gamma, 'avg-accuracy'] + metrics.precision_score(validLabelDict[foldNUM], prediction)\n",
    "            \n",
    "        if pd.isnull(DF_PrecisionRecallFscore.ix[c_gamma, 'avg-recall']):\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-recall'] = metrics.recall_score(validLabelDict[foldNUM], prediction)\n",
    "        else:\n",
    "            DF_PrecisionRecallFscore.ix[c_gamma, 'avg-recall'] = DF_PrecisionRecallFscore.ix[c_gamma, 'avg-recall'] + metrics.recall_score(validLabelDict[foldNUM], prediction)\n",
    "\n",
    "DF_PrecisionRecallFscore/(foldNUM+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Random Forests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Fold accuracy of the Random Forest classifier is [ 0.825  0.855  0.81   0.8    0.825  0.825  0.88   0.86   0.835  0.84 ] and their mean is :  0.8355\n",
      "The 10 Fold precision of the Random Forest classifier is [ 0.87603306  0.87068966  0.91666667  0.89565217  0.83870968  0.8173913\n",
      "  0.91666667  0.86259542  0.872       0.82352941] and their mean is :  0.868993403365\n",
      "The 10 Fold recall of the Random Forest classifier is [ 0.824       0.84745763  0.8372093   0.86507937  0.8974359   0.81034483\n",
      "  0.90163934  0.90322581  0.82677165  0.88034188] and their mean is :  0.859350570414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifierRF = RandomForestClassifier(n_estimators=20, criterion='entropy')  # Entropy and Gini provides very similar evaluation results\n",
    "nFoldRF_acc = model_selection.cross_val_score(classifierRF, dataContinuous, targetBinomial, cv=cv, scoring='accuracy')\n",
    "nFoldRF_precision = model_selection.cross_val_score(classifierRF, dataContinuous, targetBinomial, cv=cv, scoring='precision')\n",
    "nFoldRF_recall = model_selection.cross_val_score(classifierRF, dataContinuous, targetBinomial, cv=cv, scoring='recall')\n",
    "\n",
    "\n",
    "print ('The 10 Fold accuracy of the Random Forest classifier is %s and their mean is : '%(str(nFoldRF_acc)), np.mean(nFoldRF_acc))\n",
    "print ('The 10 Fold precision of the Random Forest classifier is %s and their mean is : '%(str(nFoldRF_precision)), np.mean(nFoldRF_precision))\n",
    "print ('The 10 Fold recall of the Random Forest classifier is %s and their mean is : '%(str(nFoldRF_recall)), np.mean(nFoldRF_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Ridge Regression with PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.640634785297\n",
      "The MSE for the best model based on cross validation is (0.0195070383179) and the corresponding norm co-efficient alpha is:  0.001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "alpha = np.array([0.001, 0.000001], dtype='float64')\n",
    "\n",
    "classifierRRPCA_cv = RidgeCV(alpha, cv=cv)\n",
    "\n",
    "classifierRRPCA_cv = classifierRRPCA_cv.fit(dataTransformed, targetContinuous)\n",
    "predictionContinuousRRPCA_cv = classifierRRPCA_cv.predict(dataTransformed)\n",
    "R_square = classifierRRPCA_cv.score(dataTransformed, targetContinuous)\n",
    "print (R_square)\n",
    "\n",
    "mseRR_Best = metrics.mean_squared_error(targetContinuous, predictionContinuousRRPCA_cv)\n",
    "alpha_Best = classifierRRPCA_cv.alpha_\n",
    "print ('The MSE for the best model based on cross validation is (%s) and the corresponding norm co-efficient alpha is: '%str(mseRR_Best), alpha_Best)\n",
    "\n",
    "\n",
    "# alpha=1000,  0.608987702744 \n",
    "# alpha=100,   0.627824794667\n",
    "# alpha=10,    0.637611221912\n",
    "# alpha=1,     0.640523035231\n",
    "# alpha=0.1,   0.640633399513\n",
    "# alpha=0.01,  0.64063477125\n",
    "# alpha=0.001, 0.640634785297\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE for the Ridge Regression at alpha (0.001) is:  0.0195070383179\n",
      "The R_squared for the Ridge Regression at alpha (0.001) is:  0.640634785297\n",
      "The MSE for the Ridge Regression at alpha (0.01) is:  0.0195070390804\n",
      "The R_squared for the Ridge Regression at alpha (0.01) is:  0.64063477125\n",
      "The MSE for the Ridge Regression at alpha (0.1) is:  0.0195071135409\n",
      "The R_squared for the Ridge Regression at alpha (0.1) is:  0.640633399513\n",
      "The MSE for the Ridge Regression at alpha (1) is:  0.0195131043274\n",
      "The R_squared for the Ridge Regression at alpha (1) is:  0.640523035231\n",
      "The MSE for the Ridge Regression at alpha (10) is:  0.0196711631814\n",
      "The R_squared for the Ridge Regression at alpha (10) is:  0.637611221912\n",
      "The MSE for the Ridge Regression at alpha (100) is:  0.0202023893643\n",
      "The R_squared for the Ridge Regression at alpha (100) is:  0.627824794667\n",
      "The MSE for the Ridge Regression at alpha (1000) is:  0.021224903116\n",
      "The R_squared for the Ridge Regression at alpha (1000) is:  0.608987702744\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def ridgeRegression(datasetIN, targetIN, alphaIN):\n",
    "    classifierRR = Ridge(alpha=alphaIN)\n",
    "    classifierRR = classifierRR.fit(datasetIN, targetIN)\n",
    "    predictionContinuousRR = classifierRR.predict(datasetIN)\n",
    "    coeffDetermination = classifierRR.score(datasetIN, targetIN)\n",
    "    mseRR = metrics.mean_squared_error(targetContinuous, predictionContinuousRR)\n",
    "    print ('The MSE for the Ridge Regression at alpha (%s) is: '%str(alpha), mseRR)\n",
    "    print ('The R_squared for the Ridge Regression at alpha (%s) is: '%str(alpha), coeffDetermination)\n",
    "    \n",
    "    \n",
    "datasetIN = dataTransformed\n",
    "targetIN = targetContinuous\n",
    "\n",
    "for alpha in [0.001,0.01,0.1,1,10,100,1000]:\n",
    "    ridgeRegression(datasetIN, targetIN,alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Rough Works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>numbUrban</th>\n",
       "      <th>pctUrban</th>\n",
       "      <th>medIncome</th>\n",
       "      <th>pctWWage</th>\n",
       "      <th>pctWFarmSelf</th>\n",
       "      <th>pctWInvInc</th>\n",
       "      <th>pctWSocSec</th>\n",
       "      <th>pctWPubAsst</th>\n",
       "      <th>pctWRetire</th>\n",
       "      <th>medFamInc</th>\n",
       "      <th>perCapInc</th>\n",
       "      <th>whitePerCap</th>\n",
       "      <th>blackPerCap</th>\n",
       "      <th>indianPerCap</th>\n",
       "      <th>AsianPerCap</th>\n",
       "      <th>OtherPerCap</th>\n",
       "      <th>HispPerCap</th>\n",
       "      <th>NumUnderPov</th>\n",
       "      <th>PctPopUnderPov</th>\n",
       "      <th>PctLess9thGrade</th>\n",
       "      <th>PctNotHSGrad</th>\n",
       "      <th>PctBSorMore</th>\n",
       "      <th>PctUnemployed</th>\n",
       "      <th>PctEmploy</th>\n",
       "      <th>PctEmplManu</th>\n",
       "      <th>PctEmplProfServ</th>\n",
       "      <th>PctOccupManu</th>\n",
       "      <th>PctOccupMgmtProf</th>\n",
       "      <th>MalePctDivorce</th>\n",
       "      <th>MalePctNevMarr</th>\n",
       "      <th>FemalePctDiv</th>\n",
       "      <th>TotalPctDiv</th>\n",
       "      <th>PersPerFam</th>\n",
       "      <th>PctFam2Par</th>\n",
       "      <th>PctKids2Par</th>\n",
       "      <th>PctYoungKids2Par</th>\n",
       "      <th>PctTeen2Par</th>\n",
       "      <th>PctWorkMomYoungKids</th>\n",
       "      <th>PctWorkMom</th>\n",
       "      <th>NumIlleg</th>\n",
       "      <th>PctIlleg</th>\n",
       "      <th>NumImmig</th>\n",
       "      <th>PctImmigRecent</th>\n",
       "      <th>PctImmigRec5</th>\n",
       "      <th>PctImmigRec8</th>\n",
       "      <th>PctImmigRec10</th>\n",
       "      <th>PctRecentImmig</th>\n",
       "      <th>PctRecImmig5</th>\n",
       "      <th>PctRecImmig8</th>\n",
       "      <th>PctRecImmig10</th>\n",
       "      <th>PctSpeakEnglOnly</th>\n",
       "      <th>PctNotSpeakEnglWell</th>\n",
       "      <th>PctLargHouseFam</th>\n",
       "      <th>PctLargHouseOccup</th>\n",
       "      <th>PersPerOccupHous</th>\n",
       "      <th>PersPerOwnOccHous</th>\n",
       "      <th>PersPerRentOccHous</th>\n",
       "      <th>PctPersOwnOccup</th>\n",
       "      <th>PctPersDenseHous</th>\n",
       "      <th>PctHousLess3BR</th>\n",
       "      <th>MedNumBR</th>\n",
       "      <th>HousVacant</th>\n",
       "      <th>PctHousOccup</th>\n",
       "      <th>PctHousOwnOcc</th>\n",
       "      <th>PctVacantBoarded</th>\n",
       "      <th>PctVacMore6Mos</th>\n",
       "      <th>MedYrHousBuilt</th>\n",
       "      <th>PctHousNoPhone</th>\n",
       "      <th>PctWOFullPlumb</th>\n",
       "      <th>OwnOccLowQuart</th>\n",
       "      <th>OwnOccMedVal</th>\n",
       "      <th>OwnOccHiQuart</th>\n",
       "      <th>RentLowQ</th>\n",
       "      <th>RentMedian</th>\n",
       "      <th>RentHighQ</th>\n",
       "      <th>MedRent</th>\n",
       "      <th>MedRentPctHousInc</th>\n",
       "      <th>MedOwnCostPctInc</th>\n",
       "      <th>MedOwnCostPctIncNoMtg</th>\n",
       "      <th>NumInShelters</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.057612</td>\n",
       "      <td>0.463437</td>\n",
       "      <td>0.179227</td>\n",
       "      <td>0.753984</td>\n",
       "      <td>0.153753</td>\n",
       "      <td>0.144089</td>\n",
       "      <td>0.424210</td>\n",
       "      <td>0.493914</td>\n",
       "      <td>0.336297</td>\n",
       "      <td>0.423086</td>\n",
       "      <td>0.064104</td>\n",
       "      <td>0.696618</td>\n",
       "      <td>0.361259</td>\n",
       "      <td>0.558314</td>\n",
       "      <td>0.291540</td>\n",
       "      <td>0.495780</td>\n",
       "      <td>0.471044</td>\n",
       "      <td>0.317546</td>\n",
       "      <td>0.479242</td>\n",
       "      <td>0.375805</td>\n",
       "      <td>0.350336</td>\n",
       "      <td>0.368073</td>\n",
       "      <td>0.291169</td>\n",
       "      <td>0.203567</td>\n",
       "      <td>0.322333</td>\n",
       "      <td>0.284742</td>\n",
       "      <td>0.386157</td>\n",
       "      <td>0.055509</td>\n",
       "      <td>0.302750</td>\n",
       "      <td>0.315695</td>\n",
       "      <td>0.383251</td>\n",
       "      <td>0.361711</td>\n",
       "      <td>0.363281</td>\n",
       "      <td>0.501229</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>0.440552</td>\n",
       "      <td>0.391234</td>\n",
       "      <td>0.441305</td>\n",
       "      <td>0.461164</td>\n",
       "      <td>0.434451</td>\n",
       "      <td>0.487501</td>\n",
       "      <td>0.494195</td>\n",
       "      <td>0.487747</td>\n",
       "      <td>0.611124</td>\n",
       "      <td>0.620868</td>\n",
       "      <td>0.664300</td>\n",
       "      <td>0.583081</td>\n",
       "      <td>0.501405</td>\n",
       "      <td>0.526703</td>\n",
       "      <td>0.036292</td>\n",
       "      <td>0.249694</td>\n",
       "      <td>0.030075</td>\n",
       "      <td>0.320261</td>\n",
       "      <td>0.360723</td>\n",
       "      <td>0.399212</td>\n",
       "      <td>0.428038</td>\n",
       "      <td>0.181450</td>\n",
       "      <td>0.182218</td>\n",
       "      <td>0.184867</td>\n",
       "      <td>0.182970</td>\n",
       "      <td>0.785805</td>\n",
       "      <td>0.150652</td>\n",
       "      <td>0.267602</td>\n",
       "      <td>0.251897</td>\n",
       "      <td>0.462132</td>\n",
       "      <td>0.494496</td>\n",
       "      <td>0.404064</td>\n",
       "      <td>0.562619</td>\n",
       "      <td>0.186272</td>\n",
       "      <td>0.495203</td>\n",
       "      <td>0.314601</td>\n",
       "      <td>0.076829</td>\n",
       "      <td>0.719649</td>\n",
       "      <td>0.548685</td>\n",
       "      <td>0.204476</td>\n",
       "      <td>0.433211</td>\n",
       "      <td>0.494235</td>\n",
       "      <td>0.264355</td>\n",
       "      <td>0.242905</td>\n",
       "      <td>0.264792</td>\n",
       "      <td>0.263593</td>\n",
       "      <td>0.269037</td>\n",
       "      <td>0.346553</td>\n",
       "      <td>0.372614</td>\n",
       "      <td>0.423121</td>\n",
       "      <td>0.384240</td>\n",
       "      <td>0.490070</td>\n",
       "      <td>0.449759</td>\n",
       "      <td>0.403638</td>\n",
       "      <td>0.029453</td>\n",
       "      <td>0.022790</td>\n",
       "      <td>0.215655</td>\n",
       "      <td>0.608776</td>\n",
       "      <td>0.534967</td>\n",
       "      <td>0.626322</td>\n",
       "      <td>0.651470</td>\n",
       "      <td>0.065243</td>\n",
       "      <td>0.232910</td>\n",
       "      <td>0.161741</td>\n",
       "      <td>0.094099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.126935</td>\n",
       "      <td>0.163747</td>\n",
       "      <td>0.252870</td>\n",
       "      <td>0.243807</td>\n",
       "      <td>0.208905</td>\n",
       "      <td>0.232531</td>\n",
       "      <td>0.155234</td>\n",
       "      <td>0.143584</td>\n",
       "      <td>0.166540</td>\n",
       "      <td>0.179196</td>\n",
       "      <td>0.128280</td>\n",
       "      <td>0.444648</td>\n",
       "      <td>0.209327</td>\n",
       "      <td>0.182820</td>\n",
       "      <td>0.204155</td>\n",
       "      <td>0.178067</td>\n",
       "      <td>0.173616</td>\n",
       "      <td>0.221951</td>\n",
       "      <td>0.167606</td>\n",
       "      <td>0.198224</td>\n",
       "      <td>0.191118</td>\n",
       "      <td>0.186848</td>\n",
       "      <td>0.171607</td>\n",
       "      <td>0.164793</td>\n",
       "      <td>0.195457</td>\n",
       "      <td>0.191008</td>\n",
       "      <td>0.183045</td>\n",
       "      <td>0.127973</td>\n",
       "      <td>0.228202</td>\n",
       "      <td>0.213354</td>\n",
       "      <td>0.202528</td>\n",
       "      <td>0.209239</td>\n",
       "      <td>0.201916</td>\n",
       "      <td>0.173940</td>\n",
       "      <td>0.202427</td>\n",
       "      <td>0.175490</td>\n",
       "      <td>0.198971</td>\n",
       "      <td>0.186332</td>\n",
       "      <td>0.182471</td>\n",
       "      <td>0.175481</td>\n",
       "      <td>0.175189</td>\n",
       "      <td>0.183620</td>\n",
       "      <td>0.154633</td>\n",
       "      <td>0.201817</td>\n",
       "      <td>0.206190</td>\n",
       "      <td>0.218477</td>\n",
       "      <td>0.191353</td>\n",
       "      <td>0.168642</td>\n",
       "      <td>0.175284</td>\n",
       "      <td>0.108698</td>\n",
       "      <td>0.229610</td>\n",
       "      <td>0.087209</td>\n",
       "      <td>0.219132</td>\n",
       "      <td>0.210929</td>\n",
       "      <td>0.201458</td>\n",
       "      <td>0.194889</td>\n",
       "      <td>0.235819</td>\n",
       "      <td>0.236357</td>\n",
       "      <td>0.236762</td>\n",
       "      <td>0.234846</td>\n",
       "      <td>0.226884</td>\n",
       "      <td>0.219752</td>\n",
       "      <td>0.196616</td>\n",
       "      <td>0.190756</td>\n",
       "      <td>0.169588</td>\n",
       "      <td>0.157935</td>\n",
       "      <td>0.189343</td>\n",
       "      <td>0.197134</td>\n",
       "      <td>0.210009</td>\n",
       "      <td>0.172550</td>\n",
       "      <td>0.255212</td>\n",
       "      <td>0.150501</td>\n",
       "      <td>0.194021</td>\n",
       "      <td>0.185251</td>\n",
       "      <td>0.217812</td>\n",
       "      <td>0.188952</td>\n",
       "      <td>0.232511</td>\n",
       "      <td>0.242846</td>\n",
       "      <td>0.206232</td>\n",
       "      <td>0.224434</td>\n",
       "      <td>0.231555</td>\n",
       "      <td>0.235273</td>\n",
       "      <td>0.219240</td>\n",
       "      <td>0.209213</td>\n",
       "      <td>0.248249</td>\n",
       "      <td>0.213369</td>\n",
       "      <td>0.169524</td>\n",
       "      <td>0.187321</td>\n",
       "      <td>0.192476</td>\n",
       "      <td>0.102630</td>\n",
       "      <td>0.100424</td>\n",
       "      <td>0.231146</td>\n",
       "      <td>0.204314</td>\n",
       "      <td>0.181360</td>\n",
       "      <td>0.200520</td>\n",
       "      <td>0.198253</td>\n",
       "      <td>0.109485</td>\n",
       "      <td>0.203127</td>\n",
       "      <td>0.229099</td>\n",
       "      <td>0.240379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "count  1993.000000    1993.000000   1993.000000   1993.000000   1993.000000   \n",
       "mean      0.057612       0.463437      0.179227      0.753984      0.153753   \n",
       "std       0.126935       0.163747      0.252870      0.243807      0.208905   \n",
       "min       0.000000       0.000000      0.000000      0.000000      0.000000   \n",
       "25%       0.010000       0.350000      0.020000      0.630000      0.040000   \n",
       "50%       0.020000       0.440000      0.060000      0.850000      0.070000   \n",
       "75%       0.050000       0.540000      0.230000      0.940000      0.170000   \n",
       "max       1.000000       1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       racePctHisp  agePct12t21  agePct12t29  agePct16t24   agePct65up  \\\n",
       "count  1993.000000  1993.000000  1993.000000  1993.000000  1993.000000   \n",
       "mean      0.144089     0.424210     0.493914     0.336297     0.423086   \n",
       "std       0.232531     0.155234     0.143584     0.166540     0.179196   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.010000     0.340000     0.410000     0.250000     0.300000   \n",
       "50%       0.040000     0.400000     0.480000     0.290000     0.420000   \n",
       "75%       0.160000     0.470000     0.540000     0.360000     0.530000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "         numbUrban     pctUrban    medIncome     pctWWage  pctWFarmSelf  \\\n",
       "count  1993.000000  1993.000000  1993.000000  1993.000000   1993.000000   \n",
       "mean      0.064104     0.696618     0.361259     0.558314      0.291540   \n",
       "std       0.128280     0.444648     0.209327     0.182820      0.204155   \n",
       "min       0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "25%       0.000000     0.000000     0.200000     0.440000      0.160000   \n",
       "50%       0.030000     1.000000     0.320000     0.560000      0.230000   \n",
       "75%       0.070000     1.000000     0.490000     0.690000      0.370000   \n",
       "max       1.000000     1.000000     1.000000     1.000000      1.000000   \n",
       "\n",
       "        pctWInvInc   pctWSocSec  pctWPubAsst   pctWRetire    medFamInc  \\\n",
       "count  1993.000000  1993.000000  1993.000000  1993.000000  1993.000000   \n",
       "mean      0.495780     0.471044     0.317546     0.479242     0.375805   \n",
       "std       0.178067     0.173616     0.221951     0.167606     0.198224   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.370000     0.350000     0.140000     0.360000     0.230000   \n",
       "50%       0.480000     0.470000     0.260000     0.470000     0.330000   \n",
       "75%       0.620000     0.580000     0.440000     0.580000     0.480000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "         perCapInc  whitePerCap  blackPerCap  indianPerCap  AsianPerCap  \\\n",
       "count  1993.000000  1993.000000  1993.000000   1993.000000  1993.000000   \n",
       "mean      0.350336     0.368073     0.291169      0.203567     0.322333   \n",
       "std       0.191118     0.186848     0.171607      0.164793     0.195457   \n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "25%       0.220000     0.240000     0.180000      0.110000     0.190000   \n",
       "50%       0.300000     0.320000     0.250000      0.170000     0.280000   \n",
       "75%       0.430000     0.440000     0.380000      0.250000     0.400000   \n",
       "max       1.000000     1.000000     1.000000      1.000000     1.000000   \n",
       "\n",
       "       OtherPerCap   HispPerCap  NumUnderPov  PctPopUnderPov  PctLess9thGrade  \\\n",
       "count  1993.000000  1993.000000  1993.000000     1993.000000      1993.000000   \n",
       "mean      0.284742     0.386157     0.055509        0.302750         0.315695   \n",
       "std       0.191008     0.183045     0.127973        0.228202         0.213354   \n",
       "min       0.000000     0.000000     0.000000        0.000000         0.000000   \n",
       "25%       0.170000     0.260000     0.010000        0.110000         0.160000   \n",
       "50%       0.250000     0.340000     0.020000        0.250000         0.270000   \n",
       "75%       0.360000     0.480000     0.050000        0.450000         0.420000   \n",
       "max       1.000000     1.000000     1.000000        1.000000         1.000000   \n",
       "\n",
       "       PctNotHSGrad  PctBSorMore  PctUnemployed    PctEmploy  PctEmplManu  \\\n",
       "count   1993.000000  1993.000000    1993.000000  1993.000000  1993.000000   \n",
       "mean       0.383251     0.361711       0.363281     0.501229     0.396427   \n",
       "std        0.202528     0.209239       0.201916     0.173940     0.202427   \n",
       "min        0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%        0.230000     0.210000       0.220000     0.380000     0.250000   \n",
       "50%        0.360000     0.310000       0.320000     0.510000     0.370000   \n",
       "75%        0.510000     0.460000       0.480000     0.630000     0.520000   \n",
       "max        1.000000     1.000000       1.000000     1.000000     1.000000   \n",
       "\n",
       "       PctEmplProfServ  PctOccupManu  PctOccupMgmtProf  MalePctDivorce  \\\n",
       "count      1993.000000   1993.000000       1993.000000     1993.000000   \n",
       "mean          0.440552      0.391234          0.441305        0.461164   \n",
       "std           0.175490      0.198971          0.186332        0.182471   \n",
       "min           0.000000      0.000000          0.000000        0.000000   \n",
       "25%           0.320000      0.240000          0.310000        0.330000   \n",
       "50%           0.410000      0.370000          0.400000        0.470000   \n",
       "75%           0.530000      0.510000          0.540000        0.590000   \n",
       "max           1.000000      1.000000          1.000000        1.000000   \n",
       "\n",
       "       MalePctNevMarr  FemalePctDiv  TotalPctDiv   PersPerFam   PctFam2Par  \\\n",
       "count     1993.000000   1993.000000  1993.000000  1993.000000  1993.000000   \n",
       "mean         0.434451      0.487501     0.494195     0.487747     0.611124   \n",
       "std          0.175481      0.175189     0.183620     0.154633     0.201817   \n",
       "min          0.000000      0.000000     0.000000     0.000000     0.000000   \n",
       "25%          0.310000      0.360000     0.360000     0.400000     0.490000   \n",
       "50%          0.400000      0.500000     0.500000     0.470000     0.630000   \n",
       "75%          0.500000      0.620000     0.630000     0.560000     0.760000   \n",
       "max          1.000000      1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       PctKids2Par  PctYoungKids2Par  PctTeen2Par  PctWorkMomYoungKids  \\\n",
       "count  1993.000000       1993.000000  1993.000000          1993.000000   \n",
       "mean      0.620868          0.664300     0.583081             0.501405   \n",
       "std       0.206190          0.218477     0.191353             0.168642   \n",
       "min       0.000000          0.000000     0.000000             0.000000   \n",
       "25%       0.490000          0.530000     0.480000             0.390000   \n",
       "50%       0.640000          0.700000     0.610000             0.510000   \n",
       "75%       0.780000          0.840000     0.720000             0.620000   \n",
       "max       1.000000          1.000000     1.000000             1.000000   \n",
       "\n",
       "        PctWorkMom     NumIlleg     PctIlleg     NumImmig  PctImmigRecent  \\\n",
       "count  1993.000000  1993.000000  1993.000000  1993.000000     1993.000000   \n",
       "mean      0.526703     0.036292     0.249694     0.030075        0.320261   \n",
       "std       0.175284     0.108698     0.229610     0.087209        0.219132   \n",
       "min       0.000000     0.000000     0.000000     0.000000        0.000000   \n",
       "25%       0.420000     0.000000     0.090000     0.000000        0.160000   \n",
       "50%       0.540000     0.010000     0.170000     0.010000        0.290000   \n",
       "75%       0.650000     0.020000     0.320000     0.020000        0.430000   \n",
       "max       1.000000     1.000000     1.000000     1.000000        1.000000   \n",
       "\n",
       "       PctImmigRec5  PctImmigRec8  PctImmigRec10  PctRecentImmig  \\\n",
       "count   1993.000000   1993.000000    1993.000000     1993.000000   \n",
       "mean       0.360723      0.399212       0.428038        0.181450   \n",
       "std        0.210929      0.201458       0.194889        0.235819   \n",
       "min        0.000000      0.000000       0.000000        0.000000   \n",
       "25%        0.200000      0.250000       0.280000        0.030000   \n",
       "50%        0.340000      0.390000       0.430000        0.090000   \n",
       "75%        0.480000      0.530000       0.560000        0.230000   \n",
       "max        1.000000      1.000000       1.000000        1.000000   \n",
       "\n",
       "       PctRecImmig5  PctRecImmig8  PctRecImmig10  PctSpeakEnglOnly  \\\n",
       "count   1993.000000   1993.000000    1993.000000       1993.000000   \n",
       "mean       0.182218      0.184867       0.182970          0.785805   \n",
       "std        0.236357      0.236762       0.234846          0.226884   \n",
       "min        0.000000      0.000000       0.000000          0.000000   \n",
       "25%        0.030000      0.030000       0.030000          0.730000   \n",
       "50%        0.080000      0.090000       0.090000          0.870000   \n",
       "75%        0.230000      0.230000       0.230000          0.940000   \n",
       "max        1.000000      1.000000       1.000000          1.000000   \n",
       "\n",
       "       PctNotSpeakEnglWell  PctLargHouseFam  PctLargHouseOccup  \\\n",
       "count          1993.000000      1993.000000        1993.000000   \n",
       "mean              0.150652         0.267602           0.251897   \n",
       "std               0.219752         0.196616           0.190756   \n",
       "min               0.000000         0.000000           0.000000   \n",
       "25%               0.030000         0.150000           0.140000   \n",
       "50%               0.060000         0.200000           0.190000   \n",
       "75%               0.160000         0.310000           0.290000   \n",
       "max               1.000000         1.000000           1.000000   \n",
       "\n",
       "       PersPerOccupHous  PersPerOwnOccHous  PersPerRentOccHous  \\\n",
       "count       1993.000000        1993.000000         1993.000000   \n",
       "mean           0.462132           0.494496            0.404064   \n",
       "std            0.169588           0.157935            0.189343   \n",
       "min            0.000000           0.000000            0.000000   \n",
       "25%            0.340000           0.390000            0.270000   \n",
       "50%            0.440000           0.480000            0.360000   \n",
       "75%            0.550000           0.580000            0.490000   \n",
       "max            1.000000           1.000000            1.000000   \n",
       "\n",
       "       PctPersOwnOccup  PctPersDenseHous  PctHousLess3BR     MedNumBR  \\\n",
       "count      1993.000000       1993.000000     1993.000000  1993.000000   \n",
       "mean          0.562619          0.186272        0.495203     0.314601   \n",
       "std           0.197134          0.210009        0.172550     0.255212   \n",
       "min           0.000000          0.000000        0.000000     0.000000   \n",
       "25%           0.440000          0.060000        0.400000     0.000000   \n",
       "50%           0.560000          0.110000        0.510000     0.500000   \n",
       "75%           0.700000          0.220000        0.600000     0.500000   \n",
       "max           1.000000          1.000000        1.000000     1.000000   \n",
       "\n",
       "        HousVacant  PctHousOccup  PctHousOwnOcc  PctVacantBoarded  \\\n",
       "count  1993.000000   1993.000000    1993.000000       1993.000000   \n",
       "mean      0.076829      0.719649       0.548685          0.204476   \n",
       "std       0.150501      0.194021       0.185251          0.217812   \n",
       "min       0.000000      0.000000       0.000000          0.000000   \n",
       "25%       0.010000      0.630000       0.430000          0.060000   \n",
       "50%       0.030000      0.770000       0.540000          0.130000   \n",
       "75%       0.070000      0.860000       0.670000          0.270000   \n",
       "max       1.000000      1.000000       1.000000          1.000000   \n",
       "\n",
       "       PctVacMore6Mos  MedYrHousBuilt  PctHousNoPhone  PctWOFullPlumb  \\\n",
       "count     1993.000000     1993.000000     1993.000000     1993.000000   \n",
       "mean         0.433211        0.494235        0.264355        0.242905   \n",
       "std          0.188952        0.232511        0.242846        0.206232   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          0.290000        0.350000        0.060000        0.100000   \n",
       "50%          0.420000        0.520000        0.180000        0.190000   \n",
       "75%          0.560000        0.670000        0.420000        0.330000   \n",
       "max          1.000000        1.000000        1.000000        1.000000   \n",
       "\n",
       "       OwnOccLowQuart  OwnOccMedVal  OwnOccHiQuart     RentLowQ   RentMedian  \\\n",
       "count     1993.000000   1993.000000    1993.000000  1993.000000  1993.000000   \n",
       "mean         0.264792      0.263593       0.269037     0.346553     0.372614   \n",
       "std          0.224434      0.231555       0.235273     0.219240     0.209213   \n",
       "min          0.000000      0.000000       0.000000     0.000000     0.000000   \n",
       "25%          0.090000      0.090000       0.090000     0.170000     0.200000   \n",
       "50%          0.180000      0.170000       0.180000     0.310000     0.330000   \n",
       "75%          0.400000      0.390000       0.380000     0.490000     0.520000   \n",
       "max          1.000000      1.000000       1.000000     1.000000     1.000000   \n",
       "\n",
       "         RentHighQ      MedRent  MedRentPctHousInc  MedOwnCostPctInc  \\\n",
       "count  1993.000000  1993.000000        1993.000000       1993.000000   \n",
       "mean      0.423121     0.384240           0.490070          0.449759   \n",
       "std       0.248249     0.213369           0.169524          0.187321   \n",
       "min       0.000000     0.000000           0.000000          0.000000   \n",
       "25%       0.220000     0.210000           0.370000          0.320000   \n",
       "50%       0.370000     0.340000           0.480000          0.450000   \n",
       "75%       0.590000     0.530000           0.590000          0.580000   \n",
       "max       1.000000     1.000000           1.000000          1.000000   \n",
       "\n",
       "       MedOwnCostPctIncNoMtg  NumInShelters    NumStreet  PctForeignBorn  \\\n",
       "count            1993.000000    1993.000000  1993.000000     1993.000000   \n",
       "mean                0.403638       0.029453     0.022790        0.215655   \n",
       "std                 0.192476       0.102630     0.100424        0.231146   \n",
       "min                 0.000000       0.000000     0.000000        0.000000   \n",
       "25%                 0.250000       0.000000     0.000000        0.060000   \n",
       "50%                 0.370000       0.000000     0.000000        0.130000   \n",
       "75%                 0.510000       0.010000     0.000000        0.280000   \n",
       "max                 1.000000       1.000000     1.000000        1.000000   \n",
       "\n",
       "       PctBornSameState  PctSameHouse85  PctSameCity85  PctSameState85  \\\n",
       "count       1993.000000     1993.000000    1993.000000     1993.000000   \n",
       "mean           0.608776        0.534967       0.626322        0.651470   \n",
       "std            0.204314        0.181360       0.200520        0.198253   \n",
       "min            0.000000        0.000000       0.000000        0.000000   \n",
       "25%            0.470000        0.420000       0.520000        0.560000   \n",
       "50%            0.630000        0.540000       0.670000        0.700000   \n",
       "75%            0.770000        0.660000       0.770000        0.790000   \n",
       "max            1.000000        1.000000       1.000000        1.000000   \n",
       "\n",
       "          LandArea      PopDens  PctUsePubTrans  LemasPctOfficDrugUn  \n",
       "count  1993.000000  1993.000000     1993.000000          1993.000000  \n",
       "mean      0.065243     0.232910        0.161741             0.094099  \n",
       "std       0.109485     0.203127        0.229099             0.240379  \n",
       "min       0.000000     0.000000        0.000000             0.000000  \n",
       "25%       0.020000     0.100000        0.020000             0.000000  \n",
       "50%       0.040000     0.170000        0.070000             0.000000  \n",
       "75%       0.070000     0.280000        0.190000             0.000000  \n",
       "max       1.000000     1.000000        1.000000             1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    display(dataContinuous.describe())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1202169e8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACN4AAAJTCAYAAADdFUndAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ee7a4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataContinuous.ix[:,0:20].plot.box(vert=True, figsize=(40, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x122b29390>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACOMAAAJTCAYAAABAGEBVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122b29550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Doing Log Transformation:\n",
    "np.log(dataContinuous.ix[:,20:40] + 0.000001).plot.box(vert=True, figsize=(40, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perCapInc</th>\n",
       "      <th>whitePerCap</th>\n",
       "      <th>blackPerCap</th>\n",
       "      <th>indianPerCap</th>\n",
       "      <th>AsianPerCap</th>\n",
       "      <th>OtherPerCap</th>\n",
       "      <th>HispPerCap</th>\n",
       "      <th>NumUnderPov</th>\n",
       "      <th>PctPopUnderPov</th>\n",
       "      <th>PctLess9thGrade</th>\n",
       "      <th>PctNotHSGrad</th>\n",
       "      <th>PctBSorMore</th>\n",
       "      <th>PctUnemployed</th>\n",
       "      <th>PctEmploy</th>\n",
       "      <th>PctEmplManu</th>\n",
       "      <th>PctEmplProfServ</th>\n",
       "      <th>PctOccupManu</th>\n",
       "      <th>PctOccupMgmtProf</th>\n",
       "      <th>MalePctDivorce</th>\n",
       "      <th>MalePctNevMarr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.237871</td>\n",
       "      <td>-1.237871</td>\n",
       "      <td>-1.309330</td>\n",
       "      <td>-1.832575</td>\n",
       "      <td>-1.427112</td>\n",
       "      <td>-0.967581</td>\n",
       "      <td>-1.347070</td>\n",
       "      <td>-4.605070</td>\n",
       "      <td>-1.966106e+00</td>\n",
       "      <td>-1.309330</td>\n",
       "      <td>-0.994250</td>\n",
       "      <td>-0.941606</td>\n",
       "      <td>-2.120255</td>\n",
       "      <td>-0.371062</td>\n",
       "      <td>-1.309330e+00</td>\n",
       "      <td>-9.942496e-01</td>\n",
       "      <td>-1.139431</td>\n",
       "      <td>-0.733967</td>\n",
       "      <td>-1.171180</td>\n",
       "      <td>-1.609433e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.514123</td>\n",
       "      <td>-1.237871</td>\n",
       "      <td>-1.897113</td>\n",
       "      <td>-13.815511</td>\n",
       "      <td>-1.237871</td>\n",
       "      <td>-13.815511</td>\n",
       "      <td>-1.966106</td>\n",
       "      <td>-3.911973</td>\n",
       "      <td>-7.985055e-01</td>\n",
       "      <td>-0.562117</td>\n",
       "      <td>-0.356674</td>\n",
       "      <td>-1.560643</td>\n",
       "      <td>-1.309330</td>\n",
       "      <td>-0.843968</td>\n",
       "      <td>9.999995e-07</td>\n",
       "      <td>-1.771951e+00</td>\n",
       "      <td>-0.072570</td>\n",
       "      <td>-1.427112</td>\n",
       "      <td>-0.867498</td>\n",
       "      <td>-1.139431e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.560643</td>\n",
       "      <td>-1.049819</td>\n",
       "      <td>-1.897113</td>\n",
       "      <td>-1.347070</td>\n",
       "      <td>-1.714793</td>\n",
       "      <td>-0.174352</td>\n",
       "      <td>-1.108660</td>\n",
       "      <td>-2.813394</td>\n",
       "      <td>-4.307814e-01</td>\n",
       "      <td>-0.733967</td>\n",
       "      <td>-0.544725</td>\n",
       "      <td>-1.272962</td>\n",
       "      <td>-0.235721</td>\n",
       "      <td>-1.514123</td>\n",
       "      <td>-8.209783e-01</td>\n",
       "      <td>-8.439677e-01</td>\n",
       "      <td>-0.616184</td>\n",
       "      <td>-0.891596</td>\n",
       "      <td>-0.371062</td>\n",
       "      <td>-1.021648e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.309330</td>\n",
       "      <td>-1.203969</td>\n",
       "      <td>-1.714793</td>\n",
       "      <td>-1.660726</td>\n",
       "      <td>-1.609433</td>\n",
       "      <td>-13.815511</td>\n",
       "      <td>-0.223142</td>\n",
       "      <td>-3.911973</td>\n",
       "      <td>-9.675814e-01</td>\n",
       "      <td>-0.673343</td>\n",
       "      <td>-0.527631</td>\n",
       "      <td>-1.139431</td>\n",
       "      <td>-0.994250</td>\n",
       "      <td>-0.843968</td>\n",
       "      <td>-4.462855e-01</td>\n",
       "      <td>-1.203969e+00</td>\n",
       "      <td>-0.653925</td>\n",
       "      <td>-0.776527</td>\n",
       "      <td>-0.755020</td>\n",
       "      <td>-1.171180e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.771951</td>\n",
       "      <td>-1.660726</td>\n",
       "      <td>-1.832575</td>\n",
       "      <td>-2.659246</td>\n",
       "      <td>-1.560643</td>\n",
       "      <td>-1.966106</td>\n",
       "      <td>-1.514123</td>\n",
       "      <td>-2.207266</td>\n",
       "      <td>9.999995e-07</td>\n",
       "      <td>-1.714793</td>\n",
       "      <td>-1.714793</td>\n",
       "      <td>-0.198450</td>\n",
       "      <td>-0.867498</td>\n",
       "      <td>-1.469672</td>\n",
       "      <td>-1.660726e+00</td>\n",
       "      <td>9.999995e-07</td>\n",
       "      <td>-1.386290</td>\n",
       "      <td>-0.400476</td>\n",
       "      <td>-2.407934</td>\n",
       "      <td>9.999995e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   perCapInc  whitePerCap  blackPerCap  indianPerCap  AsianPerCap  \\\n",
       "0  -1.237871    -1.237871    -1.309330     -1.832575    -1.427112   \n",
       "1  -1.514123    -1.237871    -1.897113    -13.815511    -1.237871   \n",
       "2  -1.560643    -1.049819    -1.897113     -1.347070    -1.714793   \n",
       "3  -1.309330    -1.203969    -1.714793     -1.660726    -1.609433   \n",
       "4  -1.771951    -1.660726    -1.832575     -2.659246    -1.560643   \n",
       "\n",
       "   OtherPerCap  HispPerCap  NumUnderPov  PctPopUnderPov  PctLess9thGrade  \\\n",
       "0    -0.967581   -1.347070    -4.605070   -1.966106e+00        -1.309330   \n",
       "1   -13.815511   -1.966106    -3.911973   -7.985055e-01        -0.562117   \n",
       "2    -0.174352   -1.108660    -2.813394   -4.307814e-01        -0.733967   \n",
       "3   -13.815511   -0.223142    -3.911973   -9.675814e-01        -0.673343   \n",
       "4    -1.966106   -1.514123    -2.207266    9.999995e-07        -1.714793   \n",
       "\n",
       "   PctNotHSGrad  PctBSorMore  PctUnemployed  PctEmploy   PctEmplManu  \\\n",
       "0     -0.994250    -0.941606      -2.120255  -0.371062 -1.309330e+00   \n",
       "1     -0.356674    -1.560643      -1.309330  -0.843968  9.999995e-07   \n",
       "2     -0.544725    -1.272962      -0.235721  -1.514123 -8.209783e-01   \n",
       "3     -0.527631    -1.139431      -0.994250  -0.843968 -4.462855e-01   \n",
       "4     -1.714793    -0.198450      -0.867498  -1.469672 -1.660726e+00   \n",
       "\n",
       "   PctEmplProfServ  PctOccupManu  PctOccupMgmtProf  MalePctDivorce  \\\n",
       "0    -9.942496e-01     -1.139431         -0.733967       -1.171180   \n",
       "1    -1.771951e+00     -0.072570         -1.427112       -0.867498   \n",
       "2    -8.439677e-01     -0.616184         -0.891596       -0.371062   \n",
       "3    -1.203969e+00     -0.653925         -0.776527       -0.755020   \n",
       "4     9.999995e-07     -1.386290         -0.400476       -2.407934   \n",
       "\n",
       "   MalePctNevMarr  \n",
       "0   -1.609433e+00  \n",
       "1   -1.139431e+00  \n",
       "2   -1.021648e+00  \n",
       "3   -1.171180e+00  \n",
       "4    9.999995e-07  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformedData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12482c898>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACOMAAAJTCAYAAABAGEBVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12533aba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "dataTransformed = np.log(dataContinuous + 0.00001)  # Add a small amount of noise to avoid log(0)\n",
    "scallerSTD = StandardScaler()\n",
    "dataScaled = scallerSTD.fit_transform(dataTransformed)\n",
    "dataScaled = pd.DataFrame(dataScaled, columns=dataContinuous.columns)\n",
    "# scaledData.plot.box(vert=True, figsize=(40, 10))\n",
    "dataScaled.ix[:,20:40].plot.box(vert=True, figsize=(40, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.665290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.562340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.398627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ViolentCrimesPerPop\n",
       "0            -0.665290\n",
       "1             0.005554\n",
       "2             1.562340\n",
       "3             0.398627\n",
       "4             0.060181"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetContinuous = crimeDF[regTargetVar]\n",
    "\n",
    "targetTransformed = np.log(targetContinuous + 0.00001)  # Add a small amount of noise to avoid log(0)\n",
    "scallerSTD = StandardScaler()\n",
    "targetScaled = scallerSTD.fit_transform(targetTransformed)\n",
    "targetScaled = pd.DataFrame(targetScaled, columns=targetContinuous.columns)\n",
    "targetScaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE for the best model based on cross validation is (0.430933258646) and the corresponding norm co-efficient alpha is:  0.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "alpha = np.array([100,10, 1, 0.1, 0.01, 0.001], dtype='float64')   # 100,10, 1, 0.1, 0.01, 0.001\n",
    "\n",
    "classifierRR_cv = RidgeCV(alpha, cv=cv)\n",
    "\n",
    "classifierRR_cv = classifierRR_cv.fit(dataScaled, targetScaled)\n",
    "predictionContinuousRR_cv = classifierRR_cv.predict(dataScaled)\n",
    "# print (predictContinuous)\n",
    "\n",
    "mseRR_Best = metrics.mean_squared_error(targetScaled, predictionContinuousRR_cv)\n",
    "alpha_Best = classifierRR_cv.alpha_\n",
    "print ('The MSE for the best model based on cross validation is (%s) and the corresponding norm co-efficient alpha is: '%str(mseRR_Best), alpha_Best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE for the best model based on cross validation is (0.0197610792858) and the corresponding norm co-efficient alpha is:  50.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "alpha = np.array([50,10, 1, 0.1, 0.01, 0.001], dtype='float64')\n",
    "\n",
    "classifierRR_cv = RidgeCV(alpha, cv=cv)\n",
    "\n",
    "classifierRR_cv = classifierRR_cv.fit(dataScaled, targetContinuous)\n",
    "predictionContinuousRR_cv = classifierRR_cv.predict(dataScaled)\n",
    "# print (predictContinuous)\n",
    "\n",
    "mseRR_Best = metrics.mean_squared_error(targetContinuous, predictionContinuousRR_cv)\n",
    "alpha_Best = classifierRR_cv.alpha_\n",
    "print ('The MSE for the best model based on cross validation is (%s) and the corresponding norm co-efficient alpha is: '%str(mseRR_Best), alpha_Best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "0.019507038311"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
