{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227463, 29)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data_dir = '/Users/sam/All-Program/App-DataSet/z-others/creditcard.csv'\n",
    "data = pd.read_csv(data_dir)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data = data.drop(['Time'], axis=1)\n",
    "data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "\n",
    "X_train, X_test = train_test_split(data, test_size=0.2, random_state=7676)\n",
    "X_train = X_train[X_train.Class == 0]\n",
    "X_train = X_train.drop(['Class'], axis=1)\n",
    "y_test = X_test['Class']\n",
    "X_test = X_test.drop(['Class'], axis=1)\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Activation, regularizers\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 14\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", \n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
    "decoder = Dense(int(encoding_dim / 2), activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 227463 samples, validate on 56962 samples\n",
      "Epoch 1/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7099 - acc: 0.6946 - val_loss: 0.7649 - val_acc: 0.6915\n",
      "Epoch 2/100\n",
      "227463/227463 [==============================] - 12s 51us/step - loss: 0.7100 - acc: 0.6941 - val_loss: 0.7658 - val_acc: 0.6938\n",
      "Epoch 3/100\n",
      "227463/227463 [==============================] - 12s 51us/step - loss: 0.7094 - acc: 0.6950 - val_loss: 0.7695 - val_acc: 0.6843\n",
      "Epoch 4/100\n",
      "227463/227463 [==============================] - 12s 51us/step - loss: 0.7101 - acc: 0.6944 - val_loss: 0.7651 - val_acc: 0.6870\n",
      "Epoch 5/100\n",
      "227463/227463 [==============================] - 12s 51us/step - loss: 0.7101 - acc: 0.6944 - val_loss: 0.7662 - val_acc: 0.6943\n",
      "Epoch 6/100\n",
      "227463/227463 [==============================] - 12s 51us/step - loss: 0.7095 - acc: 0.6942 - val_loss: 0.7657 - val_acc: 0.6973\n",
      "Epoch 7/100\n",
      "227463/227463 [==============================] - 12s 51us/step - loss: 0.7096 - acc: 0.6955 - val_loss: 0.7639 - val_acc: 0.6983\n",
      "Epoch 8/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7097 - acc: 0.6953 - val_loss: 0.7652 - val_acc: 0.6934\n",
      "Epoch 9/100\n",
      "227463/227463 [==============================] - 12s 51us/step - loss: 0.7099 - acc: 0.6956 - val_loss: 0.7671 - val_acc: 0.6965\n",
      "Epoch 10/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7096 - acc: 0.6946 - val_loss: 0.7656 - val_acc: 0.6970\n",
      "Epoch 11/100\n",
      "227463/227463 [==============================] - 12s 51us/step - loss: 0.7090 - acc: 0.6953 - val_loss: 0.7641 - val_acc: 0.6928\n",
      "Epoch 12/100\n",
      "227463/227463 [==============================] - 12s 51us/step - loss: 0.7091 - acc: 0.6953 - val_loss: 0.7972 - val_acc: 0.6215\n",
      "Epoch 13/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7093 - acc: 0.6956 - val_loss: 0.7628 - val_acc: 0.6953\n",
      "Epoch 14/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7090 - acc: 0.6953 - val_loss: 0.7648 - val_acc: 0.6959\n",
      "Epoch 15/100\n",
      "227463/227463 [==============================] - 12s 51us/step - loss: 0.7096 - acc: 0.6951 - val_loss: 0.7638 - val_acc: 0.6955\n",
      "Epoch 16/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7088 - acc: 0.6958 - val_loss: 0.7637 - val_acc: 0.6997\n",
      "Epoch 17/100\n",
      "227463/227463 [==============================] - 12s 51us/step - loss: 0.7092 - acc: 0.6960 - val_loss: 0.7642 - val_acc: 0.6905\n",
      "Epoch 18/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7093 - acc: 0.6958 - val_loss: 0.7642 - val_acc: 0.6895\n",
      "Epoch 19/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7090 - acc: 0.6959 - val_loss: 0.7947 - val_acc: 0.6743\n",
      "Epoch 20/100\n",
      "227463/227463 [==============================] - 12s 51us/step - loss: 0.7091 - acc: 0.6960 - val_loss: 0.7700 - val_acc: 0.6850\n",
      "Epoch 21/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7088 - acc: 0.6959 - val_loss: 0.7636 - val_acc: 0.6979\n",
      "Epoch 22/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7090 - acc: 0.6958 - val_loss: 0.7651 - val_acc: 0.6955\n",
      "Epoch 23/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7089 - acc: 0.6952 - val_loss: 0.7642 - val_acc: 0.6893\n",
      "Epoch 24/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7094 - acc: 0.6959 - val_loss: 0.7725 - val_acc: 0.6878\n",
      "Epoch 25/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7091 - acc: 0.6959 - val_loss: 0.7659 - val_acc: 0.6942\n",
      "Epoch 26/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7085 - acc: 0.6958 - val_loss: 0.7647 - val_acc: 0.6920\n",
      "Epoch 27/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7090 - acc: 0.6955 - val_loss: 0.7627 - val_acc: 0.6946\n",
      "Epoch 28/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7087 - acc: 0.6958 - val_loss: 0.7632 - val_acc: 0.6976\n",
      "Epoch 29/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7090 - acc: 0.6962 - val_loss: 0.7636 - val_acc: 0.6982\n",
      "Epoch 30/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7089 - acc: 0.6962 - val_loss: 0.7631 - val_acc: 0.6958\n",
      "Epoch 31/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7087 - acc: 0.6965 - val_loss: 0.7635 - val_acc: 0.6930\n",
      "Epoch 32/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7093 - acc: 0.6967 - val_loss: 0.7641 - val_acc: 0.6948\n",
      "Epoch 33/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7085 - acc: 0.6957 - val_loss: 0.7636 - val_acc: 0.6937\n",
      "Epoch 34/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7086 - acc: 0.6971 - val_loss: 0.7636 - val_acc: 0.7001\n",
      "Epoch 35/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7089 - acc: 0.6956 - val_loss: 0.7632 - val_acc: 0.6917\n",
      "Epoch 36/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7087 - acc: 0.6960 - val_loss: 0.7662 - val_acc: 0.6878\n",
      "Epoch 37/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7087 - acc: 0.6960 - val_loss: 0.7640 - val_acc: 0.6950\n",
      "Epoch 38/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7086 - acc: 0.6960 - val_loss: 0.7636 - val_acc: 0.6944\n",
      "Epoch 39/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7090 - acc: 0.6963 - val_loss: 0.7629 - val_acc: 0.6981\n",
      "Epoch 40/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7084 - acc: 0.6970 - val_loss: 0.7657 - val_acc: 0.7004\n",
      "Epoch 41/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7087 - acc: 0.6958 - val_loss: 0.7626 - val_acc: 0.6975\n",
      "Epoch 42/100\n",
      "227463/227463 [==============================] - 12s 54us/step - loss: 0.7088 - acc: 0.6962 - val_loss: 0.7628 - val_acc: 0.6999\n",
      "Epoch 43/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7091 - acc: 0.6964 - val_loss: 0.7630 - val_acc: 0.6977\n",
      "Epoch 44/100\n",
      "227463/227463 [==============================] - 13s 55us/step - loss: 0.7084 - acc: 0.6968 - val_loss: 0.7648 - val_acc: 0.6926\n",
      "Epoch 45/100\n",
      "227463/227463 [==============================] - 11s 51us/step - loss: 0.7083 - acc: 0.6962 - val_loss: 0.7636 - val_acc: 0.6957\n",
      "Epoch 46/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7086 - acc: 0.6967 - val_loss: 0.7645 - val_acc: 0.6984\n",
      "Epoch 47/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7084 - acc: 0.6960 - val_loss: 0.7643 - val_acc: 0.6937\n",
      "Epoch 48/100\n",
      "227463/227463 [==============================] - 11s 50us/step - loss: 0.7087 - acc: 0.6961 - val_loss: 0.7670 - val_acc: 0.6911\n",
      "Epoch 49/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7085 - acc: 0.6965 - val_loss: 0.7655 - val_acc: 0.6966\n",
      "Epoch 50/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7086 - acc: 0.6966 - val_loss: 0.7622 - val_acc: 0.6972\n",
      "Epoch 51/100\n",
      "227463/227463 [==============================] - 11s 49us/step - loss: 0.7087 - acc: 0.6972 - val_loss: 0.7617 - val_acc: 0.6988\n",
      "Epoch 52/100\n",
      "227463/227463 [==============================] - 11s 49us/step - loss: 0.7084 - acc: 0.6970 - val_loss: 0.7749 - val_acc: 0.6638\n",
      "Epoch 53/100\n",
      "227463/227463 [==============================] - 11s 49us/step - loss: 0.7083 - acc: 0.6970 - val_loss: 0.7645 - val_acc: 0.6908\n",
      "Epoch 54/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7085 - acc: 0.6962 - val_loss: 0.7651 - val_acc: 0.6882\n",
      "Epoch 55/100\n",
      "227463/227463 [==============================] - 11s 49us/step - loss: 0.7083 - acc: 0.6976 - val_loss: 0.7648 - val_acc: 0.6967\n",
      "Epoch 56/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7081 - acc: 0.6971 - val_loss: 0.7696 - val_acc: 0.6847\n",
      "Epoch 57/100\n",
      "227463/227463 [==============================] - 11s 49us/step - loss: 0.7087 - acc: 0.6965 - val_loss: 0.7651 - val_acc: 0.6923\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7083 - acc: 0.6970 - val_loss: 0.7786 - val_acc: 0.6552\n",
      "Epoch 59/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7087 - acc: 0.6964 - val_loss: 0.7685 - val_acc: 0.6962\n",
      "Epoch 60/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7082 - acc: 0.6969 - val_loss: 0.7638 - val_acc: 0.6979\n",
      "Epoch 61/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7087 - acc: 0.6973 - val_loss: 0.7639 - val_acc: 0.6960\n",
      "Epoch 62/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7083 - acc: 0.6968 - val_loss: 0.7651 - val_acc: 0.6950\n",
      "Epoch 63/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7085 - acc: 0.6960 - val_loss: 0.7622 - val_acc: 0.7005\n",
      "Epoch 64/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7081 - acc: 0.6980 - val_loss: 0.7621 - val_acc: 0.6931\n",
      "Epoch 65/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7086 - acc: 0.6968 - val_loss: 0.7714 - val_acc: 0.6872\n",
      "Epoch 66/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7083 - acc: 0.6972 - val_loss: 0.7624 - val_acc: 0.6992\n",
      "Epoch 67/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7081 - acc: 0.6974 - val_loss: 0.7639 - val_acc: 0.6978\n",
      "Epoch 68/100\n",
      "227463/227463 [==============================] - 11s 49us/step - loss: 0.7085 - acc: 0.6977 - val_loss: 0.7642 - val_acc: 0.6975\n",
      "Epoch 69/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7082 - acc: 0.6979 - val_loss: 0.7639 - val_acc: 0.6976\n",
      "Epoch 70/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7088 - acc: 0.6976 - val_loss: 0.7634 - val_acc: 0.6982\n",
      "Epoch 71/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7076 - acc: 0.6980 - val_loss: 0.7640 - val_acc: 0.6937\n",
      "Epoch 72/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7081 - acc: 0.6971 - val_loss: 0.7624 - val_acc: 0.6977\n",
      "Epoch 73/100\n",
      "227463/227463 [==============================] - 11s 49us/step - loss: 0.7084 - acc: 0.6978 - val_loss: 0.7676 - val_acc: 0.6868\n",
      "Epoch 74/100\n",
      "227463/227463 [==============================] - 11s 49us/step - loss: 0.7082 - acc: 0.6965 - val_loss: 0.7630 - val_acc: 0.6918\n",
      "Epoch 75/100\n",
      "227463/227463 [==============================] - 11s 49us/step - loss: 0.7083 - acc: 0.6984 - val_loss: 0.7631 - val_acc: 0.6924\n",
      "Epoch 76/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7082 - acc: 0.6973 - val_loss: 0.7645 - val_acc: 0.6820\n",
      "Epoch 77/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7082 - acc: 0.6978 - val_loss: 0.7621 - val_acc: 0.6956\n",
      "Epoch 78/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7083 - acc: 0.6970 - val_loss: 0.7623 - val_acc: 0.7008\n",
      "Epoch 79/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7081 - acc: 0.6974 - val_loss: 0.7626 - val_acc: 0.7018\n",
      "Epoch 80/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7079 - acc: 0.6978 - val_loss: 0.7617 - val_acc: 0.7002\n",
      "Epoch 81/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7079 - acc: 0.6978 - val_loss: 0.7635 - val_acc: 0.6961\n",
      "Epoch 82/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7080 - acc: 0.6977 - val_loss: 0.7619 - val_acc: 0.6957\n",
      "Epoch 83/100\n",
      "227463/227463 [==============================] - 13s 58us/step - loss: 0.7084 - acc: 0.6969 - val_loss: 0.7651 - val_acc: 0.6918\n",
      "Epoch 84/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7085 - acc: 0.6970 - val_loss: 0.7619 - val_acc: 0.6978\n",
      "Epoch 85/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7080 - acc: 0.6978 - val_loss: 0.7619 - val_acc: 0.6968\n",
      "Epoch 86/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7080 - acc: 0.6981 - val_loss: 0.7630 - val_acc: 0.6987\n",
      "Epoch 87/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7078 - acc: 0.6984 - val_loss: 0.7621 - val_acc: 0.6956\n",
      "Epoch 88/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7089 - acc: 0.6969 - val_loss: 0.7626 - val_acc: 0.6986\n",
      "Epoch 89/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7080 - acc: 0.6983 - val_loss: 0.7642 - val_acc: 0.6931\n",
      "Epoch 90/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7080 - acc: 0.6979 - val_loss: 0.7626 - val_acc: 0.6958\n",
      "Epoch 91/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7082 - acc: 0.6982 - val_loss: 0.7620 - val_acc: 0.6941\n",
      "Epoch 92/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7081 - acc: 0.6981 - val_loss: 0.7612 - val_acc: 0.6983\n",
      "Epoch 93/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7077 - acc: 0.6974 - val_loss: 0.7670 - val_acc: 0.6955\n",
      "Epoch 94/100\n",
      "227463/227463 [==============================] - 12s 54us/step - loss: 0.7084 - acc: 0.6970 - val_loss: 0.7630 - val_acc: 0.6990\n",
      "Epoch 95/100\n",
      "227463/227463 [==============================] - 12s 51us/step - loss: 0.7079 - acc: 0.6975 - val_loss: 0.7694 - val_acc: 0.6945\n",
      "Epoch 96/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7079 - acc: 0.6978 - val_loss: 0.7719 - val_acc: 0.6768\n",
      "Epoch 97/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7080 - acc: 0.6978 - val_loss: 0.7627 - val_acc: 0.6948\n",
      "Epoch 98/100\n",
      "227463/227463 [==============================] - 11s 48us/step - loss: 0.7085 - acc: 0.6973 - val_loss: 0.7618 - val_acc: 0.7030\n",
      "Epoch 99/100\n",
      "227463/227463 [==============================] - 12s 52us/step - loss: 0.7080 - acc: 0.6983 - val_loss: 0.7614 - val_acc: 0.6990\n",
      "Epoch 100/100\n",
      "227463/227463 [==============================] - 12s 53us/step - loss: 0.7078 - acc: 0.6975 - val_loss: 0.7629 - val_acc: 0.6989\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "filepath=\"/Users/sam/All-Program/App-DataSet/DataScienceProjects/CreditCardFraud/autoencoder_checkpoints/model.h5\"\n",
    "nb_epoch = 100\n",
    "batch_size = 32\n",
    "autoencoder.compile(optimizer='adam', \n",
    "                    loss='mean_squared_error', \n",
    "                    metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath=filepath,\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir='./logs',\n",
    "                          histogram_freq=0,\n",
    "                          write_graph=True,\n",
    "                          write_images=True)\n",
    "history = autoencoder.fit(X_train, X_train,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_test, X_test),\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpointer, tensorboard]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"/Users/sam/All-Program/App-DataSet/DataScienceProjects/CreditCardFraud/autoencoder_checkpoints/model.h5\"\n",
    "autoencoder = load_model(filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
