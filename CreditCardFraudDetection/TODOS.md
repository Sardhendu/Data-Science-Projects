

To Do's :

* L2 Regularization  **DONE** --> improves the model
* Batch Normalization
* Learning Rate Decay

Start the experiment with 1 hidden Layer and few nodes and then increase the
number of hidden layer and layer nodes


Baseline by https://uu.diva-portal.org/smash/get/diva2:1150344/FULLTEXT01.pdf
4 Hidden layer with 20 nodes each
Converges at epoch 200 and learning rate 0.005
Batch size = 2048
'''