{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.mllib.stat import Statistics\n",
    "import csv\n",
    "import numpy as np\n",
    "from ggplot import *\n",
    "\n",
    "# conf = SparkConf().setAppName('ListnerSummarizer')\n",
    "# sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f1dd1774f752>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparseLine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "trackfilepath = \"/Users/sam/All-Program/App-DataSet/Spark-Operations/input1.txt\"\n",
    "\n",
    "# trackfile = sc.texFile(trackfilepath)\n",
    "\n",
    "def parseLine(line):\n",
    "    infoArray = line.split(\",\")       # Split the line into tokens\n",
    "#     print (bits)\n",
    "    print ([e for e in infoArray])\n",
    "    return np.array([float(e) for e in infoArray[4:12]])\n",
    "    \n",
    "    \n",
    "df = sc.textFile(trackfilepath).map(parseLine)\n",
    "print (df)\n",
    "\n",
    "# Run the Map Task to find the summary statistics\n",
    "stats = df.map(lambda e: e[0])\n",
    "print (stats)\n",
    "# print (df.head)\n",
    "# a = .join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "del sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Rough:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext#, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "import csv\n",
    "import numpy as np\n",
    "# from pyspark.mllib.stat import Statistics\n",
    "# import csv\n",
    "# import numpy as np\n",
    "# from ggplot import *\n",
    "\n",
    "directory = \"/Users/sam/All-Program/App-DataSet/Spark-Operations/test138026.txt\"\n",
    "trackfilepath = \"/Users/sam/All-Program/App-DataSet/Spark-Operations/input.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataRDD = sc.textFile(trackfilepath)\n",
    "dataRDD = dataRDD.mapPartitions(lambda x: csv.reader(x))\n",
    "dataDF = sqlContext.read.load(trackfilepath, \n",
    "                          format='com.databricks.spark.csv', \n",
    "                          header='true', \n",
    "                          inferSchema='true')\n",
    "\n",
    "schema = dataDF.schema            \n",
    "            \n",
    "\n",
    "# schema1 = dataDF1.schema\n",
    "print (dataRDD.take(3))\n",
    "# print ('')\n",
    "print (dataDF.show())\n",
    "print('')\n",
    "print (schema)\n",
    "print ('')\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "def scoreToCategory(value):\n",
    "    if value == 'Joe': return 'Joewa'\n",
    "    else: return np.NaN\n",
    "\n",
    "udfScoreToCategory=udf(scoreToCategory, StringType())\n",
    "dataDF.withColumn(\"Name\", udfScoreToCategory(\"Name\")).show(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def splitWords(line):\n",
    "    return line.split(\",\")\n",
    "\n",
    "def createPair(words):\n",
    "    return (words, 1)\n",
    "\n",
    "def wordCount(cnt1,cnt2):\n",
    "    return cnt1+cnt2\n",
    "\n",
    "def records_wth_joy(word):\n",
    "    if word == \"Joy\":\n",
    "        return word\n",
    "    #     print (word)\n",
    "\n",
    "    \n",
    "ex1RDD = sc.textFile(directory)\n",
    "\n",
    "print (ex1RDD.take(5))\n",
    "\n",
    "\n",
    "# Operation Map\n",
    "wordToken = ex1RDD.flatMap(splitWords)\n",
    "wordPair = wordToken.map(createPair)\n",
    "print ('WordToken operation :', wordToken.take(1))\n",
    "print ('')\n",
    "print ('WordCountPair operation :', wordPair.take(1))\n",
    "print ('')\n",
    "\n",
    "# Operation Reduce\n",
    "reduceRDD = wordPair.reduceByKey(wordCount)\n",
    "# See the Output\n",
    "print ('Reduce by operation :', reduceRDD.collect())\n",
    "print ('')\n",
    "\n",
    "# Operation Filter\n",
    "filtRDD = wordToken.filter(records_wth_joy)\n",
    "print ('Filter by operation :', filtRDD.collect())\n",
    "print ('')\n",
    "\n",
    "# Operation Coelesce: Some times a filter may result in RDD partitions of different size, Hence we coelesce to make partitin of similar size\n",
    "partitionRDD = filtRDD.coalesce(2).glom()\n",
    "print ('Coelesce operation :', partitionRDD.collect())  # This will partition the data in two uniform parts.\n",
    "print ('')\n",
    "\n",
    "# GroupBY Operation\n",
    "groupbyRDD = wordPair.groupByKey()\n",
    "# print ('Group by key : ', groupbyRDD.collect())   # This will print the RDD object\n",
    "for key,value in groupbyRDD.collect():\n",
    "    print (key,list(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def splitLines(lines):\n",
    "    val = lines.split(',')\n",
    "    return val\n",
    "\n",
    "def thirdWordInt(value):\n",
    "    value[2] = int(value[2])\n",
    "    return value\n",
    "\n",
    "def keyValueList(splitList):\n",
    "#     key = spitList[0]\n",
    "#     value = (splitList[1])\n",
    "    return (splitList[0], tuple(splitList))\n",
    "    \n",
    "    \n",
    "# Question 1\n",
    "print ('Question 1')\n",
    "print (ex1RDD.take(5))\n",
    "print ('')\n",
    "# print (testData.take(5))\n",
    "\n",
    "# Question 2:\n",
    "print ('Question 2')\n",
    "ex2RDD = ex1RDD.flatMap(lambda line: line.split(\" \")).map(lambda sep: sep.split(','))\n",
    "# ex2RDD1 = ex2RDD.reduceByKey(lambda out: out)\n",
    "# OR\n",
    "ex2RDD_al = ex1RDD.flatMap(lambda line: line.split(\" \")).map(splitLines)\n",
    "print (ex2RDD.take(5))\n",
    "print ('')\n",
    "print (ex2RDD_al.take(5))\n",
    "print ('')\n",
    "# print (ex2RDD1.collect(10))\n",
    "\n",
    "\n",
    "# Question 3:\n",
    "print ('Question 3')\n",
    "ex3RDD = ex2RDD.map(lambda cnvrt: [cnvrt[0], cnvrt[1], int(cnvrt[2]), cnvrt[3], cnvrt[4]])\n",
    "# OR\n",
    "ex3RDD_al = ex2RDD.map(thirdWordInt)\n",
    "print (ex3RDD.take(5))\n",
    "print ('')\n",
    "print (ex3RDD_al.take(5))\n",
    "print ('')\n",
    "\n",
    "\n",
    "# Question 4\n",
    "print ('Question 4')\n",
    "ex4RDD = ex3RDD.filter(lambda cond: cond[2]<25)\n",
    "ex4RDD_al = ex3RDD.map(lambda cond: cond if cond[2]<25 else None)\n",
    "print (ex4RDD.take(5))\n",
    "print ('')\n",
    "print (ex4RDD_al.take(5))\n",
    "print ('')\n",
    "\n",
    "\n",
    "# Question 5\n",
    "print ('Question 5')\n",
    "ex5RDD = ex4RDD.map(lambda a: (a[0],tuple(a)))\n",
    "ex5RDD_al = ex4RDD.map(keyValueList)\n",
    "print (ex5RDD.take(5))\n",
    "print ('')\n",
    "print (ex5RDD_al.take(5))\n",
    "print ('')\n",
    "\n",
    "# Question 6\n",
    "print ('Question 6')\n",
    "ex6RDD = ex5RDD.sortByKey(True)\n",
    "print (ex6RDD.take(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assignment -9:\n",
    "from pyspark.sql import Row\n",
    "\n",
    "trackfilepath = \"/Users/sam/All-Program/App-DataSet/Spark-Operations/test130757.txt\"\n",
    "\n",
    "step1RDD = sc.textFile(trackfilepath)\n",
    "print (step1RDD.take(5))\n",
    "print ('')\n",
    "\n",
    "step2RDD = step1RDD.map(lambda l: l.split(','))\n",
    "print (step2RDD.take(5))\n",
    "print ('')\n",
    "\n",
    "step3RDD = step2RDD.map(lambda l: Row(name=l[0], f2=int(l[1]), f3=int(l[2]), f4=int(l[3]), f5=int(l[4]) ))\n",
    "print (step3RDD.take(5))\n",
    "print ('')\n",
    "\n",
    "# ex2DF = step3RDD.toDF()\n",
    "\n",
    "ex2DF = sqlCtx.createDataFrame(step3RDD)\n",
    "print (ex2DF.head(5))\n",
    "print ('')\n",
    "\n",
    "sqlContext.registerDataFrameAsTable(ex2DF, 'ex3Table')\n",
    "ex3DF = sqlCtx.sql(\"select * from ex3Table where f2<25 and f4>40\")\n",
    "print (ex3DF.head(5))\n",
    "print ('')\n",
    "\n",
    "# sqlContext.registerDataFrameAsTable(ex3DF, 'ex4Table')\n",
    "ex4DF = sqlCtx.sql(\"select name, f3 from ex3Table where f3<30 and f2<25 and f4>40\")\n",
    "print (ex4DF.head(5))\n",
    "\n",
    "ex5DF = ex3DF.describe(['f3', 'f4'])\n",
    "ex5DF.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      male\n",
       "1    female\n",
       "2    female\n",
       "3    female\n",
       "4      male\n",
       "Name: Sex, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "trackfilepath = \"/Users/sam/All-Program/App-DataSet/Spark-Operations/Titanic.txt\"\n",
    "\n",
    "titanic_train = pd.read_csv(trackfilepath) \n",
    "titanic_train.head()\n",
    "char_cabin = titanic_train[\"Cabin\"].astype(str)\n",
    "char_cabin\n",
    "new_Cabin = np.array([cabin[0] for cabin in char_cabin])\n",
    "new_Cabin\n",
    "titanic_train[\"Cabin\"] = pd.Categorical(new_Cabin)\n",
    "titanic_train[\"Cabin\"].head()\n",
    "titanic_train[\"Sex\"].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9c0a6f3515d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabel_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mencoded_sex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitanic_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Sex\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mencoded_sex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "encoded_sex = label_encoder.fit_transform(titanic_train[\"Sex\"])\n",
    "# encoded_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 2, 8, 2, 8, 8, 4, 8, 8, 8, 6, 2, 8, 8, 8, 8, 8, 8, 8, 8, 8, 3, 8,\n",
       "       0, 8, 8, 8, 2, 8, 8, 8, 1, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 3, 8, 1, 2, 8, 8, 8, 8, 8, 1, 2, 8, 8, 8, 5, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 5, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 8, 8, 8,\n",
       "       4, 8, 8, 8, 0, 3, 8, 8, 8, 8, 3, 8, 8, 8, 8, 8, 8, 8, 2, 8, 8, 8, 8,\n",
       "       8, 8, 8, 1, 8, 8, 8, 8, 4, 3, 8, 8, 8, 5, 8, 8, 8, 8, 8, 8, 8, 3, 2,\n",
       "       8, 1, 8, 8, 8, 8, 8, 8, 8, 8, 5, 8, 8, 2, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 4, 8, 8, 8, 1, 8, 8, 8, 0, 8, 8, 2, 8, 8, 8, 8, 8, 5,\n",
       "       8, 0, 8, 8, 8, 8, 8, 8, 8, 5, 1, 1, 8, 8, 8, 8, 8, 8, 8, 8, 8, 6, 8,\n",
       "       8, 8, 0, 8, 8, 8, 8, 8, 3, 8, 8, 3, 8, 8, 8, 8, 8, 2, 8, 8, 8, 8, 8,\n",
       "       2, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 8, 8, 3, 8, 8, 6, 2,\n",
       "       8, 8, 8, 8, 1, 8, 8, 8, 8, 4, 1, 8, 8, 8, 8, 2, 2, 8, 8, 8, 2, 8, 3,\n",
       "       8, 8, 8, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 8, 1, 3, 8, 8, 8, 8, 2, 2,\n",
       "       1, 8, 8, 8, 4, 8, 2, 8, 2, 8, 4, 2, 1, 8, 8, 8, 8, 8, 8, 2, 4, 8, 8,\n",
       "       8, 8, 8, 2, 8, 3, 8, 1, 8, 2, 2, 8, 8, 8, 2, 4, 8, 7, 5, 2, 8, 8, 8,\n",
       "       5, 8, 8, 8, 8, 8, 2, 8, 8, 8, 8, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 3, 8,\n",
       "       8, 1, 4, 8, 8, 8, 8, 8, 8, 2, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1,\n",
       "       8, 8, 3, 6, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 2, 8, 8, 8, 4, 1, 8,\n",
       "       8, 2, 8, 8, 8, 8, 8, 8, 0, 8, 8, 8, 2, 8, 8, 2, 2, 8, 8, 4, 3, 8, 8,\n",
       "       4, 8, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 3, 8, 0, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 1, 8, 2, 1, 8, 8, 8, 8, 2, 8, 8, 8, 3, 8, 2, 8, 8, 8, 8, 8, 1, 2,\n",
       "       8, 8, 8, 8, 8, 8, 4, 8, 8, 3, 5, 8, 8, 8, 1, 8, 8, 1, 8, 8, 8, 2, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8, 1, 8, 8, 1, 1, 8, 8, 8, 2, 8, 8, 8, 8, 8, 2, 8,\n",
       "       8, 8, 8, 8, 0, 8, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 4, 8, 8,\n",
       "       8, 8, 4, 8, 8, 8, 2, 8, 0, 8, 4, 8, 1, 8, 8, 8, 3, 8, 8, 8, 8, 8, 8,\n",
       "       8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 8, 8, 8, 8, 8, 8, 8, 8, 5, 8, 8,\n",
       "       3, 8, 8, 8, 3, 8, 3, 8, 8, 0, 8, 1, 8, 8, 8, 8, 8, 8, 8, 8, 1, 8, 8,\n",
       "       8, 3, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 3, 8, 8, 4, 8, 8, 8, 8,\n",
       "       8, 8, 2, 8, 1, 8, 8, 8, 8, 8, 8, 8, 1, 8, 3, 8, 8, 8, 8, 8, 8, 8, 1,\n",
       "       1, 8, 8, 8, 8, 8, 8, 8, 2, 5, 2, 4, 8, 8, 8, 8, 8, 4, 8, 8, 2, 2, 2,\n",
       "       8, 8, 5, 2, 4, 8, 8, 8, 8, 8, 8, 4, 8, 8, 8, 8, 8, 1, 8, 8, 8, 8, 8,\n",
       "       8, 1, 8, 8, 3, 2, 1, 8, 8, 1, 8, 8, 3, 8, 8, 4, 8, 8, 8, 8, 8, 8, 8,\n",
       "       1, 8, 8, 8, 1, 8, 3, 8, 8, 8, 8, 8, 8, 4, 8, 8, 8, 5, 8, 8, 1, 8, 1,\n",
       "       3, 8, 8, 8, 8, 8, 8, 1, 8, 8, 8, 8, 8, 8, 3, 8, 8, 8, 8, 8, 1, 8, 8,\n",
       "       8, 0, 8, 8, 4, 8, 8, 8, 8, 8, 1, 8, 8, 8, 8, 1, 8, 8, 4, 8, 8, 8, 8,\n",
       "       8, 1, 8, 8, 8, 8, 8, 4, 8, 8, 8, 2, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 8,\n",
       "       8, 8, 3, 8, 8, 8, 4, 8, 8, 8, 8, 3, 8, 8, 8, 8, 0, 8, 8, 8, 3, 1, 8,\n",
       "       8, 8, 8, 8, 8, 2, 8, 8, 8, 8, 8, 8, 8, 1, 8, 2, 8])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_class = label_encoder.fit_transform(titanic_train[\"Pclass\"])\n",
    "encoded_cabin = label_encoder.fit_transform(titanic_train[\"Cabin\"])\n",
    "encoded_cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2     3\n",
       "0    2.0  8.0  1.0  22.0\n",
       "1    0.0  2.0  0.0  38.0\n",
       "2    2.0  8.0  0.0  26.0\n",
       "3    0.0  2.0  0.0  35.0\n",
       "4    2.0  8.0  1.0  35.0\n",
       "5    2.0  8.0  1.0   NaN\n",
       "6    0.0  4.0  1.0  54.0\n",
       "7    2.0  8.0  1.0   2.0\n",
       "8    2.0  8.0  0.0  27.0\n",
       "9    1.0  8.0  0.0  14.0\n",
       "10   2.0  6.0  0.0   4.0\n",
       "11   0.0  2.0  0.0  58.0\n",
       "12   2.0  8.0  1.0  20.0\n",
       "13   2.0  8.0  1.0  39.0\n",
       "14   2.0  8.0  0.0  14.0\n",
       "15   1.0  8.0  0.0  55.0\n",
       "16   2.0  8.0  1.0   2.0\n",
       "17   1.0  8.0  1.0   NaN\n",
       "18   2.0  8.0  0.0  31.0\n",
       "19   2.0  8.0  0.0   NaN\n",
       "20   1.0  8.0  1.0  35.0\n",
       "21   1.0  3.0  1.0  34.0\n",
       "22   2.0  8.0  0.0  15.0\n",
       "23   0.0  0.0  1.0  28.0\n",
       "24   2.0  8.0  0.0   8.0\n",
       "25   2.0  8.0  0.0  38.0\n",
       "26   2.0  8.0  1.0   NaN\n",
       "27   0.0  2.0  1.0  19.0\n",
       "28   2.0  8.0  0.0   NaN\n",
       "29   2.0  8.0  1.0   NaN\n",
       "..   ...  ...  ...   ...\n",
       "861  1.0  8.0  1.0  21.0\n",
       "862  0.0  3.0  0.0  48.0\n",
       "863  2.0  8.0  0.0   NaN\n",
       "864  1.0  8.0  1.0  24.0\n",
       "865  1.0  8.0  0.0  42.0\n",
       "866  1.0  8.0  0.0  27.0\n",
       "867  0.0  0.0  1.0  31.0\n",
       "868  2.0  8.0  1.0   NaN\n",
       "869  2.0  8.0  1.0   4.0\n",
       "870  2.0  8.0  1.0  26.0\n",
       "871  0.0  3.0  0.0  47.0\n",
       "872  0.0  1.0  1.0  33.0\n",
       "873  2.0  8.0  1.0  47.0\n",
       "874  1.0  8.0  0.0  28.0\n",
       "875  2.0  8.0  0.0  15.0\n",
       "876  2.0  8.0  1.0  20.0\n",
       "877  2.0  8.0  1.0  19.0\n",
       "878  2.0  8.0  1.0   NaN\n",
       "879  0.0  2.0  0.0  56.0\n",
       "880  1.0  8.0  0.0  25.0\n",
       "881  2.0  8.0  1.0  33.0\n",
       "882  2.0  8.0  0.0  22.0\n",
       "883  1.0  8.0  1.0  28.0\n",
       "884  2.0  8.0  1.0  25.0\n",
       "885  2.0  8.0  0.0  39.0\n",
       "886  1.0  8.0  1.0  27.0\n",
       "887  0.0  1.0  0.0  19.0\n",
       "888  2.0  8.0  0.0   NaN\n",
       "889  0.0  2.0  1.0  26.0\n",
       "890  2.0  8.0  1.0  32.0\n",
       "\n",
       "[891 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = pd.DataFrame([encoded_class,\n",
    "                              encoded_cabin,\n",
    "                              encoded_sex,\n",
    "                              titanic_train[\"Age\"]]).T\n",
    "\n",
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Q'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-47a5952ea6be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitanic_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Q'"
     ]
    }
   ],
   "source": [
    "X = titanic_train.as_matrix().astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
